{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "import joblib\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "# Definindo a seed para o random state\n",
    "rs = 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo os dados\n",
    "data_fraud = pd.read_csv(\"../data/processed/data_fraud.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo em variáveis explicativas e target\n",
    "x = data_fraud.drop([\"score_fraude_modelo\", \"fraude\"], axis = 1)\n",
    "y = data_fraud[\"fraude\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos relembrar pontos importantes que descobrimos na etapa de análise:\n",
    "\n",
    "- As variáveis **pais** e **categoria_produto** possuem uma alta cardinalidade.\n",
    "- As variáveis **pais** e **categoria_produto** possuem muitos valores com contagem de categorias iguais.\n",
    "- Ainda existem variáveis com valores ausentes, tanto categóricas, como numéricas.\n",
    "- O target está desbalanceado.\n",
    "\n",
    "Sabendo disso, vamos desenhar como a etapa de experimentação irá se desenrolar:\n",
    "\n",
    "1. Os dados serão divididos em treino, dev e teste. Iremos treinar o algoritmo\n",
    "com os dados de treino, fazer a tunagem com os dados de dev, e, por fim, validar\n",
    "com os dados de teste.\n",
    "2. Será criado um esqueleto para o pipeline de transformação, consistindo\n",
    "em um imputer e scaler(quando necessário) para as variáveis numéricas e um imputer \n",
    "e um encoder para as categóricas.\n",
    "    \n",
    "    2.1. Não usaremos o OneHotEncoder para as colunas com uma alta quantidade de\n",
    "    categorias únicas, pois isso elevaria a dimensionalidade dos dados.\n",
    "\n",
    "    2.2. Também não será utilizado o CountEncoder nas colunas com uma alta quantidade\n",
    "    de categorias únicas, pois algumas categorias apresentam a mesma quantidade de registros.\n",
    "\n",
    "3. A princípio, testaremos alguns modelos base com o StandardScaler (quando necessário),\n",
    "OneHotEncoder para as features de baixa dimensão e CatBoostEncoder para as de alta\n",
    "dimensão.\n",
    "3. As métricas avaliadas serão o Recall e a Latência média.\n",
    "4. Os modelos mais promissores entrarão em outra rodada de experimentos, dessa\n",
    "vez para testar outras combinações de encoders e scalers (se necessário).\n",
    "\n",
    "Agora que sabemos o que fazer, vamos descobrir quais métricas devemos superar.\n",
    "Para tal, vamos calcular o **recall** e **f1_weighted** das predições do modelo atual, \n",
    "assim como ganhos e perdas que tais predições geram. Segue como cada uma será\n",
    "calculada:\n",
    "\n",
    "- Perdas: o valor de compra de todos os falsos negativos (fraudes identificadas como compras legítimas) serão somadas.\n",
    "- Lucro Bruto: o valor de todos os verdadeiros negativos (compras legítimas não identificadas como fraude).\n",
    "- Lucro líquido: Lucro Bruto - Perdas\n",
    "\n",
    "Eu também poderia acrescentar os falsos positivos (compras legítimas \n",
    "identificadas como fraudulentas), mas como não sei se a compra é cancelada de\n",
    "vez ou aguarda confirmação adicional por parte do cliente, optarei por não\n",
    "incluir esses valores.\n",
    "\n",
    "As métricas serão calculadas a partir dos dados de **teste**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o local para salvar os exoerimentos\n",
    "mlflow.set_tracking_uri('../mlruns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divindo os dados em treino, dev e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x,\n",
    "                                                        y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=rs)\n",
    "\n",
    "x_dev, x_teste, y_dev, y_teste = train_test_split(x_teste, \n",
    "                                                  y_teste,\n",
    "                                                  stratify=y_teste,\n",
    "                                                  test_size=0.5,\n",
    "                                                  random_state=rs)\n",
    "\n",
    "# Dividindo features numéricas de categóricas\n",
    "cat_cols_high_dim = [\"pais\", \"categoria_produto\"]\n",
    "cat_cols = [col for col in x_treino.select_dtypes(\"object\").columns if col not in cat_cols_high_dim]\n",
    "num_cols = x_treino.select_dtypes([\"int\", \"float\"]).columns\n",
    "\n",
    "# Setando o KFold\n",
    "kf = StratifiedKFold(shuffle=True, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os dados de métricas\n",
    "data_metrics = data_fraud.loc[y_teste.index, [\"valor_compra\", \"score_fraude_modelo\", \"fraude\"]]\n",
    "\n",
    "# Criando uma label com base nos scores do modelo\n",
    "data_metrics[\"label_fraude_modelo\"] = data_metrics[\"score_fraude_modelo\"].apply(lambda score: 1 if score >= 50 else 0)\n",
    "\n",
    "# Reduzindo o score para a escala entre 0 e 1\n",
    "data_metrics[\"score_fraude_modelo\"] = data_metrics[\"score_fraude_modelo\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando as métricas\n",
    "recall = recall_score(data_metrics[\"fraude\"], data_metrics[\"label_fraude_modelo\"])\n",
    "f1_weighted = f1_score(data_metrics[\"fraude\"], data_metrics[\"label_fraude_modelo\"], average=\"weighted\")\n",
    "perdas = data_metrics.query(\"fraude == 1 and label_fraude_modelo == 0\")[\"valor_compra\"].sum()\n",
    "ganhos_brutos = (data_metrics.query(\"fraude == 0 and label_fraude_modelo == 0\")[\"valor_compra\"] * 0.10).sum()\n",
    "ganhos_liquidos = ganhos_brutos - perdas\n",
    "\n",
    "print(\"Com o threshold base (50%), o recall é de: \", recall)\n",
    "print(\"Com o threshold base (50%), o f1-score weighted é de: \", f1_weighted)\n",
    "print(\"Com o threshold base (50%), as perdas são de: \", perdas)\n",
    "print(\"Com o threshold base (50%), os ganhos bruto são de: \", ganhos_brutos)\n",
    "print(\"Com o threshold base (50%), os ganhos líquidos são de: \", ganhos_liquidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\"Threshold\":[], \n",
    "             \"Recall\":[],\n",
    "             \"Precision\":[],\n",
    "             \"F1 Weighted\":[],\n",
    "             \"Ganhos Brutos\":[],\n",
    "             \"Perdas\":[],\n",
    "             \"Ganhos Líquidos\":[]}\n",
    "\n",
    "# Calculando as métricas para cada threshold\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "    predictions = (data_metrics[\"score_fraude_modelo\"] >= threshold).astype(int)\n",
    "    recall = recall_score(y_teste, predictions)\n",
    "    precision = precision_score(y_teste, predictions)\n",
    "    f1 = f1_score(y_teste, predictions, average=\"weighted\")\n",
    "    data_dict[\"Threshold\"].append(threshold)\n",
    "    data_dict[\"Recall\"].append(recall)\n",
    "    data_dict[\"Precision\"].append(precision)\n",
    "    data_dict[\"F1 Weighted\"].append(f1)\n",
    "    \n",
    "    data_metrics[\"label_fraude_modelo\"] = predictions\n",
    "    acertos = data_metrics.query(f\"fraude == 0 and label_fraude_modelo == 0\")\n",
    "    erros = data_metrics.query(f\"fraude == 1 and label_fraude_modelo == 0\")\n",
    "    ganhos = (acertos[\"valor_compra\"] * 0.10).sum()\n",
    "    perdas = erros[\"valor_compra\"].sum()\n",
    "    diff_ganhos_perdas = ganhos - perdas\n",
    "    data_dict[\"Ganhos Brutos\"].append(ganhos)\n",
    "    data_dict[\"Perdas\"].append(perdas)\n",
    "    data_dict[\"Ganhos Líquidos\"].append(diff_ganhos_perdas)\n",
    "        \n",
    "# Plotando o gráfico    \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"Recall\"], label='Recall')\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"Precision\"], label='Precision')\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"F1 Weighted\"], label='F1 Weighted')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Recall, Precision e F1 Weighted em diferentes thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados em forma de tabela\n",
    "pd.DataFrame(data_dict).sort_values(by=\"Ganhos Líquidos\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso maior ganho está no Threshold 0.76, onde o lucro líquido foi de 46362.21\n",
    "\n",
    "## Realizando os experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os dicionarios com os modelos e etapas de pre-processamento que serã utilizadas\n",
    "\n",
    "dict_models_scale_sensitive = {\"LR\": LogisticRegression(random_state=rs,\n",
    "                                                        class_weight='balanced')}\n",
    "\n",
    "dict_models_tree_based = {\"LGBM\": LGBMClassifier(is_unbalance=True,\n",
    "                                                 objective= 'binary',\n",
    "                                                 random_state=rs),\n",
    "                          \"XGB\": XGBClassifier(random_state=rs,\n",
    "                                               objective='binary:hinge'),\n",
    "                          \"RF\": RandomForestClassifier(class_weight='balanced',\n",
    "                                                       random_state=rs)}\n",
    "\n",
    "# Criando dicionário com os encoders\n",
    "dict_encoders = {\"OHE\": OneHotEncoder(drop='first'),\n",
    "                 \"TE\": ce.TargetEncoder(),\n",
    "                 \"BE\": ce.BinaryEncoder(),\n",
    "                 \"ME\": ce.MEstimateEncoder(),\n",
    "                 \"CE\": ce.CatBoostEncoder(),\n",
    "                 \"GE\":ce.GrayEncoder(),\n",
    "                 \"CTE\":ce.CountEncoder()}\n",
    "\n",
    "dict_imputers_num = {\"SIAVG\": SimpleImputer(strategy='mean'),\n",
    "                     \"SIMEDIAN\": SimpleImputer(strategy='median')}\n",
    "\n",
    "dict_scalers = {\"SS\": StandardScaler(),\n",
    "                \"RS\": RobustScaler()}\n",
    "\n",
    "# Criando dicionário com os transformers\n",
    "dict_transformers = {\"PT\": PowerTransformer()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando/acessando o experimento\n",
    "mlflow.set_experiment('Comparando modelos base')\n",
    "\n",
    "# Iniciando os experimentos sem transformers\n",
    "for tag, model in dict_models_scale_sensitive.items():\n",
    "\n",
    "    # Gerando a tag de identificação do modelo\n",
    "    nome_modelo = f'{tag}'\n",
    "\n",
    "    with mlflow.start_run(run_name=nome_modelo):\n",
    "\n",
    "        # Criando os pipeline com os transformers\n",
    "        pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                            ('encoder', OneHotEncoder(drop='first'))])\n",
    "    \n",
    "        # Criando os pipeline com os transformers\n",
    "        pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                        ('encoder_hd', ce.CatBoostEncoder())])\n",
    "    \n",
    "        pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "                            ('scaler', StandardScaler())])\n",
    "    \n",
    "        # Criando o transformador\n",
    "        transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                        ('num', pipe_num, num_cols),\n",
    "                                        ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                        remainder=\"passthrough\")\n",
    "    \n",
    "        # Criando o pipeline final\n",
    "        pipe = Pipeline([('transformer', transformer),\n",
    "                        ('model', model)])\n",
    "    \n",
    "        # Executando o cross validation\n",
    "        cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='recall')\n",
    "    \n",
    "        # Calculando a média das métricas\n",
    "        mean_score = cross_val_scores.mean()           \n",
    "    \n",
    "        # Salvando a métrica da folder 1\n",
    "        mlflow.log_metric('recall_fold_1', cross_val_scores[0])\n",
    "    \n",
    "        # Salvando a métrica da folder 2\n",
    "        mlflow.log_metric('recall_fold_2', cross_val_scores[1])\n",
    "    \n",
    "        # Salvando a métrica da folder 3\n",
    "        mlflow.log_metric('recall_fold_3', cross_val_scores[2])\n",
    "    \n",
    "        # Salvando a métrica da folder 4\n",
    "        mlflow.log_metric('recall_fold_4', cross_val_scores[3])\n",
    "    \n",
    "        # Salvando a métrica da folder 5\n",
    "        mlflow.log_metric('recall_fold_5', cross_val_scores[4])\n",
    "    \n",
    "        # Salvando as métricas\n",
    "        mlflow.log_metric('recall_mean', mean_score)\n",
    "        \n",
    "        # Salvando o f1 weighted\n",
    "        mean_f1 = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='f1_weighted').mean()\n",
    "        \n",
    "        # Salvando a métrica do f1\n",
    "        mlflow.log_metric('f1_weighted_mean', mean_f1)\n",
    "    \n",
    "        # Treinando o algoritmo\n",
    "        pipe.fit(x_treino, y_treino)\n",
    "    \n",
    "        # Calculando a latência média\n",
    "        latency_list = []\n",
    "    \n",
    "        for _, row in x_treino[:1000].iterrows():\n",
    "        \n",
    "            # Início da contagem de tempo\n",
    "            start_time = time.time()\n",
    "    \n",
    "            # Extrair os recursos da linha\n",
    "            features = row.values.reshape(1, -1)\n",
    "    \n",
    "            # Fazer a previsão para a linha individual\n",
    "            prediction = pipe.predict(pd.DataFrame(features, columns = x_treino.columns.to_list()))\n",
    "    \n",
    "            # Encerra a contagem\n",
    "            end_time = time.time()\n",
    "            atomic_time = end_time - start_time\n",
    "    \n",
    "            # Transforma segundo em milissegundo\n",
    "            atomic_milissec = atomic_time * 1000\n",
    "    \n",
    "            # Adiciona o tempo em uma lista\n",
    "            latency_list.append(atomic_milissec)\n",
    "    \n",
    "        # calcula a média \n",
    "        mlflow.log_metric(\"Latência média\", np.mean(latency_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando os experimentos sem transformers\n",
    "for tag, model in dict_models_tree_based.items():\n",
    "\n",
    "    # Gerando a tag de identificação do modelo\n",
    "    nome_modelo = f'{tag}'\n",
    "\n",
    "    with mlflow.start_run(run_name=nome_modelo):\n",
    "\n",
    "        # Criando os pipeline com os transformers\n",
    "        pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                            ('encoder', OneHotEncoder(drop='first'))])\n",
    "    \n",
    "        # Criando os pipeline com os transformers\n",
    "        pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                        ('encoder_hd', ce.CatBoostEncoder())])\n",
    "    \n",
    "        pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\"))])\n",
    "    \n",
    "        # Criando o transformador\n",
    "        transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                        ('num', pipe_num, num_cols),\n",
    "                                        ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                        remainder=\"passthrough\")\n",
    "    \n",
    "        # Criando o pipeline final\n",
    "        pipe = Pipeline([('transformer', transformer),\n",
    "                        ('model', model)])\n",
    "    \n",
    "        # Executando o cross validation\n",
    "        cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='recall')\n",
    "    \n",
    "        # Calculando a média das métricas\n",
    "        mean_score = cross_val_scores.mean()           \n",
    "    \n",
    "        # Salvando a métrica da folder 1\n",
    "        mlflow.log_metric('recall_fold_1', cross_val_scores[0])\n",
    "    \n",
    "        # Salvando a métrica da folder 2\n",
    "        mlflow.log_metric('recall_fold_2', cross_val_scores[1])\n",
    "    \n",
    "        # Salvando a métrica da folder 3\n",
    "        mlflow.log_metric('recall_fold_3', cross_val_scores[2])\n",
    "    \n",
    "        # Salvando a métrica da folder 4\n",
    "        mlflow.log_metric('recall_fold_4', cross_val_scores[3])\n",
    "    \n",
    "        # Salvando a métrica da folder 5\n",
    "        mlflow.log_metric('recall_fold_5', cross_val_scores[4])\n",
    "    \n",
    "        # Salvando as métricas\n",
    "        mlflow.log_metric('recall_mean', mean_score)\n",
    "        \n",
    "        # Salvando o f1 weighted\n",
    "        mean_f1 = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='f1_weighted').mean()\n",
    "        \n",
    "        # Salvando a métrica do f1\n",
    "        mlflow.log_metric('f1_weighted_mean', mean_f1)\n",
    "    \n",
    "        # Treinando o algoritmo\n",
    "        pipe.fit(x_treino, y_treino)\n",
    "    \n",
    "        # Calculando a latência média\n",
    "        latency_list = []\n",
    "    \n",
    "        for _, row in x_treino[:1000].iterrows():\n",
    "        \n",
    "            # Início da contagem de tempo\n",
    "            start_time = time.time()\n",
    "    \n",
    "            # Extrair os recursos da linha\n",
    "            features = row.values.reshape(1, -1)\n",
    "    \n",
    "            # Fazer a previsão para a linha individual\n",
    "            prediction = pipe.predict(pd.DataFrame(features, columns = x_treino.columns.to_list()))\n",
    "    \n",
    "            # Encerra a contagem\n",
    "            end_time = time.time()\n",
    "            atomic_time = end_time - start_time\n",
    "    \n",
    "            # Transforma segundo em milissegundo\n",
    "            atomic_milissec = atomic_time * 1000\n",
    "    \n",
    "            # Adiciona o tempo em uma lista\n",
    "            latency_list.append(atomic_milissec)\n",
    "    \n",
    "        # calcula a média \n",
    "        mlflow.log_metric(\"Latência média\", np.mean(latency_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as colunas de interesse\n",
    "colunas_para_buscar = [\"tags.mlflow.runName\", 'metrics.f1_weighted_mean', \n",
    "                       'metrics.recall_mean', 'metrics.Latência média', \n",
    "                       'metrics.recall_fold_1', 'metrics.recall_fold_2', \n",
    "                       'metrics.recall_fold_3', 'metrics.recall_fold_4', \n",
    "                       'metrics.recall_fold_5']\n",
    "\n",
    "# Buscando os melhores modelos\n",
    "runs = mlflow.search_runs()[colunas_para_buscar]\n",
    "\n",
    "# Ordenando por recall médio\n",
    "runs.sort_values(by=\"metrics.recall_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos modelos testados, apenas o **LightGBM** e a **Regressão Logística** tiveram\n",
    "um bom resultado. \n",
    "\n",
    "- O **Recall** do **LightGBM** é cerca de **0.5% superior** ao da **Regressão**.\n",
    "- A **latência** do **LightGBM** é cerca de **76% maior** do que a da **Regressão**.\n",
    "\n",
    "Vamos tunar e avaliar ambos os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando/acessando o experimento\n",
    "mlflow.set_experiment('Comparando regressões')\n",
    "\n",
    "# Iniciando os experimentos com regressões\n",
    "for tag_encoder, encoder in dict_encoders.items():\n",
    "    for tag_scaler, scaler in dict_scalers.items():\n",
    "        for tag_imputer, imputer in dict_imputers_num.items():\n",
    "        \n",
    "            # Gerando a tag de identificação do modelo\n",
    "            nome_modelo = f'LR_{tag_encoder}_{tag_scaler}_{tag_imputer}'\n",
    "\n",
    "            with mlflow.start_run(run_name=nome_modelo):\n",
    "            \n",
    "                # Criando os pipeline com os transformers\n",
    "                pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('encoder', encoder)])\n",
    "\n",
    "                # Criando os pipeline com os transformers\n",
    "                pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "                pipe_num = Pipeline([('imputer_num', imputer),\n",
    "                                     ('scaler', scaler)])\n",
    "\n",
    "                # Criando o transformador\n",
    "                transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                                ('num', pipe_num, num_cols),\n",
    "                                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                                remainder=\"passthrough\")\n",
    "\n",
    "                # Criando o pipeline final\n",
    "                pipe = Pipeline([('transformer', transformer),\n",
    "                                ('model', LogisticRegression(class_weight='balanced',\n",
    "                                                             random_state=rs))])\n",
    "\n",
    "                # Executando o cross validation\n",
    "                cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='recall')\n",
    "\n",
    "                # Calculando a média das métricas\n",
    "                mean_score = cross_val_scores.mean()           \n",
    "\n",
    "                # Salvando a métrica da folder 1\n",
    "                mlflow.log_metric('recall_fold_1', cross_val_scores[0])\n",
    "\n",
    "                # Salvando a métrica da folder 2\n",
    "                mlflow.log_metric('recall_fold_2', cross_val_scores[1])\n",
    "\n",
    "                # Salvando a métrica da folder 3\n",
    "                mlflow.log_metric('recall_fold_3', cross_val_scores[2])\n",
    "\n",
    "                # Salvando a métrica da folder 4\n",
    "                mlflow.log_metric('recall_fold_4', cross_val_scores[3])\n",
    "\n",
    "                # Salvando a métrica da folder 5\n",
    "                mlflow.log_metric('recall_fold_5', cross_val_scores[4])\n",
    "\n",
    "                # Salvando as métricas\n",
    "                mlflow.log_metric('recall_mean', mean_score)\n",
    "                \n",
    "                # Salvando o f1 weighted\n",
    "                mean_f1 = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='f1_weighted').mean()\n",
    "                \n",
    "                # Salvando a métrica do f1\n",
    "                mlflow.log_metric('f1_weighted_mean', mean_f1)\n",
    "\n",
    "                # Treinando o algoritmo\n",
    "                pipe.fit(x_treino, y_treino)\n",
    "\n",
    "                # Calculando a latência média\n",
    "                latency_list = []\n",
    "\n",
    "                for _, row in x_treino[:1000].iterrows():\n",
    "                \n",
    "                    # Início da contagem de tempo\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    # Extrair os recursos da linha\n",
    "                    features = row.values.reshape(1, -1)\n",
    "\n",
    "                    # Fazer a previsão para a linha individual\n",
    "                    prediction = pipe.predict(pd.DataFrame(features, columns = x_treino.columns.to_list()))\n",
    "\n",
    "                    # Encerra a contagem\n",
    "                    end_time = time.time()\n",
    "                    atomic_time = end_time - start_time\n",
    "\n",
    "                    # Transforma segundo em milissegundo\n",
    "                    atomic_milissec = atomic_time * 1000\n",
    "\n",
    "                    # Adiciona o tempo em uma lista\n",
    "                    latency_list.append(atomic_milissec)\n",
    "\n",
    "                # calcula a média \n",
    "                mlflow.log_metric(\"Latência média\", np.mean(latency_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as colunas de interesse\n",
    "colunas_para_buscar = [\"tags.mlflow.runName\", 'metrics.f1_weighted_mean', \n",
    "                       'metrics.recall_mean', 'metrics.Latência média', \n",
    "                       'metrics.recall_fold_1', 'metrics.recall_fold_2', \n",
    "                       'metrics.recall_fold_3', 'metrics.recall_fold_4', \n",
    "                       'metrics.recall_fold_5']\n",
    "\n",
    "# Buscando os melhores modelos\n",
    "runs = mlflow.search_runs()[colunas_para_buscar]\n",
    "\n",
    "# Ordenando por recall médio\n",
    "runs.sort_values(by=\"metrics.recall_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando/acessando o experimento\n",
    "mlflow.set_experiment('Comparando lgbms')\n",
    "\n",
    "# Iniciando os experimentos com o lightgbm\n",
    "for tag_encoder, encoder in dict_encoders.items():\n",
    "        for tag_imputer, imputer in dict_imputers_num.items():\n",
    "    \n",
    "            # Gerando a tag de identificação do modelo\n",
    "            nome_modelo = f'LGBM_{tag_encoder}_{tag_imputer}'\n",
    "    \n",
    "            with mlflow.start_run(run_name=nome_modelo):\n",
    "            \n",
    "                # Criando os pipeline com os transformers\n",
    "                pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('encoder', encoder)])\n",
    "    \n",
    "                # Criando os pipeline com os transformers\n",
    "                pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "    \n",
    "                pipe_num = Pipeline([('imputer_num', imputer)])\n",
    "    \n",
    "                # Criando o transformador\n",
    "                transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                                ('num', pipe_num, num_cols),\n",
    "                                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                                remainder=\"passthrough\")\n",
    "    \n",
    "                # Criando o pipeline final\n",
    "                pipe = Pipeline([('transformer', transformer),\n",
    "                                ('model', LGBMClassifier(is_unbalance=True,\n",
    "                                                 objective= 'binary',\n",
    "                                                 random_state=rs))])\n",
    "    \n",
    "                # Executando o cross validation\n",
    "                cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='recall')\n",
    "    \n",
    "                # Calculando a média das métricas\n",
    "                mean_score = cross_val_scores.mean()           \n",
    "    \n",
    "                # Salvando a métrica da folder 1\n",
    "                mlflow.log_metric('recall_fold_1', cross_val_scores[0])\n",
    "    \n",
    "                # Salvando a métrica da folder 2\n",
    "                mlflow.log_metric('recall_fold_2', cross_val_scores[1])\n",
    "    \n",
    "                # Salvando a métrica da folder 3\n",
    "                mlflow.log_metric('recall_fold_3', cross_val_scores[2])\n",
    "    \n",
    "                # Salvando a métrica da folder 4\n",
    "                mlflow.log_metric('recall_fold_4', cross_val_scores[3])\n",
    "    \n",
    "                # Salvando a métrica da folder 5\n",
    "                mlflow.log_metric('recall_fold_5', cross_val_scores[4])\n",
    "    \n",
    "                # Salvando as métricas\n",
    "                mlflow.log_metric('recall_mean', mean_score)\n",
    "                \n",
    "                # Salvando o f1 weighted\n",
    "                mean_f1 = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='f1_weighted').mean()\n",
    "                \n",
    "                # Salvando a métrica do f1\n",
    "                mlflow.log_metric('f1_weighted_mean', mean_f1)\n",
    "    \n",
    "                # Treinando o algoritmo\n",
    "                pipe.fit(x_treino, y_treino)\n",
    "    \n",
    "                # Calculando a latência média\n",
    "                latency_list = []\n",
    "    \n",
    "                for _, row in x_treino[:1000].iterrows():\n",
    "                \n",
    "                    # Início da contagem de tempo\n",
    "                    start_time = time.time()\n",
    "    \n",
    "                    # Extrair os recursos da linha\n",
    "                    features = row.values.reshape(1, -1)\n",
    "    \n",
    "                    # Fazer a previsão para a linha individual\n",
    "                    prediction = pipe.predict(pd.DataFrame(features, columns = x_treino.columns.to_list()))\n",
    "    \n",
    "                    # Encerra a contagem\n",
    "                    end_time = time.time()\n",
    "                    atomic_time = end_time - start_time\n",
    "    \n",
    "                    # Transforma segundo em milissegundo\n",
    "                    atomic_milissec = atomic_time * 1000\n",
    "    \n",
    "                    # Adiciona o tempo em uma lista\n",
    "                    latency_list.append(atomic_milissec)\n",
    "    \n",
    "                # calcula a média \n",
    "                mlflow.log_metric(\"Latência média\", np.mean(latency_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as colunas de interesse\n",
    "colunas_para_buscar = [\"tags.mlflow.runName\", 'metrics.f1_weighted_mean', \n",
    "                       'metrics.recall_mean', 'metrics.Latência média', \n",
    "                       'metrics.recall_fold_1', 'metrics.recall_fold_2', \n",
    "                       'metrics.recall_fold_3', 'metrics.recall_fold_4', \n",
    "                       'metrics.recall_fold_5']\n",
    "\n",
    "# Buscando os melhores modelos\n",
    "runs = mlflow.search_runs()[colunas_para_buscar]\n",
    "\n",
    "# Ordenando por recall médio\n",
    "runs.sort_values(by=\"metrics.recall_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística \n",
    "A combinação **Logistic Regression** + **CountEncoder** + **RobustSaler** + \n",
    "**SimpleImputer(Mediana)** obteve o primeiro lugar com as seguintes estatísticas:\n",
    "- Recall médio de 0.70\n",
    "- F1 weighted médio de 0.69 \n",
    "- Latência média de 39 milissegundos\n",
    "\n",
    "No geral, são boas métricas, e ele será o modelo escolhido. Entretanto, também\n",
    "houveram outras combinações que se saíram bem. A combinação \n",
    "**Logistic Regression** + **OneHotEncoder** + **RobustSaler** + \n",
    "**SimpleImputer(Media)** demonstrou ser promissora:\n",
    "- Recall médio de 0.67 (0.03 a menos que o primeiro colocado)\n",
    "- F1 weighted médio de 0.80 (0.10 a mais que o primeiro colocado)\n",
    "- Latência média de 20 milissegundos (19 milissegundos a menos que o primeiro colocado)\n",
    "\n",
    "Selecionaremos esses dois modelos para tunar os parâmetros.\n",
    "\n",
    "#### LightGBM\n",
    "\n",
    "Para os modelos com base no LightGBM, temos métricas bem semelhantes entre as \n",
    "combinações, por isso, selecionaremos aquele com a menor latência dentre os \n",
    "5 primeiros:\n",
    "**LightGBM** + **OneHotEncoder** + **SimpleImputer(Média)**\n",
    "\n",
    "## Tunando o modelo candidato\n",
    "\n",
    "Agora que já temos a melhor combinação de preprocessors, vamos buscar a melhor\n",
    "opção de hiperparâmetros.\n",
    "\n",
    "Para tal, usaremos o **Optuna**.\n",
    "\n",
    "Vamos iniciar com a primeira regressão: **Logistic Regression** + **CountEncoder** + **RobustSaler** + \n",
    "**SimpleImputer(Mediana)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para tunar o modelo\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 1e-4, 1e+4, log=True),\n",
    "        'penalty': trial.suggest_categorical('penalty', [None, 'l2']),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'saga', 'newton-cholesky']),\n",
    "        'max_iter': trial.suggest_int('max_iter', 50, 1000),\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "        'random_state': rs\n",
    "    }\n",
    "    \n",
    "    # Criando os pipeline com os transformers\n",
    "    pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                        ('encoder', ce.CountEncoder())])\n",
    "\n",
    "    # Criando os pipeline com os transformers\n",
    "    pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "    pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "                          (\"scaler\", RobustScaler())])\n",
    "\n",
    "    # Criando o transformador\n",
    "    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                    ('num', pipe_num, num_cols),\n",
    "                                    ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                    remainder=\"passthrough\")\n",
    "    \n",
    "    # Criando o pipeline final\n",
    "    pipe = Pipeline([('transformer', transformer),\n",
    "                    ('model', LogisticRegression(**params))])\n",
    "\n",
    "    # Treinando o modelo com os dados de treino\n",
    "    pipe.fit(x_treino, y_treino)\n",
    "   \n",
    "    recall = recall_score(y_dev, pipe.predict(x_dev))\n",
    "    \n",
    "    return recall\n",
    "\n",
    "# Criando o estudo de otimização\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos parâmetros que quase zeram a taxa de falsos negativos. Averiguaremos \n",
    "melhor durante o teste final, mas me reservarei a selecionar outro conjunto de \n",
    "parâmetros que identifiquei no log dos experimentos, pois diferentemente dos\n",
    "melhores parâmetros encontrados, estes usam regularização, que ajuda a prevenir o \n",
    "overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando os melhores parâmetros\n",
    "best_params_l1_v1 = {'C': 0.0003497693165590731,\n",
    "                    'penalty': None,\n",
    "                    'solver': 'saga',\n",
    "                    'max_iter': 224,\n",
    "                    'fit_intercept': False,\n",
    "                    'class_weight': 'balanced',\n",
    "                    'random_state': rs}\n",
    "\n",
    "best_params_l1_v2 = {'C': 1789.4428651327607, \n",
    "                      'penalty': 'l2', \n",
    "                      'solver': 'saga', \n",
    "                      'max_iter': 694, \n",
    "                      'fit_intercept': True, \n",
    "                      'class_weight': 'balanced',\n",
    "                      'random_state':rs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os pipeline com os transformers\n",
    "pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', ce.CountEncoder())])\n",
    "\n",
    "# Criando os pipeline com os transformers\n",
    "pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "                        (\"scaler\", RobustScaler())])\n",
    "\n",
    "# Criando o transformador\n",
    "transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                ('num', pipe_num, num_cols),\n",
    "                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                remainder=\"passthrough\")\n",
    "\n",
    "# Criando o pipeline final\n",
    "pipe_logistica_1_v1 = Pipeline([('transformer', transformer),\n",
    "                ('model', LogisticRegression(**best_params_l1_v1))])\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "pipe_logistica_1_v1.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os pipeline com os transformers\n",
    "pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', ce.CountEncoder())])\n",
    "\n",
    "# Criando os pipeline com os transformers\n",
    "pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "                        (\"scaler\", RobustScaler())])\n",
    "\n",
    "# Criando o transformador\n",
    "transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                ('num', pipe_num, num_cols),\n",
    "                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                remainder=\"passthrough\")\n",
    "\n",
    "# Criando o pipeline final\n",
    "pipe_logistica_1_v2 = Pipeline([('transformer', transformer),\n",
    "                ('model', LogisticRegression(**best_params_l1_v2))])\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "pipe_logistica_1_v2.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos testar a segunda: **Logistic Regression** + **OneHotEncoder** + **RobustSaler** + \n",
    "**SimpleImputer(Media)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para tunar o modelo\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 1e-4, 1e+4, log=True),\n",
    "        'penalty': trial.suggest_categorical('penalty', [None, 'l2']),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'saga', 'newton-cholesky']),\n",
    "        'max_iter': trial.suggest_int('max_iter', 50, 1000),\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "        'random_state': rs\n",
    "    }\n",
    "    \n",
    "    # Criando os pipeline com os transformers\n",
    "    pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                        ('encoder', OneHotEncoder(drop='first'))])\n",
    "\n",
    "    # Criando os pipeline com os transformers\n",
    "    pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "    pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"mean\")),\n",
    "                        ('scaler', RobustScaler())])\n",
    "\n",
    "    # Criando o transformador\n",
    "    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                    ('num', pipe_num, num_cols),\n",
    "                                    ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                    remainder=\"passthrough\")\n",
    "    \n",
    "    # Criando o pipeline final\n",
    "    pipe = Pipeline([('transformer', transformer),\n",
    "                    ('model', LogisticRegression(**params))])\n",
    "\n",
    "    # Treinando o modelo com os dados de treino\n",
    "    pipe.fit(x_treino, y_treino)\n",
    "   \n",
    "    recall = recall_score(y_dev, pipe.predict(x_dev))\n",
    "    \n",
    "    return recall\n",
    "\n",
    "# Criando o estudo de otimização\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_l2 = {'C': 3.9049332827863656,\n",
    "                    'penalty': None,\n",
    "                    'solver': 'saga',\n",
    "                    'max_iter': 983,\n",
    "                    'fit_intercept': True,\n",
    "                    'class_weight': 'balanced',\n",
    "                    'random_state':rs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os pipeline com os transformers\n",
    "pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', OneHotEncoder(drop='first'))])\n",
    "\n",
    "# Criando os pipeline com os transformers\n",
    "pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"mean\")),\n",
    "                    ('scaler', RobustScaler())])\n",
    "\n",
    "# Criando o transformador\n",
    "transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                ('num', pipe_num, num_cols),\n",
    "                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                remainder=\"passthrough\")\n",
    "\n",
    "# Criando o pipeline final\n",
    "pipe_logistica_2 = Pipeline([('transformer', transformer),\n",
    "                ('model', LogisticRegression(**best_params_l2))])\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "pipe_logistica_2.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E finalmente, vamos à ultima combinação: **LightGBM** + **OneHotEncoder** + **SimpleImputer(Média)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para tunar o modelo\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'goss', 'dart']),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000, step=20000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 10.0, log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "        'random_state': rs,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    # Criando os pipeline com os transformers\n",
    "    pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                        ('encoder', OneHotEncoder(drop='first'))])\n",
    "\n",
    "    # Criando os pipeline com os transformers\n",
    "    pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "    pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "    # Criando o transformador\n",
    "    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                    ('num', pipe_num, num_cols),\n",
    "                                    ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                    remainder=\"passthrough\")\n",
    "    \n",
    "    # Criando o pipeline final\n",
    "    pipe = Pipeline([('transformer', transformer),\n",
    "                    ('model', LGBMClassifier(**params))])\n",
    "\n",
    "    # Treinando o modelo com os dados de treino\n",
    "    pipe.fit(x_treino, y_treino)\n",
    "   \n",
    "    recall = recall_score(y_dev, pipe.predict(x_dev))\n",
    "    \n",
    "    return recall\n",
    "\n",
    "# Criando o estudo de otimização\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramslgbm = {'boosting_type': 'gbdt',\n",
    " 'num_leaves': 59,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.1956139464650669,\n",
    " 'n_estimators': 53,\n",
    " 'subsample_for_bin': 100000,\n",
    " 'min_child_samples': 436,\n",
    " 'reg_alpha': 1.1509684515235595e-05,\n",
    " 'reg_lambda': 0.32209012112142255,\n",
    " 'colsample_bytree': 0.6757255778256718,\n",
    " 'subsample': 0.9437474856939362,\n",
    " 'class_weight': 'balanced',\n",
    " 'random_state':rs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os pipeline com os transformers\n",
    "pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))])\n",
    "\n",
    "# Criando os pipeline com os transformers\n",
    "pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "                    ('scaler', StandardScaler())])\n",
    "\n",
    "# Criando o transformador\n",
    "transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                ('num', pipe_num, num_cols),\n",
    "                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                remainder=\"passthrough\")\n",
    "\n",
    "# Criando o pipeline final\n",
    "pipelgbm = Pipeline([('transformer', transformer),\n",
    "                ('model', LGBMClassifier(**paramslgbm))])\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "pipelgbm.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprando modelos\n",
    "\n",
    "Agora vamos comparar os modelos com o antigo.\n",
    "\n",
    "Vamos relembrar o desempenho da solução antigo com o threshold base de 50% (conjunto de teste):\n",
    "\n",
    "- **Recall**:  0.7608888888888888\n",
    "- **F1-Score Weighted**:  0.6586582569846577\n",
    "- **Perda com fraude**:  12690.34\n",
    "- **Ganho bruto**:  42153.344000000005\n",
    "- **Ganho líquido**:  29463.004000000004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando as predições ao dataset\n",
    "data_metrics[\"label_fraude_logistica_v1_1\"] = pipe_logistica_1_v1.predict(x_teste)\n",
    "\n",
    "# Calculando as métricas\n",
    "recall = recall_score(y_teste, data_metrics[\"label_fraude_logistica_v1_1\"])\n",
    "f1_weighted = f1_score(y_teste, data_metrics[\"label_fraude_logistica_v1_1\"], average=\"weighted\")\n",
    "perdas = data_metrics.query(\"fraude == 1 and label_fraude_logistica_v1_1 == 0\")[\"valor_compra\"].sum()\n",
    "ganhos_brutos = (data_metrics.query(\"fraude == 0 and label_fraude_logistica_v1_1 == 0\")[\"valor_compra\"] * 0.10).sum()\n",
    "ganhos_liquidos = ganhos_brutos - perdas\n",
    "\n",
    "print(\"----------Logística v1----------\")\n",
    "print(\"Com o threshold base (50%), o recall é de: \", recall)\n",
    "print(\"Com o threshold base (50%), o f1-score weighted é de: \", f1_weighted)\n",
    "print(\"Com o threshold base (50%), as perdas são de: \", perdas)\n",
    "print(\"Com o threshold base (50%), os ganhos bruto são de: \", ganhos_brutos)\n",
    "print(\"Com o threshold base (50%), os ganhos líquidos são de: \", ganhos_liquidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando as predições ao dataset\n",
    "data_metrics[\"label_fraude_logistica_v1_2\"] = pipe_logistica_1_v2.predict(x_teste)\n",
    "\n",
    "# Calculando as métricas\n",
    "recall = recall_score(y_teste, data_metrics[\"label_fraude_logistica_v1_2\"])\n",
    "f1_weighted = f1_score(y_teste, data_metrics[\"label_fraude_logistica_v1_2\"], average=\"weighted\")\n",
    "perdas = data_metrics.query(\"fraude == 1 and label_fraude_logistica_v1_2 == 0\")[\"valor_compra\"].sum()\n",
    "ganhos_brutos = (data_metrics.query(\"fraude == 0 and label_fraude_logistica_v1_2 == 0\")[\"valor_compra\"] * 0.10).sum()\n",
    "ganhos_liquidos = ganhos_brutos - perdas\n",
    "\n",
    "print(\"----------Logística v1.2----------\")\n",
    "print(\"Com o threshold base (50%), o recall é de: \", recall)\n",
    "print(\"Com o threshold base (50%), o f1-score weighted é de: \", f1_weighted)\n",
    "print(\"Com o threshold base (50%), as perdas são de: \", perdas)\n",
    "print(\"Com o threshold base (50%), os ganhos bruto são de: \", ganhos_brutos)\n",
    "print(\"Com o threshold base (50%), os ganhos líquidos são de: \", ganhos_liquidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando as predições ao dataset\n",
    "data_metrics[\"label_fraude_logistica_2\"] = pipe_logistica_2.predict(x_teste)\n",
    "\n",
    "# Calculando as métricas\n",
    "recall = recall_score(y_teste, data_metrics[\"label_fraude_logistica_2\"])\n",
    "f1_weighted = f1_score(y_teste, data_metrics[\"label_fraude_logistica_2\"], average=\"weighted\")\n",
    "perdas = data_metrics.query(\"fraude == 1 and label_fraude_logistica_2 == 0\")[\"valor_compra\"].sum()\n",
    "ganhos_brutos = (data_metrics.query(\"fraude == 0 and label_fraude_logistica_2 == 0\")[\"valor_compra\"] * 0.10).sum()\n",
    "ganhos_liquidos = ganhos_brutos - perdas\n",
    "\n",
    "print(\"----------Logística v2----------\")\n",
    "print(\"Com o threshold base (50%), o recall é de: \", recall)\n",
    "print(\"Com o threshold base (50%), o f1-score weighted é de: \", f1_weighted)\n",
    "print(\"Com o threshold base (50%), as perdas são de: \", perdas)\n",
    "print(\"Com o threshold base (50%), os ganhos bruto são de: \", ganhos_brutos)\n",
    "print(\"Com o threshold base (50%), os ganhos líquidos são de: \", ganhos_liquidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando as predições ao dataset\n",
    "data_metrics[\"label_fraude_lgbm\"] = pipelgbm.predict(x_teste)\n",
    "\n",
    "# Calculando as métricas\n",
    "recall = recall_score(y_teste, data_metrics[\"label_fraude_lgbm\"])\n",
    "f1_weighted = f1_score(y_teste, data_metrics[\"label_fraude_lgbm\"], average=\"weighted\")\n",
    "perdas = data_metrics.query(\"fraude == 1 and label_fraude_lgbm == 0\")[\"valor_compra\"].sum()\n",
    "ganhos_brutos = (data_metrics.query(\"fraude == 0 and label_fraude_lgbm == 0\")[\"valor_compra\"] * 0.10).sum()\n",
    "ganhos_liquidos = ganhos_brutos - perdas\n",
    "\n",
    "print(\"----------LGBM----------\")\n",
    "print(\"Com o threshold base (50%), o recall é de: \", recall)\n",
    "print(\"Com o threshold base (50%), o f1-score weighted é de: \", f1_weighted)\n",
    "print(\"Com o threshold base (50%), as perdas são de: \", perdas)\n",
    "print(\"Com o threshold base (50%), os ganhos bruto são de: \", ganhos_brutos)\n",
    "print(\"Com o threshold base (50%), os ganhos líquidos são de: \", ganhos_liquidos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando apenas os modelos base, duas das soluções criadas conseguem superar\n",
    "o modelo antigo a um threshold de 0.5:\n",
    "- **Logistic Regression** + **OneHotEncoder** + **RobustSaler** + **SimpleImputer(Media)**.\n",
    "- **LightGBM** + **OneHotEncoder** + **SimpleImputer(Média)**.\n",
    "\n",
    "Agora, vamos comparar os modelos com base nos thresholds que trazem o maior ganho.\n",
    "Lembrando que o modelo antigo, no meu melhor threshold trouxe um ganho líquido de\n",
    "46362.21 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o dicionário base\n",
    "data_dict = {\"Threshold\":[], \n",
    "             \"Recall\":[],\n",
    "             \"Precision\":[],\n",
    "             \"F1 Weighted\":[],\n",
    "             \"Ganhos Brutos\":[],\n",
    "             \"Perdas\":[],\n",
    "             \"Ganhos Líquidos\":[]}\n",
    "\n",
    "# Adicionando as predições de probabilidade\n",
    "data_metrics[\"score_fraude_logistica_2\"] = pipe_logistica_2.predict_proba(x_teste)[:, 1]\n",
    "\n",
    "# Calculando as métricas para cada threshold\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "    predictions = (data_metrics[\"score_fraude_logistica_2\"] >= threshold).astype(int)\n",
    "    recall = recall_score(y_teste, predictions)\n",
    "    precision = precision_score(y_teste, predictions)\n",
    "    f1 = f1_score(y_teste, predictions, average=\"weighted\")\n",
    "    data_dict[\"Threshold\"].append(threshold)\n",
    "    data_dict[\"Recall\"].append(recall)\n",
    "    data_dict[\"Precision\"].append(precision)\n",
    "    data_dict[\"F1 Weighted\"].append(f1)\n",
    "    \n",
    "    data_metrics[\"label_fraude_novo_logistica_2\"] = predictions\n",
    "    acertos = data_metrics.query(f\"fraude == 0 and label_fraude_novo_logistica_2 == 0\")\n",
    "    erros = data_metrics.query(f\"fraude == 1 and label_fraude_novo_logistica_2 == 0\")\n",
    "    ganhos = (acertos[\"valor_compra\"] * 0.10).sum()\n",
    "    perdas = erros[\"valor_compra\"].sum()\n",
    "    diff_ganhos_perdas = ganhos - perdas\n",
    "    data_dict[\"Ganhos Brutos\"].append(ganhos)\n",
    "    data_dict[\"Perdas\"].append(perdas)\n",
    "    data_dict[\"Ganhos Líquidos\"].append(diff_ganhos_perdas)\n",
    "        \n",
    "# Plotando o gráfico    \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"Recall\"], label='Recall')\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"Precision\"], label='Precision')\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"F1 Weighted\"], label='F1 Weighted')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Recall, Precision e F1 Weighted em diferentes thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados em forma de tabela\n",
    "pd.DataFrame(data_dict).sort_values(by=\"Ganhos Líquidos\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o dicionário base\n",
    "data_dict = {\"Threshold\":[], \n",
    "             \"Recall\":[],\n",
    "             \"Precision\":[],\n",
    "             \"F1 Weighted\":[],\n",
    "             \"Ganhos Brutos\":[],\n",
    "             \"Perdas\":[],\n",
    "             \"Ganhos Líquidos\":[]}\n",
    "\n",
    "# Adicionando as predições de probabilidade\n",
    "data_metrics[\"score_fraude_lightgbm\"] = pipelgbm.predict_proba(x_teste)[:, 1]\n",
    "\n",
    "# Calculando as métricas para cada threshold\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "    predictions = (data_metrics[\"score_fraude_lightgbm\"] >= threshold).astype(int)\n",
    "    recall = recall_score(y_teste, predictions)\n",
    "    precision = precision_score(y_teste, predictions)\n",
    "    f1 = f1_score(y_teste, predictions, average=\"weighted\")\n",
    "    data_dict[\"Threshold\"].append(threshold)\n",
    "    data_dict[\"Recall\"].append(recall)\n",
    "    data_dict[\"Precision\"].append(precision)\n",
    "    data_dict[\"F1 Weighted\"].append(f1)\n",
    "    \n",
    "    data_metrics[\"label_fraude_novo_lightgbm\"] = predictions\n",
    "    acertos = data_metrics.query(f\"fraude == 0 and label_fraude_novo_lightgbm == 0\")\n",
    "    erros = data_metrics.query(f\"fraude == 1 and label_fraude_novo_lightgbm == 0\")\n",
    "    ganhos = (acertos[\"valor_compra\"] * 0.10).sum()\n",
    "    perdas = erros[\"valor_compra\"].sum()\n",
    "    diff_ganhos_perdas = ganhos - perdas\n",
    "    data_dict[\"Ganhos Brutos\"].append(ganhos)\n",
    "    data_dict[\"Perdas\"].append(perdas)\n",
    "    data_dict[\"Ganhos Líquidos\"].append(diff_ganhos_perdas)\n",
    "        \n",
    "# Plotando o gráfico    \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"Recall\"], label='Recall')\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"Precision\"], label='Precision')\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"F1 Weighted\"], label='F1 Weighted')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Recall, Precision e F1 Weighted em diferentes thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados em forma de tabela\n",
    "pd.DataFrame(data_dict).sort_values(by=\"Ganhos Líquidos\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos nossas soluções no máximo de polimento, vamos verificar a taxa\n",
    "de fraude gerada por cada uma das soluções, incluindo o modelo antigo.\n",
    " \n",
    "Para esse cálculo, vamos usar a seguinte fórmula:<br><br>\n",
    "$\\text{Taxa de Fraude} = \\frac{\\text{Quantidade Falsos Negativos}}{\\text{Total de registros}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando as labels no melhor threshold de cada solução\n",
    "data_metrics[\"label_fraude_modelo\"] = (data_metrics[\"score_fraude_modelo\"] >= 0.76).astype(int)\n",
    "data_metrics[\"label_fraude_novo_logistica_2\"] = (data_metrics[\"score_fraude_modelo\"] >= 0.63).astype(int)\n",
    "data_metrics[\"label_fraude_novo_lightgbm\"] = (data_metrics[\"score_fraude_modelo\"] >= 0.66).astype(int)\n",
    "\n",
    "# Salvando as taxas em variáveis\n",
    "tx_modelo_antigo = (data_metrics.query(\"fraude == 1 and label_fraude_modelo == 0\").shape[0] / data_metrics.shape[0]) * 100\n",
    "tx_logistica = (data_metrics.query(\"fraude == 1 and label_fraude_novo_logistica_2 == 0\").shape[0] / data_metrics.shape[0]) * 100\n",
    "tx_lightgbm = (data_metrics.query(\"fraude == 1 and label_fraude_novo_lightgbm == 0\").shape[0] / data_metrics.shape[0]) * 100\n",
    "\n",
    "print(\"Modelo antigo: \", round(tx_modelo_antigo, 2))\n",
    "print(\"Logística: \", round(tx_logistica, 2))\n",
    "print(\"LightGBM: \", round(tx_lightgbm, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para melhor entendimento, vamos resumir os achados em uma tabela e avaliar a \n",
    "melhor solução:\n",
    "\n",
    "|               | Melhor Threshold | Melhor Recall | Melhor F1 | Latência Média (ms) | Ganho Bruto |  Perdas  | Ganho Líquido | Taxa de Fraude |\n",
    "|:-------------:|:----------------:|:-------------:|:---------:|:-------------------:|:-----------:|:--------:|:-------------:|:--------------:|\n",
    "| Modelo Antigo |       0.76       |      0.64     |    0.84   |          -          |   65912.19  | 19549.98 |    46362.21   |       1.8      |\n",
    "|  Logística_v2 |       0.63       |      0.41     |    0.90   |          20         |   65839.97  | 24752.43 |    41087.54   |      1.34      |\n",
    "|    LightGBM   |       0.66       |      0.48     |    0.90   |          39         |   73055.77  | 22947.13 |    50108.64   |      1.38      |\n",
    "\n",
    "Vamos levantar alguns pontos:\n",
    "- O modelo antigo se mostrou superior as novas soluções em evitar falsos negativos, ou seja, ele é superior em identificar transações que são fraudulentas de verdade.\n",
    "- Por outro lado, o modelo já implantado também bloqueia com mais frequência compras que são verídicas, impedindo que mais dinheiro entre no negócio.\n",
    "- A latência do LightGBM é quase o dobro da R. Logística.\n",
    "- A R. Logística, mesmo com ajuste de threshold, não consegue bater os ganhos do modelo antigo.\n",
    "- Ambos os modelos treinados reduziriam a taxa de fraude registrada.\n",
    "- O lucro registrado no LightGBM é 8% maior do que o do modelo antigo.\n",
    "\n",
    "Dado o que foi exposto aqui, selecionaremos o **LightGBM** para ser implantado.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializando o modelo\n",
    "joblib.dump(pipelgbm, \"../models/pipe.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
