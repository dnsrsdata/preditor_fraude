{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import optuna\n",
    "import joblib\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "# Definindo a seed para o random state\n",
    "rs = 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo os dados\n",
    "data_fraud = pd.read_csv(\"../data/processed/data_fraud.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo em variáveis explicativas e target\n",
    "x = data_fraud.drop([\"score_fraude_modelo\", \"fraude\"], axis = 1)\n",
    "y = data_fraud[\"fraude\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos relembrar pontos importantes que descobrimos na etapa de análise:\n",
    "\n",
    "- As variáveis **pais** e **categoria_produto** possuem uma alta cardinalidade.\n",
    "- As variáveis **pais** e **categoria_produto** possuem muitos valores com contagem de categorias iguais.\n",
    "- Ainda existem variáveis com valores ausentes, tanto categóricas, como numéricas.\n",
    "- O target está desbalanceado.\n",
    "\n",
    "Sabendo disso, vamos desenhar como a etapa de experimentação irá se desenrolar:\n",
    "\n",
    "1. Os dados serão divididos em treino, dev e teste. Iremos treinar o algoritmo\n",
    "com os dados de treino, fazer a tunagem com os dados de dev, e, por fim, validar\n",
    "com os dados de teste.\n",
    "2. Será criado um esqueleto para o pipeline de transformação, consistindo\n",
    "em um imputer e scaler(quando necessário) para as variáveis numéricas e um imputer \n",
    "e um encoder para as categóricas.\n",
    "    \n",
    "    2.1. Não usaremos o OneHotEncoder para as colunas com uma alta quantidade de\n",
    "    categorias únicas, pois isso elevaria a dimensionalidade dos dados.\n",
    "\n",
    "    2.2. Também não será utilizado o CountEncoder nas colunas com uma alta quantidade\n",
    "    de categorias únicas, pois algumas categorias apresentam a mesma quantidade de registros.\n",
    "\n",
    "3. A princípio, testaremos alguns modelos base com o StandardScaler (quando necessário),\n",
    "OneHotEncoder para as features de baixa dimensão e CatBoostEncoder para as de alta\n",
    "dimensão.\n",
    "3. As métricas avaliadas serão o Recall e a Latência média.\n",
    "4. Os modelos mais promissores entrarão em outra rodada de experimentos, dessa\n",
    "vez para testar outras combinações de encoders e scalers (se necessário).\n",
    "\n",
    "Agora que sabemos o que fazer, vamos descobrir quais métricas devemos superar.\n",
    "Para tal, vamos calcular o **recall** e **f1_weighted** das predições do modelo atual, \n",
    "assim como ganhos e perdas que tais predições geram. Segue como cada uma será\n",
    "calculada:\n",
    "\n",
    "- Perdas: o valor de compra de todos os falsos negativos (fraudes identificadas como compras legítimas) serão somadas.\n",
    "- Lucro Bruto: o valor de todos os verdadeiros negativos (compras legítimas não identificadas como fraude).\n",
    "- Lucro líquido: Lucro Bruto - Perdas\n",
    "\n",
    "Eu também poderia acrescentar os falsos positivos (compras legítimas \n",
    "identificadas como fraudulentas), mas como não sei se a compra é cancelada de\n",
    "vez ou aguarda confirmação adicional por parte do cliente, optarei por não\n",
    "incluir esses valores.\n",
    "\n",
    "As métricas serão calculadas a partir dos dados de **teste**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o local para salvar os exoerimentos\n",
    "mlflow.set_tracking_uri('../mlruns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divindo os dados em treino, dev e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x,\n",
    "                                                        y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=rs)\n",
    "\n",
    "x_dev, x_teste, y_dev, y_teste = train_test_split(x_teste, \n",
    "                                                  y_teste,\n",
    "                                                  stratify=y_teste,\n",
    "                                                  test_size=0.5,\n",
    "                                                  random_state=rs)\n",
    "\n",
    "# Dividindo features numéricas de categóricas\n",
    "cat_cols_high_dim = [\"pais\", \"categoria_produto\"]\n",
    "cat_cols = [col for col in x_treino.select_dtypes(\"object\").columns if col not in cat_cols_high_dim]\n",
    "num_cols = x_treino.select_dtypes([\"int\", \"float\"]).columns\n",
    "\n",
    "# Setando o KFold\n",
    "kf = StratifiedKFold(shuffle=True, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os dados de métricas\n",
    "data_metrics = data_fraud.loc[y_teste.index, [\"valor_compra\", \"score_fraude_modelo\", \"fraude\"]]\n",
    "\n",
    "# Criando uma label com base nos scores do modelo\n",
    "data_metrics[\"label_fraude_modelo\"] = data_metrics[\"score_fraude_modelo\"].apply(lambda score: 1 if score >= 50 else 0)\n",
    "\n",
    "# Reduzindo o score para a escala entre 0 e 1\n",
    "data_metrics[\"score_fraude_modelo\"] = data_metrics[\"score_fraude_modelo\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor_compra</th>\n",
       "      <th>score_fraude_modelo</th>\n",
       "      <th>fraude</th>\n",
       "      <th>label_fraude_modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111828</th>\n",
       "      <td>6.39</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53621</th>\n",
       "      <td>10.41</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29541</th>\n",
       "      <td>9.98</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122478</th>\n",
       "      <td>14.10</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73542</th>\n",
       "      <td>479.30</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        valor_compra  score_fraude_modelo  fraude  label_fraude_modelo\n",
       "111828          6.39                 0.87       0                    1\n",
       "53621          10.41                 0.90       0                    1\n",
       "29541           9.98                 0.19       0                    0\n",
       "122478         14.10                 0.56       0                    1\n",
       "73542         479.30                 0.86       0                    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com o threshold base (50%), o recall é de:  0.7608888888888888\n",
      "Com o threshold base (50%), o f1-score weighted é de:  0.6586582569846577\n",
      "Com o threshold base (50%), as perdas são de:  12690.34\n",
      "Com o threshold base (50%), os ganhos bruto são de:  42153.344000000005\n",
      "Com o threshold base (50%), os ganhos líquidos são de:  29463.004000000004\n"
     ]
    }
   ],
   "source": [
    "# Calculando as métricas\n",
    "recall = recall_score(data_metrics[\"fraude\"], data_metrics[\"label_fraude_modelo\"])\n",
    "f1_weighted = f1_score(data_metrics[\"fraude\"], data_metrics[\"label_fraude_modelo\"], average=\"weighted\")\n",
    "perdas = data_metrics.query(\"fraude == 1 and label_fraude_modelo == 0\")[\"valor_compra\"].sum()\n",
    "ganhos_brutos = (data_metrics.query(\"fraude == 0 and label_fraude_modelo == 0\")[\"valor_compra\"] * 0.10).sum()\n",
    "ganhos_liquidos = ganhos_brutos - perdas\n",
    "\n",
    "print(\"Com o threshold base (50%), o recall é de: \", recall)\n",
    "print(\"Com o threshold base (50%), o f1-score weighted é de: \", f1_weighted)\n",
    "print(\"Com o threshold base (50%), as perdas são de: \", perdas)\n",
    "print(\"Com o threshold base (50%), os ganhos bruto são de: \", ganhos_brutos)\n",
    "print(\"Com o threshold base (50%), os ganhos líquidos são de: \", ganhos_liquidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAADFUUlEQVR4nOzdd1yVZRvA8d8ZcNggMmUqKCpu3HujqWmuSnM03Ku0TCsrW74tKxtqpWmOzJVZuVcqmhsHKgoyXICAbJnnef/g9bwhqIjgAby+n8/5KPezrufh5pznOvd4VIqiKAghhBBCCCGEuCu1sQMQQgghhBBCiPJOEichhBBCCCGEuA9JnIQQQgghhBDiPiRxEkIIIYQQQoj7kMRJCCGEEEIIIe5DEichhBBCCCGEuA9JnIQQQgghhBDiPiRxEkIIIYQQQoj7kMRJCCGEEEIIIe5DEichHkMqlYp3333X8POSJUtQqVRERkYaLabSUtJzufOaiEfP29ubkSNHlnjb3r17l25AD2jkyJF4e3sbNYaSioyMRKVSsWTJEkPZu+++i0qlKrBebm4u06dPx8PDA7VaTb9+/R5toBXc7feno0ePGjsUoGziKe7fQVF1TojyThInIUrZ7Q+i2y+tVoubmxsjR47k6tWrxg6v1N3+8Lv90mg0eHp68tRTTxEcHGzs8Cq9f1/7f79cXFwM61y/fp0ZM2bQqVMnrK2tUalU7Nmzp1j7Hz9+PGq1msTExALliYmJqNVqdDodmZmZBZZdunQJlUrFG2+88dDnV9rOnj3Lu+++Wym+JDCGxYsX8+mnnzJw4ECWLl3KK6+8YuyQ7mrTpk1G+zLku+++k4RAiEpIa+wAhKis3nvvPapXr05mZib//PMPS5YsYf/+/Zw5cwYzMzNjh1fqnn32WZ544gny8vI4d+4c8+fPZ/Pmzfzzzz80atTokcUxbNgwnnnmGXQ63QNtd+vWLbTaivmW2K1bN4YPH16gzNzc3PD/0NBQPv74Y2rWrEn9+vU5ePBgsffdtm1b5s+fT1BQEH369DGUHzhwALVaTU5ODkePHqVt27aGZUFBQYZtH0RoaChqddl+n3f27Flmz55Nx44dK2zr0KPy1ltvMWPGjAJlu3btws3NjS+++MJIURXfpk2b+Pbbb42SPH333Xc4ODiUuAVVCFE+Vcy7BCEqgJ49e9K0aVMAXnrpJRwcHPj444/ZuHEjgwcPNnJ0pa9JkyY899xzhp/btGnDk08+yfz581m4cGGR26Snp2NpaVmqcWg0GjQazQNvV5GT2Vq1ahW49ncKCAggISEBe3t71q5dy6BBg4q979vJz/79+wskTkFBQTRo0IBbt26xf//+AknS/v37UavVtG7d+oHO40GTXVG2tFptoS8T4uLisLOzK7VjKIpCZmZmgURfFE2ulRDGJ131hHhE2rVrB0B4eHiB8vPnzzNw4EDs7e0xMzOjadOmbNy4sdD2SUlJvPLKK3h7e6PT6XB3d2f48OHEx8cDkJ2dzdtvv01AQAC2trZYWlrSrl07du/eXfYnV4TOnTsDEBERAfy/C+Pff//N+PHjcXJywt3d3bD+5s2badeuHZaWllhbW9OrVy9CQkIK7ff8+fMMHjwYR0dHzM3N8fPz48033zQsL2qM09GjRwkMDMTBwQFzc3OqV6/OCy+8UGC/RY1xOnHiBD179sTGxgYrKyu6dOnCP//8U2Cd28cLCgpi6tSpODo6YmlpyVNPPcWNGzeKda2KWwdKytraGnt7+xJt6+npiYeHh6EV6bagoCDatGlD69ati1zm7+9vuMHOysrinXfewdfXF51Oh4eHB9OnTycrK6vAdkWNcTp16hQdOnTA3Nwcd3d3PvjgA3766ae7jmPbv38/zZs3x8zMjBo1avDzzz8bli1ZssSQNHbq1MnQrfHf3RaLWw83bNhAvXr1MDMzo169evz222/3u5QFFOc4I0eOxMrKiujoaHr37o2VlRVubm58++23AJw+fZrOnTtjaWmJl5cXK1euLNaxk5KSGDlyJLa2ttjZ2TFixAiSkpIKrffvMU63u+Tu3r2bkJCQQtdOr9fz5Zdf4u/vj5mZGc7OzowZM4abN28W2OftsWhbt26ladOmmJubG75YSUpK4uWXX8bDwwOdToevry8ff/wxer3esP3tOD777DO+//57fHx80Ol0NGvWjCNHjhS4drev07+7sN5W3HiL895xJ29vb0JCQvj7778Nx+3YsWOBdbKysu77fvGw1wpg1apVBAQEYG1tjY2NDfXr1+err74qFHNx4oH8ljR/f390Oh3VqlVjwoQJRdadOxW3zsXExPD888/j7u6OTqfD1dWVvn37StdaUW5Ii5MQj8jtN/4qVaoYykJCQmjTpg1ubm7MmDEDS0tLVq9eTb9+/Vi3bh1PPfUUAGlpabRr145z587xwgsv0KRJE+Lj49m4cSNXrlzBwcGBlJQUfvzxR5599llGjRpFamoqixYtIjAwkMOHDz/S7nLw/wSxatWqBcrHjx+Po6Mjb7/9Nunp6QAsW7aMESNGEBgYyMcff0xGRgbz58+nbdu2nDhxwtCl6tSpU7Rr1w4TExNGjx6Nt7c34eHh/PHHH3z44YdFxhEXF0f37t1xdHRkxowZ2NnZERkZyfr16+8Zf0hICO3atcPGxobp06djYmLCwoUL6dixI3///TctWrQosP6kSZOoUqUK77zzDpGRkXz55ZdMnDiRX3/99b7HKU4duJfMzExDAn2btbV1qbXgtG3blvXr15OVlYVOpyM7O5sjR44wbtw4MjIymD59OoqioFKpuHnzJmfPnmXs2LFA/g3qk08+yf79+xk9ejR16tTh9OnTfPHFF1y4cIENGzbc9bhXr141JDgzZ87E0tKSH3/88a7nFRYWxsCBA3nxxRcZMWIEixcvZuTIkQQEBODv70/79u2ZPHky8+bN44033qBOnToAhn+LWw+3bdvGgAEDqFu3LnPmzCEhIcFws1ccxT0OQF5eHj179qR9+/Z88sknrFixgokTJ2Jpacmbb77J0KFD6d+/PwsWLGD48OG0atWK6tWr3/XYiqLQt29f9u/fz9ixY6lTpw6//fYbI0aMuGfMjo6OLFu2jA8//JC0tDTmzJlT4NqNGTOGJUuW8PzzzzN58mQiIiL45ptvOHHiBEFBQZiYmBj2FRoayrPPPsuYMWMYNWoUfn5+ZGRk0KFDB65evcqYMWPw9PTkwIEDzJw5k+vXr/Pll18WiGflypWkpqYyZswYVCoVn3zyCf379+fSpUuYmJgwZswYrl27xvbt21m2bFmh8ylOvCV97/jyyy+ZNGkSVlZWhi91nJ2dC6xT3PeLh7lW27dv59lnn6VLly58/PHHAJw7d46goCCmTJnywPG8++67zJ49m65duzJu3DhCQ0OZP38+R44cKfQ7/rcHqXMDBgwgJCSESZMm4e3tTVxcHNu3byc6Olq61oryQRFClKqffvpJAZQdO3YoN27cUC5fvqysXbtWcXR0VHQ6nXL58mXDul26dFHq16+vZGZmGsr0er3SunVrpWbNmoayt99+WwGU9evXFzqeXq9XFEVRcnNzlaysrALLbt68qTg7OysvvPBCgXJAeeeddwrFHBER8cDnGxERoQDK7NmzlRs3bigxMTHKnj17lMaNGyuAsm7dugLHaNu2rZKbm2vYPjU1VbGzs1NGjRpVYL8xMTGKra1tgfL27dsr1tbWSlRUVJHXoKhz+e233xRAOXLkyD3P485r0q9fP8XU1FQJDw83lF27dk2xtrZW2rdvX+h4Xbt2LRDHK6+8omg0GiUpKemexy1uHbhX3EW9fvrppyLXX7NmjQIou3fvvu++b/v2228VQNm3b5+iKIpy8OBBBVCioqKUs2fPKoASEhKiKIqi/PnnnwqgrFixQlEURVm2bJmiVqsN2962YMECBVCCgoIMZV5eXsqIESMMP0+aNElRqVTKiRMnDGUJCQmKvb19ofrq5eWlAMrevXsNZXFxcYpOp1OmTZt23/N/kHrYqFEjxdXVtcDvdtu2bQqgeHl53eNKPthxRowYoQDKRx99ZCi7efOmYm5urqhUKmXVqlWG8vPnzxeqw0XZsGGDAiiffPKJoSw3N1dp165doXrzzjvvKHfeJnTo0EHx9/cvULZv374Cv/PbtmzZUqj89u9py5YtBdZ9//33FUtLS+XChQsFymfMmKFoNBolOjpaUZT/v99UrVpVSUxMNKz3+++/K4Dyxx9/GMomTJhQKP4Hibe47x1F8ff3Vzp06FCo/EHeLx72Wk2ZMkWxsbEp8H5b0nji4uIUU1NTpXv37kpeXp5hvW+++UYBlMWLFxvKRowYUeDvoLh17ubNmwqgfPrpp3eNVwhjk656QpSRrl274ujoiIeHBwMHDsTS0pKNGzcavpVOTExk165dDB48mNTUVOLj44mPjychIYHAwEAuXrxomIVv3bp1NGzYsMjWh9vdTzQaDaampkD+t/yJiYnk5ubStGlTjh8/Xubn+8477+Do6IiLiwsdO3YkPDycjz/+mP79+xdYb9SoUQXGIG3fvp2kpCSeffZZwzWIj49Ho9HQokULQ1fDGzdusHfvXl544QU8PT0L7PPOKZP/7XZ3sT///JOcnJxinUteXh7btm2jX79+1KhRw1Du6urKkCFD2L9/PykpKQW2GT16dIE42rVrR15eHlFRUXc9zoPUgXvp27cv27dvL/AKDAws1rkWx7/HOUF+Vzw3Nzc8PT2pXbs29vb2hu56d04MsWbNGurUqUPt2rUL/H5vd+W8V1fSLVu20KpVqwKtpfb29gwdOrTI9evWrWvoEgv5rSR+fn5cunTpvudY3Hp4/fp1goODGTFiBLa2tobtu3XrRt26dUvtOP/20ksvGf5vZ2eHn58flpaWBcZK+vn5YWdnd99z3bRpE1qtlnHjxhnKNBoNkyZNum/sd7NmzRpsbW3p1q1bgXMKCAjAysqq0DlVr169UP1cs2YN7dq1o0qVKgX20bVrV/Ly8ti7d2+B9Z9++ukCrfe3f+/F+V0XN96SvHcUV3HfLx7mWtnZ2ZGens727dsfOp4dO3aQnZ3Nyy+/XGACl1GjRmFjY8Nff/11130Xt86Zm5tjamrKnj17CnWZFKK8kK56QpSRb7/9llq1apGcnMzixYvZu3dvgS5GYWFhKIrCrFmzmDVrVpH7iIuLw83NjfDwcAYMGHDfYy5dupTPP/+c8+fPF/igv1fXndIyevRoBg0ahFqtxs7OztAP/k53xnLx4kXg/2Oi7mRjYwP8/4aoXr16DxRXhw4dGDBgALNnz+aLL76gY8eO9OvXjyFDhty1y9eNGzfIyMjAz8+v0LI6deqg1+u5fPky/v7+hvI7k7nbN3X3ugF4kDpwL+7u7nTt2vWe6zyMevXqYWdnVyA5atOmDZCftLZq1YqgoCBGjRpFUFAQHh4ehutx8eJFzp07h6OjY5H7jouLu+txo6KiaNWqVaFyX1/fIte/83cA+b+H4tyEFbce3r6RrFmzZqF1/Pz87vslRXGPc5uZmVmha2dra4u7u3uhLwxsbW3ve65RUVG4urpiZWVVKPaSunjxIsnJyTg5ORW5/M7fcVHvRxcvXuTUqVPFricl+Xt70HhL8t5RXMWN/2Gu1fjx41m9ejU9e/bEzc2N7t27M3jwYHr06PHA8dyu93fWE1NTU2rUqHHPL4iKW+d0Oh0ff/wx06ZNw9nZmZYtW9K7d2+GDx9e4PEKQhiTJE5ClJHmzZsbZtXr168fbdu2ZciQIYSGhmJlZWUYxPvqq6/etXXgbjeIRVm+fDkjR46kX79+vPbaazg5OaHRaJgzZ06hCSnKQs2aNYt1837njFC3r8OyZcuK/HB82CnCVSoVa9eu5Z9//uGPP/5g69atvPDCC3z++ef8888/hT7MS+puM/kpinLXbUq7DpQVtVpNq1atOHDgAIqiEBQUVOAZTa1bt2bx4sWGsU//fiiqXq+nfv36zJ07t8h9e3h4lFqcJfkd3FbW9bCkx7nbOT3MuZY2vV6Pk5MTK1asKHL5nTf4Rc0Kp9fr6datG9OnTy9yH7Vq1Srw88P+rosTb1m+dxQ3/oe5Vk5OTgQHB7N161Y2b97M5s2b+emnnxg+fDhLly4tUTxl7eWXX6ZPnz5s2LCBrVu3MmvWLObMmcOuXbto3LjxI41FiKJI4iTEI3A7genUqRPffPMNM2bMMHQBMzExuW/C4ePjw5kzZ+65ztq1a6lRowbr168v8E30O++88/AnUIZ8fHyA/A/5e12H29frftfhblq2bEnLli358MMPWblyJUOHDmXVqlUFukHd5ujoiIWFBaGhoYWWnT9/HrVaXSo3/A9SB4ytbdu2bN68mY0bNxIXF2docYL8xOnNN99k06ZN3Lp1q8DU5D4+Ppw8eZIuXbrcs0tlUby8vAgLCytUXlRZcd0thuLWQy8vL+D/LUf/VlR9KelxyoqXlxc7d+4kLS2twI1/cWK/Gx8fH3bs2EGbNm1KPFW2j48PaWlppXpN7vW7fpB4H+S9437HLg0Pcq1MTU3p06cPffr0Qa/XM378eBYuXMisWbMe6EuZ2/U+NDS0QPfl7OxsIiIi7vs38yB1zsfHh2nTpjFt2jQuXrxIo0aN+Pzzz1m+fHmx4xWirMgYJyEekY4dO9K8eXO+/PJLMjMzcXJyomPHjixcuJDr168XWv/fU8EOGDCAkydPFjnl8e1vBG9/Y/jvbwgPHTr0QA87NYbAwEBsbGz46KOPihxHcPs6ODo60r59exYvXkx0dHSBde71rejNmzcLLb89ZubO6bBv02g0dO/end9//73ANLixsbGsXLmStm3bFupSVRIPUgeM7XYy9PHHH2NhYVFg3FHz5s3RarV88sknBdYFGDx4MFevXuWHH34otM9bt24ZZlYsSmBgIAcPHiQ4ONhQlpiYeNeWguK4/dywO6dCLm49dHV1pVGjRixdupTk5GTD8u3bt3P27Nn7Hr+4xykrTzzxBLm5ucyfP99QlpeXx9dff13ifQ4ePJi8vDzef//9Qstyc3OLNV314MGDOXjwIFu3bi20LCkpidzc3AeO626/6+LGW5L3jn8fuzjnXRLFvVYJCQkFlqnVaho0aADcP/47de3aFVNTU+bNm1fgmixatIjk5GR69ep1122LW+cyMjLIzMwsUObj44O1tfUDxytEWZEWJyEeoddee41BgwaxZMkSxo4dy7fffkvbtm2pX78+o0aNokaNGsTGxnLw4EGuXLnCyZMnDdvdfnDpCy+8QEBAAImJiWzcuJEFCxbQsGFDevfuzfr163nqqafo1asXERERLFiwgLp165KWlvbAsd6eqvenn34q9Gyd0mRjY8P8+fMZNmwYTZo04ZlnnsHR0ZHo6Gj++usv2rRpwzfffAPAvHnzaNu2LU2aNGH06NFUr16dyMhI/vrrrwI31/+2dOlSvvvuO5566il8fHxITU3lhx9+wMbGhieeeOKucX3wwQds376dtm3bMn78eLRaLQsXLiQrK8uQIJSG4taBh/XBBx8AGJ4VtGzZMsNkD2+99dZ9t2/evDmmpqYcPHiQjh07FuhSZmFhQcOGDTl48CB2dnYFxqENGzaM1atXM3bsWHbv3k2bNm3Iy8vj/PnzrF692vCMmqJMnz6d5cuX061bNyZNmmSYjtzT05PExMQSfavfqFEjNBoNH3/8McnJyeh0Ojp37oyTk1Ox6+GcOXPo1asXbdu25YUXXiAxMZGvv/4af3//+/6tPUh9Lwt9+vShTZs2zJgxg8jISOrWrcv69esLJIEPqkOHDowZM4Y5c+YQHBxM9+7dMTEx4eLFi6xZs4avvvqKgQMH3nMfr732Ghs3bqR3796GKeTT09M5ffo0a9euJTIyEgcHhweKKyAgAIDJkycTGBiIRqPhmWeeKXa8JX3vuH3s+fPn88EHH+Dr64uTk9Ndx7U9qOJeq5deeonExEQ6d+6Mu7s7UVFRfP311zRq1MgwjXxxOTo6MnPmTGbPnk2PHj148sknCQ0N5bvvvqNZs2b3fAB3cevchQsX6NKlC4MHD6Zu3bpotVp+++03YmNjeeaZZ0p0rYQodUaYyU+ISu329K5FTWGbl5en+Pj4KD4+PoYpYsPDw5Xhw4crLi4uiomJieLm5qb07t1bWbt2bYFtExISlIkTJypubm6Kqamp4u7urowYMUKJj49XFCV/CuuPPvpI8fLyUnQ6ndK4cWPlzz//LDQ1rKIUbzryr7/+usipcO90e3rg+00he6/roiiKsnv3biUwMFCxtbVVzMzMFB8fH2XkyJHK0aNHC6x35swZ5amnnlLs7OwUMzMzxc/PT5k1a9Zdz+X48ePKs88+q3h6eio6nU5xcnJSevfuXWi/d16T29sGBgYqVlZWioWFhdKpUyflwIEDxTqv3bt3F3va7+LWgaIAyoQJE4q13t1exdWqVSsFUN54441CyyZPnqwASs+ePQsty87OVj7++GPF399f0el0SpUqVZSAgABl9uzZSnJysmG9O6cjVxRFOXHihNKuXTtFp9Mp7u7uypw5c5R58+YpgBITE1Ng2169ehU6docOHQpNC/3DDz8oNWrUUDQaTaHfUXHr4bp165Q6deooOp1OqVu3rrJ+/foi/9bupjjHGTFihGJpaVnkOd05Jfi9rsGdEhISlGHDhik2NjaKra2tMmzYMOXEiRMlno78tu+//14JCAhQzM3NFWtra6V+/frK9OnTlWvXrhUrxtTUVGXmzJmKr6+vYmpqqjg4OCitW7dWPvvsMyU7O1tRlHu/39z5N5ybm6tMmjRJcXR0VFQqVaFzuV+8xX3vKEpMTIzSq1cvxdraWgEMdfBB3i8e9lqtXbtW6d69u+Lk5KSYmpoqnp6eypgxY5Tr168b9vOg71/ffPONUrt2bcXExERxdnZWxo0bp9y8ebPAOkX9HRSnzsXHxysTJkxQateurVhaWiq2trZKixYtlNWrV9/jSgvxaKkUxQgjSYUQ5d7gwYOJjIzk8OHDxg5FiAJefvllFi5cSFpa2l0HtQshhBClTbrqCSEKURSFPXv2yGBcYXS3bt0qMIA/ISGBZcuW0bZtW0mahBBCPFLS4iSEEKLcatSoER07dqROnTrExsayaNEirl27xs6dO2nfvr2xwxNCCPEYkRYnIYQQ5dYTTzzB2rVr+f7771GpVDRp0oRFixZJ0iSEEOKRkxYnIYQQQgghhLgPeY6TEEIIIYQQQtyHJE5CCCGEEEIIcR+P3RgnvV7PtWvXsLa2LtHDE4UQQgghhBCVg6IopKamUq1aNdTqe7cpPXaJ07Vr1/Dw8DB2GEIIIYQQQohy4vLly7i7u99znccucbK2tgbyL46NjY2Ro4GcnBy2bdtG9+7dMTExMXY4ooKQeiNKQuqNKCmpO6IkpN6IknjU9SYlJQUPDw9DjnAvj13idLt7no2NTblJnCwsLLCxsZE3FVFsUm9ESUi9ESUldUeUhNQbURLGqjfFGcIjk0MIIYQQQgghxH1I4iSEEEIIIYQQ9yGJkxBCCCGEEELchyROQgghhBBCCHEfkjgJIYQQQgghxH1I4iSEEEIIIYQQ9yGJkxBCCCGEEELchyROQgghhBBCCHEfkjgJIYQQQgghxH1I4iSEEEIIIYQQ9yGJkxBCCCGEEELchyROQgghhBBCCHEfkjgJIYQQQgghxH1I4iSEEEIIIYQQ92HUxGnv3r306dOHatWqoVKp2LBhw3232bNnD02aNEGn0+Hr68uSJUvKPE4hhBBCCCHE482oiVN6ejoNGzbk22+/Ldb6ERER9OrVi06dOhEcHMzLL7/MSy+9xNatW8s4UiGEEEIIIcTjTGvMg/fs2ZOePXsWe/0FCxZQvXp1Pv/8cwDq1KnD/v37+eKLLwgMDCyrMMtMZk4e83eHUy3X2JEIIYQQQggh7sWoidODOnjwIF27di1QFhgYyMsvv3zXbbKyssjKyjL8nJKSAkBOTg45OTllEmdxTVhxgp3nb9DcUU0fI8ciKpbbddfYdVhULFJvRElJ3RElIfVGlMSjrjcPcpwKlTjFxMTg7OxcoMzZ2ZmUlBRu3bqFubl5oW3mzJnD7NmzC5Vv27YNCwuLMou1OPw1sAsNh2+o+XTVDhpVVYwaj6h4tm/fbuwQRAUk9UaUlNQdURJSb0RJPKp6k5GRUex1K1TiVBIzZ85k6tSphp9TUlLw8PCge/fu2NjYGDGyfJlbQ/l+fxTrL+t4sW9rnG3MjB2SqABycnLYvn073bp1w8TExNjhiApC6o0oKak7oiSk3oiSeNT15nZvtOKoUImTi4sLsbGxBcpiY2OxsbEpsrUJQKfTodPpCpWbmJiUiz/iKV1qsvlEJJfTc5m54SxLn2+OWq0ydliigigv9VhULFJvRElJ3RElIfVGlMSjqjcPcowK9RynVq1asXPnzgJl27dvp1WrVkaK6OGZatUMq5mHmYmafRfjWXow0tghCSGEEEIIIe5g1MQpLS2N4OBggoODgfzpxoODg4mOjgbyu9kNHz7csP7YsWO5dOkS06dP5/z583z33XesXr2aV155xRjhlxpnc5gRWAuAOZvPcyE21cgRCSGEEEIIIf7NqInT0aNHady4MY0bNwZg6tSpNG7cmLfffhuA69evG5IogOrVq/PXX3+xfft2GjZsyOeff86PP/5YIaciv9OQ5h509HMkO1fPlFXBZOXmGTskIYQQQgghxP8YdYxTx44dUZS7zyS3ZMmSIrc5ceJEGUZlHCqVik8GNqDHl/s4dz2FudsuMPOJOsYOSwghhBBCCEEFG+NU2TlZm/Gf/vUB+H7fJQ6GJxg5IiGEEEIIIQRI4lTudPd34dnmHigKTFsdTPIteWicEEIIIYQQxiaJUzn0Vq+6eFe14FpyJt2/+Jt5Oy8Sl5pp7LCEEEIIIYR4bEniVA5Z6rR8/WwTnKx1xKZkMXf7Bdr8ZxdTVp3gWNTNe44LE0IIIYQQQpS+CvUA3MdJfXdb9r/emc1nrvPzwSiORd3k9+Br/B58Df9qNoxo5U1gPRdszeWBckIIIYQQQpQ1SZzKMVOtmr6N3OjbyI0zV5NZeiCS309eI+RaCtPXnWL6ulPUcLSkkbsdDT3yX3VcrdFpNcYOXQghhBBCiEpFEqcKop6bLZ8OasgbT9Th16OXWX3kMpfi07l0I/+1/sRVAEw0Kuq62tDU2542vlVpXr0qVjr5NQshhBBCCPEw5I66gqliacrYDj6M7eBDYno2J68kcfJy/iv4chI3M3I4eSWZk1eSWbQ/Aq1aRSMPO1r7OtDGpyqNPatgqpWhbUIIIYQQQjwISZwqMHtLUzr5OdHJzwkARVG4cvMWx6Nv8s+lBILCEohOzOBo1E2ORt1k3s6LmJtoaFvTgQFN3OhU20m69QkhhBBCCFEMkjhVIiqVCg97CzzsLejbyA2Ay4kZBIXFsz8snoPhCSSkZ7P9bCzbz8ZiZ2FCnwbV6N/EjUYedqhUKiOfgRBCCCGEEOWTJE6VnIe9Bc809+SZ5p7o9QrnYlLYePIaG05cJTYli2X/RLHsnyhqOFoyoIk7/Rq74WZnbuywhRBCCCGEKFckcXqMqNUq/KvZ4l/NlumBtQkKi2f98StsCYnh0o10Pt0aymfbQmlVoyr9m7jTs54LljKxhBBCCCGEEJI4Pa40ahXtaznSvpYjqZk5bD4Tw7pjVzgUkciB8AQOhCcwa8MZetZzYUCAOy1rVEWjlq58QgghhBDi8SSJk8DazITBTT0Y3NSDy4kZbDhxlXXHrxCZkMH6E1dZf+IqrrZm9G3kRs96LjRwt5XxUEIIIYQQ4rEiiZMowMPegkldajKxsy/Ho5NYf/wKf5y8xvXkTBb8Hc6Cv8NxtTWje11nAv1daF7dHq1GpjcXQgghhBCVmyROokgqlYoAryoEeFVhVu+67DwXx6bT19kdGsf15EyWHoxi6cEo7CxM6FLbmZ71XOhc2wm1dOcTQgghhBCVkCRO4r7MTDT0auBKrwauZObkERQWz9aQGHaciyMxPZt1x6+w7vgVartY82p3P7rUcZKufEIIIYQQolKRxEk8EDMTDV3qONOljjO5eXqORt1ky5kY1h2/wvmYVF76+ShNPO14LbA2rXyqGjtcIYQQQgghSoUMThElptWoaVmjKu8+6c++6Z0Y28EHMxM1x6OTePaHfxi26BCnryQbO0whhBBCCCEemiROolTYWZgyo2dt9r7WiedaeqJVq9h3MZ4+3+xn/Ipj/H3hBtm5emOHKYQQQgghRIlIVz1RqpxszPigX31Gt/Phix0X2BB8lU2nY9h0OgZrMy2dazsR6O9Ch1qO8nBdIYQQQghRYcidqygTnlUt+OLpRozpUINlB6PYdjaWG6lZ/B58jd+Dr2GqVdPO14HAei4E+rtga25i7JCFEEIIIR4rufpcUrJTSMtOQ68U3TNIQUGv6MnV55Kn5JGnzyNPySNXn0uukkt2XjZZeVn5r9wsMvMyC/yclZfFrdxbhrLM3PzlmXmZLOy6ECtTq0d81iUniZMoU7VdbPjwqfq837ceJy7fZGtILFtDYohKyGDn+Th2no/jrQ1n6FbHmQEBbrSr6YiJPBdKCCGEEOKhKIpCXEYc5xLPcTbhLGFJYSRnJZOSnWL4Nz0n3agxZuRmSOIkxJ3UahUBXvYEeNkzs2dtQmNT2Xomlk2nrxMam8pfp6/z1+nrOFiZ0reRG/2buOFfzdbYYQshhBBClHuZuZlcS7tGREoEZxPOci4hP1lKyEwo1vYWWgs0as1dl2tVWjRqDRqVBq1ai0alMfxsqjHFTGNm+Fen1aHT/P9lpjXL//d/y8w0+T/rtDqsTa1L6xI8EpI4iUdOpVJR28WG2i42TO7iS8i1FNYfv8rvwVeJT8tm0f4IFu2PoLaLNZM616RXA1djhyyEEEIIYVSZuZmEJYURnhTOlbQrXE29ypW0K1xJvcKNWzeK3EatUlPDtgZ1q9bFr4ofDuYO2OhssDW1xUZng42pDdam1mjVkhIUh1wlYVQqlYp6brbUc7Nl5hO12XvhBuuOX2HH2TjOx6QyYeVxtoRU4/2+/thZmBo7XCGEEEKIMpeYmcj5xPOEJoYa/o1IibjrOCQASxNLPKw9qG1fm7pV61LHvg5+9n6Ya80fYeSVmyROotww0agND9dNzshh0f5LfLsnnD9OXuPQpQQ+HtiATn5Oxg5TCCGEEKJUxWXEcTjmMIevH+ZwzGGupl0tcj17M3tq2tXE3do9/2X1/39tdbaoVKpHHPnjRRInUS7ZWpgwtbsfXeo488rqYC7dSOf5n47wbHNP3upVR6YyF0IIIUSFlXArgaOxRw2JUmRKZKF1vGy88KviR2372vjZ5//raO4oyZERyd2nKNcaetixaXI7Pt5ynp+CIvnlcDT7w27w+aBGNK9ub+zwhBBCCCHuKU+fR1hSGCdvnCQ4LpjgG8FcTr1cYB0VKupUrUNzl+Y0d2lOY6fGFWq2uceFJE6i3DMz0fBOH3+61XXmtTWnuJx4i6e/P8i4Dj5M7VYLrUxfLoQQQohyIjkrmdPxpzl54yQn405yKv5UkdN+16xS05AoBTgHYKuT2YTLO0mcRIXR2seBzS+34/0/zrLm2BW+2xPOqSvJzHu2MfaWMnGEEEIIIR4tvaInPCk8P0n63ysiOaLQehZaCxo4NqCRUyMaOTaivmN9bExtjBCxeBiSOIkKxcbMhE8HNaR9LUemrz3F/rB4+ny9n4XDAqjnJt/UCCGEEKLs5OpzOZ94nqMxRzkSe4QTsSdIzUkttJ6XjRcNHBrQ0LEhjZwa4Wvne8/nJImKQRInUSH1aViNms5WjFl2jKiEDAbMP8CHT9VnYIC7sUMTQgghRCWhV/SExIdwOOYwR2OPciLuRKFud+Zac+o71KehY0MaOjakgWMDqphVMVLEoixJ4iQqrNouNmyc2JZXfg1m1/k4Xl1zklNXknirV11MtTLuSQghhBAPTlEUTsefZkvkFrZFbiM2I7bAcmtTawKcA2jq3JSmLk3xq+InD5B9TMhvWVRotuYm/Di8KV/tvMhXOy/y88EoQq6l8N3QJjjbmBk7PCGEEEJUAIqicC7xnCFZ+vdzlCxNLGnh0oJmLs1o6tKUmnY1pdvdY0oSJ1HhqdUqXulWiwbutry8KphjUTfp/sVepnarxdAWnjLrnhBCCCEK0St6zsSfYWf0TnZE7SA6NdqwzFxrTkePjvTw7kEbtzboNDojRirKC0mcRKXRpY4zGye1ZcKK45y9nsI7G0NYcSiKd/r408bXwdjhCSGEEMLIcvW5HIs9xo6oHey6vIu4jDjDMjONGe3c29HDuwft3NthrjU3YqSiPJLESVQq1R0s2TixDb8cuczn20K5EJvG0B8PEejvzJtP1MWzqoWxQxRCCCHEI5STl8PB6wfZFrmNPVf2kJyVbFhmobWgnXs7unh2oYN7ByxM5D5B3J0kTqLS0WrUDGvpRZ8Grny54yLL/olia0gsu0NvMKpddcZ39MVSJ1VfCCGEqKxy9Dkcvn6YLZFb2Bm9k9Ts/08ZXkVXhY4eHenq1ZUWri2kG54oNrl7FJWWnYUp7z7pz5AWnrz3x1n2h8Xz7e5w1h27yuy+/gT6uxg7RCGEEEI8gOy8bGLTY++6/HLaZbZFbmNn9E6SspIM5Q7mDnTz6kY3r240dmoss+CJEpFaIyq9Ws7WLHuxOdvPxvLBX+eITsxgzLJjBPo7M/vJerjYyux7QgghRHmVnJXMvqv72B29m/1X95ORm1Gs7ezN7Onm1Y1A70CaODWRmfDEQ5PESTwWVCoV3f1daF/LkXk7L/L93ktsDYnlQFgC03v4MbSFF2q1ythhCiGEEAKISY9hV/Qudl/ezdGYo+QquYZlOo0OjaroJMjSxJL27u3pUb0HTZ2bSsuSKFVSm8RjxcxEw/QetenTsBoz158m+HISs34P4bcTV5nTvwF+LtbGDlEIIYR4bIUmhvLpkU85FHOoQLmPrQ+dPTvTyaMT/g7+qFXyqBHx6EniJB5LdVxtWDeuNcv/ieLTraEcj06i17x9jO/ow5SutdBI65MQQgjxyCRnJfP1ia9Zc2ENekWPChWNnRrTyaMTnTw74WXjZewQhZDESTy+NGoVI1p7093fmVkbQthxLpZ5u8KISszgs0ENMZEH5wohhBBlKk+fx7qL65h3Yp5hmvBA70CmBkylmlU1I0cnREGSOInHnqutOT8MD2BD8FVeW3OK34OvkZGdx9fPNsbMRAaSCiGEEGXheOxx5hyew/nE8wD42vnyRos3aObSzMiRCVE0SZyEIH/yiKcau2NrbsLY5cfZfjaWl5Ye5fvhAViYyp+JEEIIURoycjLYd3UfmyM2szN6JwDWptZMaDSBp/2elskcRLkmtVOIf+lc25klzzfjpaVH2R8Wz7BFh1k8shm25ibGDk0IIYSokG5m3iQoMoid0Ts5eO0g2fpsAFSo6F+zP5ObTMbezN7IUQpxf5I4CXGH1j4OLH+pBSMXH+ZY1E2G/PAPy15sgb2lqbFDE0IIISqEq2lX2RGxg7Wpa3n7t7fRK3rDMg9rD7p4dqF3jd742fsZMUohHowkTkIUoYlnFVaNbsWwRYcIuZbC0wsPsvylFjjbyMNyhRBCiDspisKFmxfYdXkXu6N3cy7xXIHldezr0NmzM108u+Br54tKJbPXiopHEich7qJuNRtWj23Fcz8e4mJcGv2/O0D/Jm608XWgsacdOq1MHCGEEOLxlavPJTgumF2Xd7ErehdX064alqlVaho7NsY5xZnx3cfjVUWmExcVnyROQtyDj6MVq8e0YuiPh4hOzODrXWF8vSsMMxM1zatXpY1PVdr4OlDX1Qa1PPtJCCFEJZdwK4Gga0Hsu7KPoGtBpGanGpbpNDpaVWtFF88udHDvgJXGik2bNsm04qLSkMRJiPvwsLfgz8lt2XI6hv1h8RwIjyc+LZu9F26w98INAKpamvJiu+o837o65qbSEiWEEKJyUBSFkIQQ9l3Zx94rewlJCEFBMSy31dnSzq0dXTy70LpaayxMLAzLcnJyjBGyEGVGEichisHGzITBzTwY3MwDRVEIjU0lKCyBA2Hx/HMpgYT0bD7ZEspPQZFM7uzL0808MdXKA3SFEEJUPHpFz6kbp9gWtY3tUduJSY8psLyOfR3aurWlvXt76jvUR6OWLwzF40ESJyEekEqloraLDbVdbHixbXVy8vT8cfIaX+y4wOXEW8z6PYQf9kXwSreaPNnQDY104RNCCFHO6RU9J2+cZFtkfrIUmxFrWGauNadNtTa0d29PG7c2OFk4GTFSIYxHEichHpKJRk3/Ju70blCNVUeimbczjOjEDF759SQL9lzi1UA/utZxkhmEhBBClCu3W5a2Rm5lW9Q24jLiDMssTSzp4N6B7t7daVOtDWZamVVWCEmchCglplo1w1t5MzDAnZ+CIln4dzihsamM+vkonWs78Z/+9XGS6cyFEEIYkaIonIr/X7IUua1Ay5KViRWdPDrRzasbrd1ao9PojBipEOWPJE5ClDILUy0TOvnyXAsvFuwNZ9G+CHadj6P7l3v5oF89ejeQ2YWEEEI8OoqicCb+DNuitrE1civX068bllmaWNLZozPdvbvTulprTDXysHch7kYSJyHKiK2FCa/3qE2/Rm5MXR1MyLUUJq48wbaQWN7r64+dhXw4CSGEKBv/nuBhR9SOAsmShdaCjh4dCfQOpI1bG2lZEqKYJHESooz5uVjz2/g2fL3rIt/tCWfjyWscikjg4wEN6OgnA2yFEEKUDr2i50TcCbZHbWd71PYCY5bMteZ0cO9AoHcgbd3aypglIUpAEichHgFTrZpp3f3oXNuJaatPcik+nZE/HWFIC09e71EbW3MTY4cohBCiAlIUhZM3ThrGLMXdKjjBQ0ePjnTz6iYTPAhRCiRxEuIRauxZhb8mt+PjLedZciCSlYei2XDiKk81dmN4K2/8XKyNHaIQQohyTlEUziaeZWvEVrZEbinQDc/axJpOnvkTPLSq1kq64QlRiiRxEuIRMzfV8O6T/nSr68zsP0K4EJvGikPRrDgUTcsa9oxo5U23us5oNfIAXSGEEP93OfUyG8M3sunSJqJTow3lt8cs9azeUyZ4EKIMSeIkhJG08XVg68vt+edSIj8fjGTb2Vj+uZTIP5cScbU1Y2gLTwYEuONqa27sUIUQQhhJRk4GO6J38NvF3zgae9RQbqYxo717e3pU70E7t3bSDU+IR0ASJyGMSKVS0cqnKq18qnIt6RYrD0Xzy+Foridn8tm2C3y27QIN3W3p7u9CoL8Lvk5Wxg5ZCCFEGVMUheAbwWwI28DWyK2k56QDoEJFS9eW9PXtSyePTliYWBg5UiEeL5I4CVFOVLMz59VAPyZ18WXT6eusPBTN0aibnLySzMkryXy6NRQfR0sC/V3o4ueAohg7YiGEEKVFURTOJZ5jW+Q2tkVt43LqZcMydyt3+vn240mfJ3G1cjVilEI83iRxEqKc0Wk1PNXYnacauxOXmsmOs3FsDYnhQHg84TfS+W5PON/tCcfBTENclSiebu4ls/IJIUQFdHuSh22R29gWuY0raVcMy8y15nTz6kY/334EOAegVsm4VyGMTRInIcoxJ2szhrTwZEgLT1Iyc9h9Po5tIbHsDo0jPjOPjzaH8sWOMJ5q4sbwVl7UdrExdshCCCHuIzwpnI3hG9kauZWraVcN5WYaM9q5t6O7V3fau7eXrnhClDOSOAlRQdiYmdC3kRt9G7mRlHaLj1ZuJzjNlgtxaaw8FM3KQ9G0qG7PiNb5s/KZyKx8QghRbiRlJrE5cjMbwzZyJuGModxca047t3Z08+5GezdJloQozyRxEqICstRpaeOs8MHIVhy/ksrPByPZGhLLoYhEDkUk4mlvwZu96tC9rjMqlcrY4QohxGMpR59D0NUgNoZvZPfl3eTqcwHQqrS0dW9L7xq9aefWTpIlISoISZyEqMBUKhUta1SlZY2qXE++ZWh5ik7MYMyyY7T1deDtPnWp5SwP1hVCiNIUmhjK2gtr2Ra1jYycjCLXyVVyDckSQG372jzp8yRPVH+CquZVH1WoQohSIomTEJWEq60507r7MbaDD/P3hPP9vkvsD4un51f7eK6FJ690q4WdhTwUUQghSiojJ4OtkVtZe2Etp+JPFWsbezN7etXoRV+fvvjZ+5VxhEKIsiSJkxCVjKVOy6uBfgxu6sFHm86xJSSGpQej+P3kNaZ1q8WzzT3RyvgnIYQottDEUNZcWMNfl/4iLScNyO9u18mzEwNqDsDb1rvI7VSocLJwQquW2y0hKgOj3z19++23eHt7Y2ZmRosWLTh8+PA91//yyy/x8/PD3NwcDw8PXnnlFTIzMx9RtEJUHJ5VLVgwLICVL7XAz9mapIwcZv0eQp9vggi5lmzs8IQQotzLzM1k9sHZDPxjIL+G/kpaThruVu683ORltg/aztyOc2nj1gY3K7ciX9WsqknSJEQlYtS/5l9//ZWpU6eyYMECWrRowZdffklgYCChoaE4OTkVWn/lypXMmDGDxYsX07p1ay5cuMDIkSNRqVTMnTvXCGcgRPnX2teBvya35ZfD0Xy+/QLnrqfQ79sgXu5aizHta0jrkxBCFOFS8iVe/ftVLt68iAoVXb26MqjWIFq4tpBnKgnxmDLqX/7cuXMZNWoUzz//PHXr1mXBggVYWFiwePHiItc/cOAAbdq0YciQIXh7e9O9e3eeffbZ+7ZSCfG402rUDGvlzY6pHQj0dyYnT+HTraEMWniQSzfSjB2eEEKUKxvDN/LMn89w8eZFqppVZWG3hcztOJdW1VpJ0iTEY8xoLU7Z2dkcO3aMmTNnGsrUajVdu3bl4MGDRW7TunVrli9fzuHDh2nevDmXLl1i06ZNDBs27K7HycrKIisry/BzSkoKADk5OeTk5JTS2ZTc7RjKQyyi4ihpvbHVqfn66QZsCL7Oe3+d50R0Ek/M28f07rUY2twDtVqmLq/M5P1GlNTjUndu5d7iP0f+wx8RfwDQzLkZH7b+EAdzh0p/7mXhcak3onQ96nrzIMdRKYqilGEsd3Xt2jXc3Nw4cOAArVq1MpRPnz6dv//+m0OHDhW53bx583j11VdRFIXc3FzGjh3L/Pnz73qcd999l9mzZxcqX7lyJRYW8twE8fi6mQUrw9VcSM7/9rSWrZ4hPnqq6IwcmBBCGEFMXgy/pv/KDf0NVKjobNaZDroO0sIkRCWXkZHBkCFDSE5OxsbG5p7rVqgRi3v27OGjjz7iu+++o0WLFoSFhTFlyhTef/99Zs2aVeQ2M2fOZOrUqYafU1JS8PDwoHv37ve9OI9CTk4O27dvp1u3bpiYmBg7HFFBlFa9eVavsOLwZT7ZdoELyfDRKS1NPe1o7VOVVjXs8a9mg0ZaoSoNeb8RJVWZ6050SjTrw9fz64VfydJn4WjuyEetPyLAOcDYoVV4lbneiLLzqOvN7d5oxWG0xMnBwQGNRkNsbGyB8tjYWFxcXIrcZtasWQwbNoyXXnoJgPr165Oens7o0aN58803UasLfyuk0+nQ6Qp/hW5iYlKu/ojLWzyiYiiNevNCOx861nbm1TUnOR6dxIFLiRy4lAiAjZmWVj5VaevrQCsfB2o4WEp3vkpA3m9ESVWWupOTl8PO6J2svbCWQzH/7+HSxq0NH7X9CHszeyNGV/lUlnojHq1HVW8e5BhGS5xMTU0JCAhg586d9OvXDwC9Xs/OnTuZOHFikdtkZGQUSo40Gg0ARupxKESlUMPRinXjWhN+I42gsAT2h8Xzz6UEUjJz2RoSy9aQ/C84bMy0NPSwo6G73f/+tcXJxszI0QshRPFEpUSx7sI6fg//ncTM/C+IVKho69aWgbUG0tGjo3TNE0LclVG76k2dOpURI0bQtGlTmjdvzpdffkl6ejrPP/88AMOHD8fNzY05c+YA0KdPH+bOnUvjxo0NXfVmzZpFnz59DAmUEKJkVCoVvk7W+DpZM6K1N7l5ek5fTeZAeAL7L8ZzPPomKZm57LsYz76L8YbtXG3NaOxpR896rnSr64yZifwtCiHKj9TsVLZFbuOPS39wLPaYodzJ3Imnaj5F/5r9qWZVzYgRCiEqCqMmTk8//TQ3btzg7bffJiYmhkaNGrFlyxacnZ0BiI6OLtDC9NZbb6FSqXjrrbe4evUqjo6O9OnThw8//NBYpyBEpaXVqGnsWYXGnlWY0MmXnDw9oTGpnLySxMnLSZy8nMyFuFSuJ2dy/XQMm07HYG2mpXcDVwY0cSfAqwoqlXTrE0I8ejn6HA5cPcAfl/5gd/RusvXZQH7rUhu3NgyqNYj27u3l4bRCiAdi9HeMiRMn3rVr3p49ewr8rNVqeeedd3jnnXceQWRCiH8z0aip52ZLPTdbhrbwAiA9K5czV5PZe/EGG05c42rSLX45fJlfDl/Gq6oFTzV246nGbnjaW0gSJYQoc6GJofwW9hubIzYbuuIB+Nj60NunN71r9MbFsuhx1EIIcT9GT5yEEBWXpU5LixpVaVGjKtO6+fFPRALrj19l0+nrRCVk8OWOi3y54yIqFViZarEy02Kp02Kl02Jtlv+vg5UOF1sznG3McLExw9lGh7OtGdY6rSRbQoj7ytXnsit6FyvOreB43HFDub2ZPU9Uf4I+Pn2oY19H3k+EEA9NEichRKlQq1W09nGgtY8D7/X1Z2tIDOuOXSUoPB5FgdSsXFKzcou9PwtTDeb3GC9lqlVjpft/Inb7/9ZmWix1Gqx0JljpNPnJ2v+SNiudFjMTDSW5fdKoVTha67A2k5mhhCgPbmbeZN3Fdaw6v4rYjPwJbDQqDV08u9DPtx+tqrWSrnhCiFIl7yhCiFJnYarlqcbuPNXYncycPFIyc0jLzCU9K4/UrBzSs/JIz8olJTOHG6lZxCRnEpOSSWxKJteTM0nNzCUjO4+M7Dxjn0ohlqYanG3zW8dcbG+3kpn9L2HTYn07mTP7fzKnKYNvuk00KrQamf1LPH7OJ55nxbkVbLq0yTB2yd7MnoG1BjK41mCcLZ2NHKEQorKSxEkIUabMTDSYmWhwsi7+NhnZucSmZJGTpy9yuaJAdq7ekISlZeUnZmn/+396Vh6pmbmkZ+WSnp1r+H9aVi5ZuUXv836yc/WkZeWSnp3HpRvpXLqRXqL9lCYzE3WB1rbb/9eZqFEV0a6m1+u5HqNmS8rJIp97V2IqsDDRGJLFf7f+/bs7poOVTh6oLEpEURQOXDvAkpAl/HP9H0N53ap1GVpnKIHegeg0hZ/ZKIQQpUkSJyFEuWNhqqW6Q/l7e0rPys1vGftfC9nt/8elZpH2v8QsPSv3f0lc/ktfho+Yy8zRk5mTTXxa9gNspSY4Ifb+q5UBjVqFo5Xufy12OlxszLC1ML2jlS6/m6WlTkNVSx0OVqbSsvYYy8nLYXPkZpaELOHizYtAfne8bl7dGFpnKA0dG8rYJSHEI1P+7kyEEKKcstRp8XG0wsfRqljrK4pCVq4efSk/oPt2i9u/k7XUfyVt2XdpqcvLyyMkJAR/f/9SffadXq+QkZNXIGFMy8xv7Uu5lUtcaiY3UrPI0yuGhPNkMfetVoGjtc7QJfL2RCLWZtq7jlWrYmlKi+pVcbSWFoiKKjU7lbUX1rL83HLiMuIAMNeaM6DmAJ6r+xxuVm5GjlAI8TiSxEkIIcqISqUqswcCW+ryE4QHkZOTw6aEMzzRwhMTk0c7yUVunp74tGxiU/4/ni0mOZOUzIJdK28ngimZudzMyCZPrxCbkkVsShaQ/EDHrO1iTRtfB9r4VqV59apY6eQjr7wLTwrnl/O/8Ef4H2TkZgDgYO7A0DpDGVRrELY6WyNHKIR4nMmniBBCiDKn1ajzJ9OwNaNhMbfJ0yskpGXlt1IlZxqSrpjkLDKyi56hUVEgKjGDc9dTOB+TyvmYVBbtj0CrVtHIw44WNeyp5WyNj6MVNRwtsTCVj0Fjy9Xn8vflv/nl/C8cijlkKPex9WGE/wh61eiFqebBviQQQoiyIJ8YQgghyiWNWoWTjRlONmY0cH+wbRPSsjgQnsCB8Hj2h8VzOfEWR6NucjTqZoH13OzM8XGywtfRiuqOllSz/X+XQHsLU9QymUWZSbiVwPqL61l9YTUx6TEAqFVqOnl04tnaz9LcpbmMXxJClCuSOAkhhKh0qlrp6NOwGn0aVgPgcmIG+8PiOXUlifC4dMJupJGYns3VpFtcTbrF3gs3Cu3DRKPCyTr/oczV7Mxp6lWFtjUd8HG0khv6EtIreg7HHGbthbXsjN5Jrj6/5bCKrgoDag1gcK3BuFq5GjlKIYQomiROQgghKj0Pewuebe7Js809DWWJ6dmE30gjLC6N8Lg0IhPSDV0BE9KzyMlTDInV8egk/jx1HQAnax1tfR1o/b/xU6625sY6rQoj/lY8G8I2sO7COq6kXTGU16tajyF1htDdu7tMJy6EKPckcRJCCPFYsrc0xd7Snmbe9oWW5eTpiUvNIvZ/U85fik/nYHgCRyITiUvNYv2Jq6w/cRWAGo6WNPWqQkMPOxq62+HnYo2JTKGOXtFz8NpB1l5Yy57Le8hV8luXrEys6FWjFwNqDqBO1TrGDVIIIR6AJE5CCCHEHUw0atzszHGz+39r0oROvmTm5HE86ib7w+IJCk/g9JUkwwORVx/Nb0nRadXUc7OlobsdDT1saeRhh6e9xWPTvS8rL4s/wv9g2dllXEq+ZChv6NiQgbUG0t2rOxYmFkaMUAghSkYSJyGEEKKYzEw0tP5fNz2A5Fs5HI5I5OTlJE5eSeLk5SRSMnM5FnWTY/+aiMLOwiQ/kXK3zW+Z8rDDwapydU1LzEzk1/O/sip0FYmZiUB+61Jf374MqDmAmlVqGjlCIYR4OJI4CSGEECVka25Ct7rOdKvrDOQ/DDgqMYOTl5MI/t/r7PUUkjJy+PvCDf7+1yQUbnbmuFUxx0qnxUqnxVKnxdpMi6WpFiszLe5VzGnkYYezjZmxTq9YIpIj+Pnsz/wR/gdZeVkAuFq6MrTOUAbUHICVafEeGC2EEOWdJE5CCCFEKVGrVVR3sKS6gyX9GrsBkJ2rJzQmleArSQRH57dMhd9IM0w8cT8uNmY09MhvqWrkbkc9d1tszB7tA4zvpCgKB68dZPm55ey7us9Q7l/VnxH+I+jm1Q2tWm4xhBCVi7yrCSGEEGXIVKumvrst9d1tGdbSC4CUzBxCrqaQkJ5FelYuqZm5pGflkZaVQ1pWHqmZOYTFpXEhNjV/pr+QTLaGxAKgUkEtJ2ta+1aljY8DLWrYY/2IEqlbubf47dJvrDi3wjB+SYWKDh4dGFF3BAHOAY/NWC4hxONHEichhBDiEbMxM6GVT9X7rpeRncuZqyn5Xf/+N4bqys1bhMamEhqbyk9BkWjUKhq62xqmSK/vZovmLg/u1ahVJZrx73r6dbbe2sonGz4hJTsFAAutBU/VfIohtYfgaeN5nz0IIUTFJ4mTEEIIUU5ZmGppXt2e5tX/P2V6fFoWhyMS2R8Wz4GweCITMjgencTx6CTm7Qq77z6rWpribGOGi61Z/r82ZrjY6gxlLjZm2Jrnt2AdjjnMr6G/sit6F3lKHgDuVu4MqTOEfr79sDa1LpsTF0KIckgSJyGEEKICcbDS8UR9V56o7wrA5cQMDoTHExSWwIHweOLTsu+5fUJ6Ngnp2Zy9nlL0CupMLOxPYFLlH/TaWENxlbwaPFFjKF28O+Fqa4lOXb4nrRBCiNImiZMQQghRgXnYW/C0vSdPN/NEURTSs/Puum5mTh6xKZnEpWTlj51KziQ2JZOYlEwup17ihnoXestjqNTZ6AElz5SclCbk3GxJapYLCy7AAg4b9udgZYqjtRmm2rt3/6tiYYKLjdm/Wrl0hpYuOwvTu3YrFEKI8kYSJyGEEKKSUKlUWOnu/tFupdPiYKXDv1r+z3pFz94re1l2dhlxMfkJkQrwsPKmvUs/api3JzlNw7WkDIJDI1Bb2hObmkVcShbZeXri07Lv28J1PxamGsOU7Fb/mo7dkHD9r/vg7cTL3sIUtSRbQggjkMRJCCGEeMxk5GSwMXwjy88tJyolCgCNSkNnz8484/cMzVyaFZgdLycnh01KOE880RwTExMURSExPZuYlEziUrPIy1OKPI5eUbiZkU1Mcn4LV+y/WrkS0vMTrozsPDKy84hLzSpW7CYaFd5VLWntU5U2vg609Klq9OnZhRCPB0mchBBCiMdEbHosv5z/hTUX1hhmx7M2sWZgrYEMqTMEF0uXYu1HpVJR1UpHVSsd/iWMJTtXT0pmzr+mY88l7V+vhLRsYlP+35UwJjmLhPQscvIULsalcTEujaUHo1CroIG7HW188xOpJp5VMDPRlDAqIYS4O0mchBBCiEogR5/Dp0c+Zc/lPSgU3QIUnxFPrpILgKe1J0PrDKWfbz8sTCweYaT5TLVqHKx0OFjpir1NTp6e2JRMzlxNISgsnqDweC7dSCf4chLBl5P4dnc4Oq2a5tXtae3jQFtfB+pWs5FxVEKIUiGJkxBCCFHBZeZmMu3vaey9sve+6zZ1bsqwusPo4N4BjbpitcyYaNS4V7HAvYoFPerlt45dT75FUFhCfiIVFk9cahb7Lsaz72I8HwO25ia09qlKa18H2td0wKuqpXFPQghRYUniJIQQQlRgadlpTNo1iaOxRzHTmPFu63fxtvUucl0bUxs8rD0ebYBlzNXWnIEB7gwMcEdRFMLi0ggKi2d/WAKHLiWQfCuHzWdi2HwmBoD+jd14vWdtnG1kOnUhxIORxEkIIYSooG5m3mTcjnGEJIRgZWLFN12+IcA5wNhhGY1KpaKmszU1na0Z2aY6uXl6Tl1N5kBYfgvU4chE1p+4ypaQGCZ08uXFttVlPJQQotju/uAFIYQQQpRbsemxPL/leUISQqiiq8KiwEWPddJUFK1GTRPPKkzsXJNfx7Ti9wltCPCqQkZ2Hp9uDaXbF3+z5UwMilL0mDAhhPg3SZyEEEKICuZy6mVGbBlBeHI4ThZOLOmxhLpV6xo7rHKvgbsda8e24qtnGuFiY8blxFuMXX6M5xYdIjQm1djhCSHKOUmchBBCiAok7GYYIzaP4GraVTysPfi558/UsKth7LAqDJVKRd9Gbuyc1oGJnXwx1aoJCkvgiXn7+HZ3mLQ+CSHuShInIYQQogIITQzlzf1vMvjPwdy4dQNfO1+W9liKm5WbsUOrkCx1Wl4N9GPn1A708HchT6/w6dZQxi4/RmpmjrHDE0KUQzI5hBBCCFFO6RU9+6/u5+ezP3Po+iFDeUvXlnzW4TNsdbZGjK5y8LC3YMGwAH45HM07v4ewNSSWi3FBfD8sAF8na2OHJ4QoRyRxEkIIIcqZW7m3+CP8D5adXUZkSiQAGpWGbl7dGFZ3GA0cGxg3wEro2eae1HaxZtzy41y6kU7fb4L4fHAjw/OihBBCEichhBCinEjPSeeX87/wc8jP3My6CYCViRUDaw1kSO0huFq5GjnCyq2xZxX+mNSWiSuPcygikbHLjzG+ow/TuvuhUauMHZ4QwsgkcRJCCCGMLCU7hRXnVrD87HJSslMAcLNy47k6z/FUzaewNLE0coSPD0drHctfasF/Np9n0f4IvtsTzumryXw2qKE8NFeIx5wkTkIIIYSRJGUmsezcMlaeW0laThoA3jbejG4wmp7Ve6JVy8e0MZho1MzqXZcG7ra8vu4U+y7G0+7j3Qxs6s7Y9j54VrUwdohCCCOQd2QhhBDiEbuZeZMlIUtYdX4VGbkZAPja+TKmwRi6eXVDo9YYOUIB0LeRG7WcrZm14QxHo26y8lA0qw5H06dhNcZ19KG2i42xQxRCPEKSOAkhhBCPSHJWMktDlrLi3ApDwlTbvjZjGoyhs2dn1Cp5Skh5U8fVhrXjWnM4IpFvd4fx94Ub/B58jd+Dr9G1jhPjOvpSz+3uCZROK0mwEJWFJE5CCCFEGUvNTmX52eX8fPZnQ5e8OvZ1GNdwHB09OqJSycQD5V3z6vY0r96cM1eTmb8nnE1nrrPjXBw7zsXdczvvqhYE+rvQ3d+Fxh52qGWSCSEqLEmchBBCiDKSkZPBinMrWBKyxDDpQ80qNZnQcAKdPTtLwlQB1XOz5duhTQi/kcbCv8P57cRVcvKUu64fmZDBwr2XWLj3Ek7WOrrVdSbQ34WWNapiqpUWRiEqEkmchBBCiFKWmp3KqvOrWHZ2mWFa8Rq2NRjXaBzdvbpLl7xKwMfRik8GNuT9fvXIztUXuU5OnsLB8AS2hsSw+3wccalZrDgUzYpD0VibaRkY4M6r3f2w1MntmBAVgfylCiGEEKUkMTOR5WeX88v5Xwxd8rxsvBjbcCw9vXvKpA+VkE6ruec4pl4NXOnVwJXsXD0HwuPZGhLL9rOxxKdl8VNQJLvOx/H5oIY09bZ/hFELIUpCEichhBDiIcWmx7IkZAnrLq7jVu4tAHxsfXipwUv08O4h04oLTLVqOvo50dHPiQ/61WPvhRu8+dtpohIyGLTwIKPb12Bqt1oymYQQ5Zi8kwshhBAldD3tOt+f/p7fw34nR58DQN2qdRldfzSdPDtJlzxRJI1aRafaTmx5pT3v/XGWtceusPDvS+w5f4O5TzfEv5qtsUMUQhRBEichhBDiASVmJvLDqR/4NfRXQ8IU4BzA6PqjaVWtlUz6IIrFxsyEzwY1pHtdZ2auP01obCr9vg1iSpeajO3gg1YjibcQ5YkkTkIIIUQxpWWnsfTsUn4O+dnwHKbmLs0Z32g8Ac4BRo5OVFTd/V1o4lWFN387zdaQWD7bdoHNZ2KY3KUm3eo4yxTmQpQTkjgJIYQQ95GVl8Wq86v48fSPJGUlAfld8qY0mUIrV2lhEg/PwUrHgucC+O3EVd7ZGELItRTGLDtGTScrxnX0oU/DaphIC5QQRiWJkxBCCHEX2XnZbAjbwPenvic2IxYAbxtvJjWeRDevbpIwiVKlUqno38Sd9rUcWbw/gmUHo7gYl8bU1SeZu/0CY9rXYFBTD8xMZAIJIYxBEichhBDiDpm5may7uI7FZxYTlxEHgLOFMxMaTaCPTx+ZJU+UKQcrHdN71GZsRx+WHYxi8f4Irty8xazfQ/hqZxjPt/FmSHNPqliaGjtUIR4r8s4vhBBC/E9GTgarQ1ezJGQJCZkJADhZOPFCvRcYWGsgOo3OyBGKx4mNmQkTOvnyQpvqrD56me/3XuJq0i0+3RrKvJ0XebJhNUa09qaem8zCJ8SjIImTEEKIx156Tjq/nP+FpSFLDWOYqllW48X6L9LPtx+mGvlmXxiPuamGEa29GdLCk43B11gcFEHItRTWHLvCmmNXaOJpx4jW3vSs54qpVsZBCVFWJHESQgjx2LqVe4tV51ex+MxiQ8LkYe3BqPqj6O3TGxO1iXEDFOJfTDRqBgS407+JG8ejk/j5YCSbTl/neHQSx6ODed/qHM+19GR8R19JoIQoA5I4CSGEeOxk52Wz9sJafjj9A/G34oH8SR9GNxhNz+o9ZQyTKNdUKhUBXlUI8KrCm73qsOrwZVYciiI2JYsvd1zk7LUUvhnSRJInIUqZfDIIIYR4bOToc9gYtpEFpxYQkx4DgJuVG2MbjqV3jd6SMIkKx8najMldajKuow8bg68x87fTbDsby8SVxyV5EqKUySeEEEKISi9Xn8vmiM0sOLmA6NRoAJzMnRjdYDT9a/bHRCNd8kTFdrsbn4O1jlE/H5XkSYgyIImTEEKISut2wvT9qe+JTIkEwN7Mnhfrvchgv8GYac2MG6AQpaxDLUd+GN7UkDxN+uU4Xz8ryZMQpUESJyGEEJXO7YRp4amFRKVEAWCrs2VE3REMrTMUCxMLI0coRNnpUMuR74cFMHrZMbaG5CdP3wxpgolGkichHoYkTkIIISoURVHIzMu867Kd0TsLJEx2OjtG+I/g2drPYmli+ShDFcJoOvo5FUiebnfbk+RJiJKTxEkIIUSFcT3tOhN2TeDizYv3XVcSJvG4Kyp5km57QpSc/OUIIYSoEGLSY3h+6/P3TZqq6KrwcpOX2TJgCy/Vf0mSJvFYu508mWrVbA2JZeCCA0QlpBs7LCEqJGlxEkIIUe7FpMfwwtYXuJp2FQ9rDxZ2W0hVs6pFrqvT6NCoNY84QiHKr45+Tiwa0ZSJK09w6koyvebtZ07/+vRpWM3YoQlRoUiLkxBCiHItNj2WF7e+yOXUy7hbubM4cDEe1h5YmFgU+ZKkSYjC2tV0ZPOUdjT1qkJaVi6TfjnBzPWnuJWdZ+zQhKgwJHESQghRbsVlxPHitheJTo3GzcqNxYGLcbF0MXZYQlRI1ezMWTW6JRM7+aJSwS+HL9P32/1cjE01dmhCVAiSOAkhhCiXbmTc4MWtLxKVEkU1y2osClyEq5WrscMSokLTatS8GujHshda4GCl40JsGn2+2c+vR6JRFMXY4QlRrkniJIQQotyJvxXPi9teJDIlEldLVxYFLsLNys3YYQlRabSt6cDmKe1oV9OBzBw9r687zZsbzpCnl+RJiLuRxEkIIUS5oSgKB64e4PktzxORHIGzhTOLAhfhbu1u7NCEqHQcrXUsfb4503v4oVLBykPRjFt+jMwcGfckRFEkcRJCCFEunLxxkpe2vcSYHWOITInEycKJnwJ/wsPaw9ihCVFpqdUqxnf05bsh+c932nY2lud+PERSRraxQxOi3JHpyIUQQhjVxZsX+frE1+y+vBsAE7UJT/s9zagGo7A3szdydEI8HnrWd6WqlY6Xlh7haNRNBi44yNIXmuNmZ27s0IQoNyRxEkIIYRRXUq/wXfB3/HnpTxQU1Co1T/o8ybiG46hmJc+XEeJRa17dnjVjWzNi8WHC4tLo/10QS19oTm0XG2OHJkS5IImTEEKIRyo1O5XvT33P8nPLydXnAtDNqxsTG02khl0NI0cnxOPNz8Wa9ePzk6eLcWkMmn+Q74c3pZVP0Q+cFuJxImOchBBCPBK5+lxWh66m1/peLAlZQq4+l5auLVnVaxVzO86VpEmIcqKanTlrx7ammXcVUrNyGbH4MOuOXTF2WEIYnbQ4CSGEKHMHrh7g06OfEpYUBkB12+q81vQ12rm3M3JkQoii2FqYsOzFFkxZdYKtIbFMW3OSA+EJvNfXH0ud3D6Kx5PUfCGEEGXmUvIlPj/6OXuv7AXAVmfL+IbjGeQ3CBO1iZGjE0Lci5mJhu+GBvDNrjC+2nmBdcevcOLyTb4d0oQ6rjLuSTx+jN5V79tvv8Xb2xszMzNatGjB4cOH77l+UlISEyZMwNXVFZ1OR61atdi0adMjilYIIURxpGWn8emRTxnw+wD2XtmLVqXluTrP8ddTfzGkzhBJmoSoIDRqFVO61mTlqJY42+i4dCOdvt8GsfyfKBRFHpYrHi9GbXH69ddfmTp1KgsWLKBFixZ8+eWXBAYGEhoaipOTU6H1s7Oz6datG05OTqxduxY3NzeioqKws7N79MELIYQoRK/o+fPSn8w9OpeEzAQAOrh3YFrTaVS3rW7k6IQQJdWyRlU2TW7Hq2tOsjv0Bm9tOMOB8Hjm9G+Arbl8ESIeD0ZNnObOncuoUaN4/vnnAViwYAF//fUXixcvZsaMGYXWX7x4MYmJiRw4cAATk/w/Um9v70cZshBCiLs4l3COjw59RPCNYAC8bLyY0XwGbd3aGjcwIUSpqGqlY9GIZiwOiuDjLefZdDqGU1eS+frZxjT2rGLs8IQoc0ZLnLKzszl27BgzZ840lKnVarp27crBgweL3Gbjxo20atWKCRMm8Pvvv+Po6MiQIUN4/fXX0Wg0RW6TlZVFVlaW4eeUlBQAcnJyyMnJKcUzKpnbMZSHWETFIfVGlERZ1ZukrCS+O/kd68LWoaBgrjVnVL1RDPEbgqnGVOppJSDvOeLfRrT0oJG7DS+vPsWVm7cYtOAgU7v58mJrb9RqlWE9qTeiJB51vXmQ46gUI3VQvXbtGm5ubhw4cIBWrVoZyqdPn87ff//NoUOHCm1Tu3ZtIiMjGTp0KOPHjycsLIzx48czefJk3nnnnSKP8+677zJ79uxC5StXrsTCwqL0TkgIIR4zuUouR7KPsCtzF7eUWwA0MGlAD/Me2Khl4LgQld2tXFh1SU1wQv6Q+Tp2ep7z1WMlPfdEBZKRkcGQIUNITk7Gxuben10VKnGqVasWmZmZREREGFqY5s6dy6effsr169eLPE5RLU4eHh7Ex8ff9+I8Cjk5OWzfvp1u3boZuh8KcT9Sb0RJlFa90St6tkdt55uT33A1/SoAvra+vN70dQKcA0orXFGOyHuOuBtFUfj16FU+2HSerFw9TtY6Ph9Yn5Y17KXeiBJ51PUmJSUFBweHYiVORuuq5+DggEajITY2tkB5bGwsLi4uRW7j6uqKiYlJgW55derUISYmhuzsbExNTQtto9Pp0Ol0hcpNTEzK1R9xeYtHVAxSb0RJPEy9+ef6P3xx7AvOJpwFwMHcgXENx9G/Zn+0annCRWUn7zmiKMNaV6dZjapMXHmCsLg0hi85yqTONRnXzguQeiNK5lHVmwc5htGmIzc1NSUgIICdO3cayvR6PTt37izQAvVvbdq0ISwsDL1ebyi7cOECrq6uRSZNQgghSkdoYihjt49l1LZRnE04i4XWggmNJvDXU38x2G+wJE1CPOZqu9iwcWIbBjd1R1Fg3s6LDF9yjKSs+28rREVh1E+6qVOnMmLECJo2bUrz5s358ssvSU9PN8yyN3z4cNzc3JgzZw4A48aN45tvvmHKlClMmjSJixcv8tFHHzF58mRjnoYQQlRoiqIw99hcVp1fRa6SW+Q6ufr8cq1Ky2C/wYxuMJqq5lUfZZhCiHLOwlTLJwMb0sbXgTfWn+ZI5E3OXdFQo2Ei7fycjR2eEA/NqInT008/zY0bN3j77beJiYmhUaNGbNmyBWfn/D+u6Oho1Or/N4p5eHiwdetWXnnlFRo0aICbmxtTpkzh9ddfN9YpCCFEhfdN8DcsCVly3/V6ePdgcuPJeNh4lH1QQogKq28jNxq42zF++THOxaQycukxZvaszYttq6NSqe6/AyHKKaP3rZg4cSITJ04sctmePXsKlbVq1Yp//vmnjKOCvLy8RzINYk5ODlqtlszMTPLy8sr8eOLhmJqaFkjmhajoVp1fxfenvgdgZvOZdPbsXOR65lpzbHW2jzI0IUQFVt3Bkl9HNefF+ds5Eq/mg7/OcfJKMh8PqI+FqdFvP4UoEam5d1AUhZiYGJKSkh7Z8VxcXLh8+bJ8C1MBqNVqqlevLmPqRKWwPWo7Hx36CIDxDcczpM4QI0ckhKhMzE01DPXV07NFXT7aHMofJ69xISaVhcMC8HawNHZ4QjwwSZzucDtpcnJywsLCosyTGb1eT1paGlZWVtKSUc7p9XquXbvG9evX8fT0lERXVGhHYo7w+t7XUVAYVGsQYxuONXZIQohKSKWCYS09qedehfErjhMam0qfb/bz1TON6Fxbxj2JikUSp3/Jy8szJE1Vqz6aQc96vZ7s7GzMzMwkcaoAHB0duXbtGrm5uTK1qqiwLty8wORdk8nR59DFswtvtnhTvggQQpSp5tXt+WtyW8YtP8bx6CReXHqU13vUZmwHH2OHJkSxyZ36v9we02RhYWHkSER5dbuLnoxHExXVzbybTNwzkbScNJo4NeHj9h+jUWvuv6EQQjwkZxszVo1uxXMtPVEU+M/m85y9lmLssIQoNkmciiDfvIq7kbohKrKbmTdZmr6U+Fvx+Nr5Mq/zPHSawg8IF0KIsmKqVfNBv/r0aVgNgM+2hRo5IiGKTxInIYSo5BRFYe+VvTy//Xni9fG4WLgwv+t8mSVPCGE0U7vVQqNWset8HEcjE40djhDFIomTKDUqlYoNGzYAEBkZiUqlIjg42KgxCfG4C08KZ9yOcUzYOYHo1GisVFZ80+kbXCxdjB2aEOIxVt3BksFN858J98mWUBRFMXJEQtyfJE6VxMiRI1GpVKhUKkxMTKhevTrTp08nMzPT2KEJIYwgKTOJjw59xICNAwi6FoRWrWV4neG8bPMyNWxrGDs8IYRgSpeamGrVHI5MZM+FG8YOR4j7ksSpEunRowfXr1/n0qVLfPHFFyxcuJB33nnH2GEJIR6hHH0OK86toNdvvfjl/C/kKXl08ujE731/5+XGL2OmMjN2iEIIAYCLrRkjWnkB8OmWUPR6aXUS5ZskTpWITqfDxcUFDw8P+vXrR9euXdm+fTuQP+35nDlzqF69Oubm5jRs2JC1a9cW2D4kJITevXtjY2ODtbU17dq1Izw8HIAjR47QrVs3HBwcsLW1pUOHDhw/fvyRn6MQ4u4OXjvIwI0D+c/h/5CSnULNKjX5ofsPzOs8D08bT2OHJ4QQhYzr6IuVTsvZ6yn8dfq6scMR4p7kOU73oSgKt3LKbuppvV7Prew8tNm5hZ7jZG6iKfEsbmfOnOHAgQN4eeV/kzNnzhyWL1/OggULqFmzJnv37uW5557D0dGRDh06cPXqVdq3b0/Hjh3ZtWsXNjY2BAUFkZubC0BqaiojRozg66+/RlEUPv/8c5544gkuXryItbX1w10EIcRDuZ52nU+Pfsr2qPwvSqroqjCx8UT61+yPVi1v80KI8sve0pRR7WrwxY4LzN1+gR71XDDRyPf6onyST9T7uJWTR923txrl2GffC8TCtPi/oj///BMrKytyc3PJyspCrVbzzTffkJWVxUcffcSOHTto1aoVADVq1GD//v0sXLiQDh068O2332Jra8uqVasMD3atVauWYd+dO3cucKzvv/8eOzs7/v77b3r37l0KZyuEeFBZeVksObOEH0//SGZeJmqVmmf8nmF8o/EyY54QosJ4sV11fj4YSUR8OmuPXeHZ5tJCLsonSZwqkU6dOjF//nzS09P54osv0Gq1DBgwgJCQEDIyMujWrVuB9bOzs2ncuDEAwcHBtGvXzpA03Sk2Npa33nqLPXv2EBcXR15eHhkZGURHR5f5eQkhCvv78t/85/B/uJJ2BYAA5wBmNp+Jn72fkSMTQogHY6XTMr6TL+//eZavdlzkqcZumJnIg7lF+SOJ032Ym2g4+15gme1fr9eTmpKKtY11kV31HoSlpSW+vr4ALF68mIYNG7Jo0SLq1asHwF9//YWbm1uBbXS6/Idfmpub33PfI0aMICEhga+++govLy90Oh2tWrUiOzv7gWIUQjycS0mX+OzoZ+y7ug8AJ3MnpjWdRs/qPeUBzUKICmtoC08W7bvEteRMlh2MYlR7mf1TlD+SON2HSqV6oO5yD0qv15NrqsHCVFsocXoYarWaN954g6lTp3LhwgV0Oh3R0dF06NChyPUbNGjA0qVLycnJKbLVKSgoiO+++44nnngCgMuXLxMfH19q8Qoh7i3hVgLzT85n7YW15Cl5+dOL1x3OmAZjsDCxMHZ4QgjxUMxMNLzctRbT153iuz1hPNPcA2uzonvBCGEsMvquEhs0aBAajYaFCxfy6quv8sorr7B06VLCw8M5fvw4X3/9NUuXLgVg4sSJpKSk8Mwzz3D06FEuXrzIsmXLCA0NBaBmzZosW7aMc+fOcejQIYYOHXrfViohxMPLysti0elF9PqtF7+G/mqYXvy3J3/jlYBXJGkSQlQa/Zu4UcPRkpsZOfywL8LY4QhRiLQ4VWJarZaJEyfyySefEBERgaOjI3PmzOHSpUvY2dnRpEkT3njjDQCqVq3Krl27eO211+jQoQMajYZGjRrRpk0bABYtWsTo0aNp0qQJHh4efPTRR7z66qvGPD0hKjVFUdgcsZmvjn/FtfRrANSxr8NrzV6jmUszI0cnhBClT6tRM62bHxNWHmfRvksMbOKOZ1X5ckiUHw+VOGVnZxMREYGPjw9areRgxrRkyZIiy2fMmMGMGTMAmDJlClOmTLnrPho0aMDWrUXPINi4cWOOHDlSoGzgwIEFflaU/z+4ztvbu8DPQojiC44L5pMjn3A6/jQAzhbOTGkyhV41eqFWSUcBIUTl1bOeC029qnA06iYTVh5nzdhWMlGEKDdK9AmckZHBiy++iIWFBf7+/oaZ1SZNmsR//vOfUg1QCCEeFzHpMby+93WGbR7G6fjTmGvNmdR4En889Qd9fPpI0iSEqPTUahXznm1MFQsTTl9N5sO/zhk7JCEMSvQpPHPmTE6ePMmePXswMzMzlHft2pVff/211IITQojHwa3cW8w/OZ8+v/VhU8QmVKh4yvcpNvXfxOgGozHXynhCIcTjo5qdOXOfbgTAsn+i2HjymnEDEuJ/StS/bsOGDfz666+0bNmywPS3/v7+hIeHl1pwQghRmSmKwpbILcw9NpeY9BgAmjg1YXrz6fhX9TdydEIIYTyd/JyY2MmXb3aHMXPdKfyr2eDjaGXssMRjrkSJ040bN3BycipUnp6eLs8REUKI/7mSeoVvgr/hZubNIpfH34rnws0LALhaujI1YCqB3oHyPiqEEMDLXWtyNCqRfy4lMn75cTZMaIO5qYx3EsZTosSpadOm/PXXX0yaNAnA8CH/448/0qpVq9KLTgghKqiMnAwm7pxIePK9W+HNtea8UO8FRvqPxExrds91hRDicaLVqJn3TGOemLef0NhU3v79DJ8OamjssMRjrESJ00cffUTPnj05e/Ysubm5fPXVV5w9e5YDBw7w999/l3aMQghRoSiKwrsH3iU8ORxHc0deDngZFYVbkdQqNc1cmuFkUbgFXwghBDjZmDHv2UY89+Mh1hy7QrPq9gxu6mHssMRjqkSJU9u2bTl58iRz5syhfv36bNu2jSZNmnDw4EHq169f2jEKIUSFsvL8SjZHbkar0vJ5x89p7NTY2CEJIUSF1drHgandavHZtgu8/fsZGrjbUtvFxthhicfQAydOOTk5jBkzhlmzZvHDDz+URUxCCFFhnYg7wWdHPgNgWtNpkjQJIUQpGN/Rl8ORN9l74QbP/XiYGo6WRa7naK1jRo/aeNjLg3NF6XvgxMnExIR169Yxa9assohHCCEqrPhb8UzbM41cJZce3j0YWmeosUMSQohKQa1W8eXTjeg9bx/XkjOJT8u667rHIm+y/KUW+DrJLHyidJWoq16/fv3YsGEDr7zySmnHIyoQlUrFb7/9Rr9+/Up1XSEqolx9Lq/9/Ro3bt3Ax9aH2a1ny+x4QghRiuwtTdnySnsOhMWjVwov1ysKX+24yMW4NJ5eeJBlL7agbjXp0idKT4kSp5o1a/Lee+8RFBREQEAAlpYFm0snT55cKsGJ4hs5ciRLly4F8lsFPT09GT58OG+88QZabYl+zfd1/fp1qlSpUurrClERfXX8K47GHsVCa8HcTnOxMJFuIkIIUdpszEzoUc/1rstb+zgwfPEhzlxN4ZnvD7LkheY08ZT7D1E6SnRHvWjRIuzs7Dh27BjHjh0rsEylUkniZCQ9evTgp59+Iisri02bNjFhwgRMTEyYOXNmgfWys7MxNTV96OO5uLiUybpCVDTbo7azJGQJAB+0/YAatjWMG5AQQjym7C1NWTmqJS/8dISjUTd57sdD/DiiKa19HIwdmqgE1CXZKCIi4q6vS5culXaMoph0Oh0uLi54eXkxbtw4unbtysaNGxk5ciT9+vXjww8/pFq1avj5+QFw+fJlBg8ejJ2dHfb29vTt25fIyMgC+1y8eDH+/v7odDpcXV2ZOHGiYZlKpWLDhg1AfjI2ceJEXF1dMTMzw8vLizlz5hS5LsDp06fp3Lkz5ubmVK1aldGjR5OWlmZYfjvmzz77DFdXV6pWrcqECRPIyckp/QsnxEM4n3ieWUH5Yz5H+o+km1c3I0ckhBCPNxszE35+sTltfR3IyM7j+Z+OsOt8rLHDEpVAiRKnf1MUBUUpoqNpZaEokJ1etq+cjKLLH/K6mpubk52dDcDOnTsJDQ1l+/bt/Pnnn+Tk5BAYGIi1tTX79u0jKCgIKysrevToYdhm/vz5TJgwgdGjR3P69Gk2btyIr69vkceaN28eGzduZPXq1YSGhrJixQq8vb2LXDc9PZ3AwECqVKnCkSNHWLNmDTt27CiQlAHs3r2b8PBwdu/ezdKlS1myZAlLlix5qGsiRGnJ0eew8ORCnv3rWdJz0mnq3JQpTaYYOywhhBCAhamWH0c0pWsdZ7Jy9Yz++Rh/nbpu7LBEBVfiwS8///wzn376KRcvXgSgVq1avPbaawwbNqzUgisXcjLgo2pltns1YHe3hW9cA9Oip9u8F0VR2LlzJ1u3bmXSpEncuHEDS0tLfvzxR0MXveXLl6PX6/nxxx8NA9h/+ukn7Ozs2LNnD927d+eDDz5g2rRpTJny/5vBZs2aFXnM6OhoatasSdu2bVGpVHh5ed01vpUrV5KZmcnPP/9sGB/3zTff0KdPHz7++GOcnZ0BqFKlCt988w0ajYbatWvTq1cvdu7cyahRox74mghRmm63Mp1PPA9AB/cOvN/mfbTqshlPKIQQ4sGZmWiY/1wTpq0+ycaT15j0y3FUqiY8Uf/uY6SEuJcSfcrPnTuXWbNmMXHiRNq0aQPA/v37GTt2LPHx8TLbnpH8+eefWFlZkZOTg16vZ8iQIbz77rtMmDCB+vXrFxjXdPLkScLCwrC2ti6wj8zMTMLDw4mLi+PatWt06dKlWMceOXIk3bp1w8/Pjx49etC7d2+6d+9e5Lrnzp2jYcOGBSYVadOmDXq9ntDQUEPi5O/vj0ajMazj6urK6dOni309hCht2XnZfH/qexadXkSukoutzpYZzWfQq3ovmUFPCCHKIRONmi+eboS5iYZfj15m6upgPO0tqOdma+zQRAVUosTp66+/Zv78+QwfPtxQ9uSTT+Lv78+7775buRInE4v8lp8yotfrSUlNxcbaGrX6jp6TDzgrV6dOnZg/fz6mpqZUq1atwGx6d858mJaWRkBAACtWrCi0H0dHx8Kx3EeTJk2IiIhg8+bN7Nixg8GDB9O1a1fWrl37QPv5NxMTkwI/q1Qq9Hp9ifcnxMM4E3+GWUGzCEsKA6CbVzfeaPEGDuYy4FgIIcozjVrFh0/V43pKJnsv3GDUz0f5fWIbnKzNjB2aqGBKlDhdv36d1q1bFypv3bo1169Xsv6jKlWJussVm14PJnn5x3jAZOVOlpaWdx2DdKcmTZrw66+/4uTkhI1N0c848Pb2ZufOnXTq1KlY+7SxseHpp5/m6aefZuDAgfTo0YPExETs7e0LrFenTh2WLFlCenq6IaELCgpCrVYbJq4QorxIyU5hfvB8Vp5fiV7RY29mzxst3iDQO9DYoQkhhCgmrUbN18825qnvgrh0I52xy47xy+iW6LSa+28sxP+U6E7d19eX1atXFyr/9ddfqVmz5kMHJcre0KFDcXBwoG/fvuzbt4+IiAj27NnD5MmTuXLlCgDvvvsun3/+OfPmzePixYscP36cr7/+usj9zZ07l19++YXz589z4cIF1qxZg4uLC3Z2dkUe28zMjBEjRnDmzBl2797NpEmTGDZsmKGbnhDGlqfPY3Xoanqv783yc8vRK3p6Vu/Jhr4bJGkSQogKyNbchEUjmmFjpuV4dBJvrD9TuSc4E6WuRC1Os2fP5umnn2bv3r2GMU5BQUHs3LmzyIRKlD8WFhbs3buX119/nf79+5OamoqbmxtdunQxtECNGDGCzMxMvvjiC1599VUcHBwYOHBgkfuztrbmk08+4eLFi2g0Gpo1a8amTZuK7PJnYWHB1q1bmTJlCs2aNcPCwoIBAwYwd+7cMj1nIYrrSMwRPj78MaE3QwGoYVuD6c2m08atjZEjE0II8TCqO1jy7dAmjPzpCOuOX6G2izWj2suz90TxqJQSptrHjh3jiy++4Ny5c0B+96tp06bRuHHjUg2wtKWkpGBra0tycnKhLmqZmZlERERQvXp1zMweTb9XvV5PSkoKNjY2DzyuSDx6xqgjRcnJyWHTpk088cQThcaCiZK7mnaVuUfnsi1qGwDWptZMaDSBwX6DMVFX/Oss9UaUlNQdURLlud78FBTB7D/OolbBopHN6OTnZOyQxP886npzr9zgTiWeOzcgIIDly5eXdHMhhCg3cvW5LDq9iB9O/0BWXhZqlZpBtQYxodEEqphVMXZ4QgghStnI1t6ExqSy6shlJq88wW8TWuPrZH3/DcVjrUSJ06ZNm9BoNAQGFuznv3XrVvR6PT179iyV4IQQoqxFJEfwxr43OJNwBoDmLs2Z3mw6fvYyUYkQQlRWKpWK9/rW49KNdA5HJvLi0qP8PqENdham999YPLZK1DdsxowZ5OXlFSpXFIUZM2Y8dFBCCFHW9IqeFedWMOiPQZxJOIO1qTVz2s3hx+4/StIkhBCPAVOtmvnPNcHNzpyohAxmrpdnRYp7K1HidPHiRerWrVuovHbt2oSFhT10UEIIUZaup11n9LbR/Ofwf8jKy6KVayvWP7me3jV6y4NshRDiMVLVSsfCYQFo1So2n4lh8+lK9lgdUapKlDjZ2tpy6dKlQuVhYWGFHrQqhBDlhaIo/B72O/039udQzCHMtea81eItFnZbiIuli7HDE0IIYQT13GwZ19EHgFm/h5CUkW3kiER5VaLEqW/fvrz88suEh4cbysLCwpg2bRpPPvlkqQUnhBClJSkziVf2vMJbQW+RlpNGA8cGrOmzhqdrPy2tTEII8Zib2NmXmk5WxKdl8d6fZ40djiinSpQ4ffLJJ1haWlK7dm2qV69O9erVqV27NlWrVuWzzz4r7RiFEOKhHLp+iAEbB7AzeidatZYpTaawtMdSvGy8jB2aEEKIckCn1fDJwAaoVbD++FV2n48zdkiiHCrRrHq2trYcOHCA7du3c/LkSczNzWnYsCHt2rUr7fiEEKLEcvJy+Cb4G3468xMKCt423nzc/mPqVi08RlMIIcTjrbFnFV5oU50f90fwxm+n2fZKe6zNytfzp4RxPVCL08GDB/nzzz+B/Gkcu3fvjpOTE5999hkDBgxg9OjRZGVllUmgQgjxIKJSohi2eRiLzyxGQWFAzQH82vtXSZqEEELc1bTufnhVteB6ciZzNp83djiinHmgxOm9994jJCTE8PPp06cZNWoU3bp1Y8aMGfzxxx/MmTOn1IMUlYtKpWLDhg3FXn/Pnj2oVCqSkpLKLKZ/e/fdd2nUqNEjOZYofYqi8NvF3xj0xyBCEkKwMbXhi45f8G7rd7EwsTB2eEIIIcoxc1MNHw9oAMDKQ9EcCI83ckSiPHmgxCk4OJguXboYfl61ahXNmzfnhx9+YOrUqcybN4/Vq1eXepDi/kaOHIlKpSr0uj09/N69e+nTpw/VqlUrVuJy/vx5VCoV//zzT4Hyli1bYmZmRmZmpqEsMzMTMzMzFi1aVKxYr1+/XuoPSZZkR0D+NOPT/p7G2wfe5lbuLZq5NGPdk+vo6tXV2KEJIYSoIFrWqMpzLT0BmLHuNBnZuUaOSJQXD5Q43bx5E2dnZ8PPf//9d4Eb4GbNmnH58uXSi048kB49enD9+vUCr+rVqwOQnp5Ow4YN+fbbb4u1r9q1a+Pi4sKePXsMZampqRw/fhxHR8cCCdXBgwfJysqic+fOxdq3i4sLOp2u+CcmxH1k5GQw7/g8+mzow/ao7WhV+RNA/NDtB5lmXAghxAN7vUdtqtmaEZ2YwefbLhg7HFFOPFDi5OzsTEREBADZ2dkcP36cli1bGpanpqZiYiKD6IxFp9Ph4uJS4KXRaADo2bMnH3zwAU899VSx99epU6cCidP+/fupVasWffr0KVC+Z88evLy8DEna77//TpMmTTAzM6NGjRrMnj2b3Nz/f1tzZ4vXgQMHaNSoEWZmZjRt2pQNGzagUqkIDg4uEM+xY8do2rQpFhYWtG7dmtDQUACWLFnC7NmzOXnypKGlbcmSJQAkJSXx0ksv4ejoiI2NDZ07d+bkyZMF9vuf//wHZ2dnrK2tefHFFwu0ponyTa/o+e3ib/T6rRc/nP6BrLwsmjo35Zfev/BS/ZfQqDXGDlEIIUQFZG1mwkf96wOwOCiCY1E3jRyRKA8eKHF64oknmDFjBvv27WPmzJlYWFgUmEnv1KlT+Pj4lHqQxqQoChk5GWX6upV7q8hyRVGMeu6dOnVi//79hqRn9+7ddOzYkQ4dOrB7927Dert376ZTp04A7Nu3j+HDhzNlyhTOnj3LwoULWbJkCR9++GGRx0hJSaFPnz7Ur1+f48eP8/777/P6668Xue6bb77J559/ztGjR9FqtbzwwgsAPP3000ybNg1/f39DS9vTTz8NwKBBg4iLi2Pz5s0cO3aMJk2a0KVLFxITEwFYvXo17777Lh999BFHjx7F1dWV7777rnQuoChTR2KO8Myfz/D2gbeJvxWPh7UHX3b8ksWBi6ltX9vY4QkhhKjgOvo5MaCJO4oCr645KV32xINNR/7+++/Tv39/OnTogJWVFUuXLsXU1NSwfPHixXTv3r3UgzSmW7m3aLGyhVGOfWjIoQcazP7nn39iZWVl+Llnz56sWbOmxMfv1KkT6enpHDlyhFatWrFnzx5ee+012rZty4gRI8jMzERRFA4fPsxLL70EwOzZs5kxYwYjRowAoEaNGrz//vtMnz6dd955p9AxVq5ciUql4ocffsDMzIy6dety9epVRo0aVWjdDz/8kA4dOgAwY8YMevXqRWZmJubm5lhZWaHVanFx+X+3rP3793P48GHi4uIMXQM/++wzNmzYwNq1axk9ejRffvklL774Ii+++CIAH3zwATt27JBWp3Is4VYCHx76kO1R2wGwNrFmTMMxPFv7WUw1pvfZWgghhCi+t3vX5UB4PBHx6Xz41zk+fKq+sUMSRvRAiZODgwN79+4lOTkZKysrQzew29asWVPgxl08Wp06dWL+/PmGny0tLR9qf76+vri7u7Nnzx78/f05ceIEHTp0wMnJCU9PTw4ePIiiKGRlZRlanE6ePElQUFCBFqa8vDwyMzPJyMjAwqJgIhgaGkqDBg0wMzMzlDVv3rzIeBo0aGD4v6urKwBxcXF4enoWuf7JkydJS0ujatWqBcpv3bpFeHg4AOfOnWPs2LEFlrdq1apAi5ooP4KuBvHm/jdJyExAo9IwsNZAxjcaj72ZvbFDE0IIUQnZWpjw+aCGDPnxECsORdO5thNd6jjff0NRKZX4AbhFsbevfDcv5lpzDg05VGb71+v1pKamYm1tjVpdsOekudb8gfZlaWmJr69vaYZHx44d2b17Nw0aNKBmzZo4OTkBGLrrKYqCr68vHh4eAKSlpTF79mz69+9faF//To5K4t/j51QqFZB//e4mLS0NV1fXAuOxbrOzs3uoWMSjlZ2XzVfHv+Lnsz8D4Gvny3/a/Qc/ez8jRyaEEKKya+3rwKh21flhXwTT155iy8vtcbSWSa4eRyVKnB4nKpWqTJ/9otfrydXmYmFiUShxKg86derE5MmTqVu3Lh07djSUt2/fnh9++AFFUQytTQBNmjQhNDS02Amcn58fy5cvJysry9Cd7siRIw8cp6mpKXl5eQXKmjRpQkxMDFqtFm9v7yK3q1OnDocOHWL48OGGsjunYBfGdSn5Eq/vfZ3zifkPInzG7xmmNZ2GmfbhEnEhhBCiuF4N9GPfxXjOx6QyY90pfhzR1PAlrnh8lL87dVEm0tLSCA4ONsxUFxERQXBwMNHR0ffc7vY4p8WLFxvGF0F+i9OhQ4c4fPhwgcTp7bff5ueff2b27NmEhIRw7tw5Vq1axVtvvVXk/ocMGYJer2f06NGcO3eOrVu38tlnnwE80BuSt7e34Zzi4+PJysqia9eutGrVin79+rFt2zYiIyM5cOAAb775JkePHgVgypQpLF68mJ9++okLFy7wzjvvFHjIszAeRVFYd2Edz/z5DOcTz2Ons2Nep3m82fJNSZqEEEI8Ujqthi+faYSpVs3O83GsPHzv+ydROUni9Jg4evQojRs3pnHjxgBMnTqVxo0b8/bbb99zu+rVq+Pl5UVqamqBxMnT05Nq1aqRnZ1doCUqMDCQP//8k23bttGsWTNatmzJF198gZeXV5H7t7Gx4Y8//iA4OJhGjRrx5ptvGmJ6kK59AwYMoEePHnTq1AlHR0d++eUXVCoVmzZton379jz//PPUqlWLZ555hqioKMPzyJ5++mlmzZrF9OnTCQgIICoqinHjxhX7uKJspGanMu3vabx78N38CVpcW7DuyXV08ux0/42FEEKIMlDbxYbXe+TP2vr+n2cJv5Fm5IjEo6ZSjD3n9SOWkpKCra0tycnJ2NjYFFiWmZlJREQE1atXf+jxOMWl1+tJSUnBxsamXHbVM4YVK1bw/PPPk5ycjLn5g43zKmvGqCNFycnJYdOmTTzxxBOV7tlpUSlRTNo1iYjkCLQqLZObTGaE/wjUKvn7eFiVud6IsiV1R5REZaw3er3C8MWH2R8WTwN3W9aNa42JRj6fStOjrjf3yg3uJL9pYXQ///wz+/fvJyIigg0bNvD6668zePDgcpc0ibJ34OoBnv3rWSKSI3CycOLnnj/zfL3nJWkSQghRLqjVKj4b1BBbcxNOXUlm3s6Lxg5JPEJyNyKMLiYmhueee446derwyiuvMGjQIL7//ntjhyUeIUVRWBqylHE7x5GanUoDxwas6rWK+o7yvAwhhBDli4utGXP6538+fbs7jKORiUaOSDwqkjgJo5s+fTqRkZGGbnBffPFFoec9icorKy+Lt4Le4rOjn6FX9PTz7cdPgT/haOFo7NCEEEKIIj1R35UBTdzRKzBtzUkyc/Luv5Go8CRxEkIYzY2MG7yw5QU2hm9ErVLzerPXea/1e5hqTI0dmhBCCHFP7z5ZFxcbM6ISMvh6l3TZexxI4lSEx2y+DPEApG6UngPXDvDMn89wKv4UNqY2LOi6gOfqPifPxRBCCFEhWJuZ8F5ffwAW/n2J8zEpRo5IlDVJnP7l9swdGRkZRo5ElFfZ2dkAaDQaI0dScSVlJvHm/jcZs30Mcbfi8LH14Zdev9CqWitjhyaEEEI8kO7+LvTwdyFXrzBj3Wny9PIFa2WmNXYA5YlGo8HOzo64uDgALCwsyvzbb71eT3Z2NpmZmTIdeTmn1+u5ceMGFhYWaLXyp/OgFEVhU8QmPjnyCYmZiahQMaTOECY3noyFiYxpE0IIUTG9+6Q/+8PiCb6cxIpDUQxv5W3skEQZkbu/O7i4uAAYkqeypigKt27dwtzcXLooVQBqtRpPT0/5XT2g62nXef+f99l3dR8Avna+vNv6XRo6NjRyZEIIIcTDcbE14/Uefsz6PYRPtoTSra4zrrbySJXKSBKnO6hUKlxdXXFyciInJ6fMj5eTk8PevXtp3759pXk4XGVmamoqLYMPIE+fx6rQVXx1/Ctu5d7CRG3CmAZjeKHeC5hopL4LIYSoHIa28OK3E1c5Hp3EO7+H8P3wpsYOSZQBSZzuQqPRPJJxLBqNhtzcXMzMzCRxEpVKVEoUs4JmcSLuBABNnJrwTut3qGFbw8iRCSGEEKVLrVYxp38Des3bx7azsWw5E0OPei7GDkuUMvnqXAhRqvSKnhXnVjBw40BOxJ3AQmvBWy3e4qceP0nSJIQQotLyc7FmbAcfAN7ZeIaUzLLvuSQeLUmchBCl5nLqZV7Y+gL/OfwfMvMyaeHSgt/6/sbTtZ9GrZK3GyGEEJXbxM6+eFe1IDYli0+3hBo7HFHK5E5GCPHQ9IqeX87/woCNAzgWewxzrTlvtXiL77t/TzWrasYOTwghhHgkzEw0fPRUfQCWH4riWFSikSMSpalcJE7ffvst3t7emJmZ0aJFCw4fPlys7VatWoVKpaJfv35lG6AQ4q6up11n9LbRfHToI27l3qKZSzPWP7leWpmEEEI8llr7OjAwwB1FgdfWnOJmeraxQxKlxOh3Nb/++itTp07lnXfe4fjx4zRs2JDAwMD7TgceGRnJq6++Srt27R5RpEKIO+2O3s3APwZyKOYQ5lpzZjafyY/df8Td2t3YoQkhhBBG8+YTdXC1NeNSfDovLj3Crew8Y4ckSoHRE6e5c+cyatQonn/+eerWrcuCBQuwsLBg8eLFd90mLy+PoUOHMnv2bGrUkMHmQjxqOXk5fHrkUybvnkxKdgr1qtZjbZ+1DKkzRFqZhBBCPPaqWJqy9IXm2JhpOR6dxMSVx8nN0xs7LPGQjDodeXZ2NseOHWPmzJmGMrVaTdeuXTl48OBdt3vvvfdwcnLixRdfZN++ffc8RlZWFllZWf9t787joqoXN45/ZoYdAUEUXHDf99Q0NTP30upa95ptZqaVV63MNm1Ts1v5u2ar5c1Ku23a3i3NJZfKLXMhtRRXXFBA3EDWgTm/Pw4gKIigcAZ43q/XvGbmzJmZZ+grzcM553ty7ycmJgLm+ZPK4jxNRcnJ4A5ZpPywctwcST7CxNUT2X58OwB3NruTh9o/hKfDU+PYzen3jZSUxo6URGUfNw1CfPjPXVdwz7xNLN8Zz8SvtvLi4JbYbDaro7m1sh43xXkfS4tTQkICWVlZhIWF5VseFhbGzp07C3zO6tWref/994mMjLyo93jppZeYOnXqecuXLl2Kn59fsTOXlmXLllkdQcqhsh43O5w7+CrlK9KMNHxsPvzd7++0iGvBsiUav+WJft9ISWnsSElU9nEzrJGN96PsfLk5hsS4Qwyqqy1PF6Osxk1KSspFr1uuToCblJTEsGHDmDNnDqGhoRf1nEmTJjFhwoTc+4mJiURERNC/f38CAwNLK+pFczqdLFu2jH79+ukEuHLRynrcOLOcvBH5Bp9EfQJA62qtebn7y5oxr5zR7xspKY0dKQmNG9NAoMHGwzz93V8sjbHTpX1L7r6qrtWx3FZZj5ucvdEuhqXFKTQ0FIfDQVxcXL7lcXFxhIeff7blvXv3Eh0dzY033pi7zOUyW7uHhwdRUVE0atQo33O8vb3x9vY+77U8PT3d6h+xu+WR8qEsxs3eU3uZ9OskdpzYAcDwlsN5uMPDeDo0Xssr/b6RktLYkZLQuIE7uzbgeEomM5ft4oVFOwkL8uWGtvrj44WU1bgpzntYehS3l5cXHTt2ZPny5bnLXC4Xy5cvp2vXruet37x5c7Zt20ZkZGTu5aabbqJXr15ERkYSERFRlvFFKjSX4eLDPz/k1u9vZceJHQR5B/FGrzd47MrHVJpERESK6cHejRl2VT0MAyYs+IO1exOsjiTFZPmuehMmTGD48OF06tSJzp0789prr5GcnMyIESMAuPvuu6lduzYvvfQSPj4+tG7dOt/zq1atCnDechEpuZgzMTyz+hk2xm0EoEftHkztNpXqftUtTiYiIlI+2Ww2ptzUioQz6fy4PZbRH21i1eO9CPH3sjqaXCTLi9PQoUM5duwYzz33HLGxsbRv357FixfnThhx8OBB7HZNbyxSFgzD4Js93zB9w3RSMlPw9fDliSuf4O9N/q5ZgERERC6Rw27j1aHtiT6+lh1HE3lzxW4m39jK6lhykSwvTgDjxo1j3LhxBT62atWqCz533rx5lz+QSCWUkJrAlLVT+PnwzwB0qNGBF65+gYgA7QIrIiJyufh4OnhqYHOGvb+Bj9cfYES3BtSt5j4zPUvhtClHpJIzDIMf9v3A4O8G8/Phn/G0e/Jox0f5YMAHKk0iIiKloEeT6vRoEoozy2DG0iir48hFUnESqcTiU+J5aMVDTPp1EqfTT9MipAULbljAPa3vwWF3WB1PRESkwnryuuYA/O+PI2w7fNriNHIxVJxEKiHDMPhuz3cM/m4wqw6vwsPuwbj24/hk0Cc0CW5idTwREZEKr3XtIAa3N6ckn754p8Vp5GK4xTFOIlJ2YpNjmbpuKqtjVgPQqlorpnWfpsIkIiJSxh7t34xF22JZvSeBX3Yd45qmmr3WnWmLk0gl4TJcfLnrS27+7mZWx6zGy+7F+A7j+XjgxypNIiIiFogI8eOuq+oB8PKPO3G5DIsTyYWoOIlUAntO7mHE4hFMXTeVM84ztK3eli9u/IKRbUbiYdeGZxEREauM692YAG8P/jqayHd/xFgdRy5AxUmkAkvNTOW1Ta8x5PshbI7fjK+HL491eoz/XvdfGlZtaHU8ERGRSi/E34vR1zYCYMaSXaRnZlmcSAqj4iRSQf16+Fdu/u5m3t/+PplGJr0ievHd375jeKvhmjFPRETEjdzbvQFhgd7EnErlo3UHrI4jhVBxEqlg4lPieXTVo4xZPoaYMzGE+YXxeq/XeaP3G9SsUtPqeCIiInIOXy8Hj/RtCsBbK/dwOtVpcSIpiIqTSAWSs5Vp6YGl2G12hrUcxneDv6N33d5WRxMREZEL+EfHOjSuUYVTKU5m/7zX6jhSABUnkQrAZbh45493GLt8LIkZibSs1pL5g+bzxJVP4O/pb3U8ERERKYKHw557UtwPVu8nPinN4kRyLhUnkXIuMSORh1Y8xNuRb2NgcGvTW/no+o9oUa2F1dFERESkGPq2qEG7iKqkZ7r49LeDVseRc6g4iZRju07u4rYfbuPnwz/jZfdiWvdpPNv1WbwcXlZHExERkWKy2WyMvLoBAB+vP0hGpsviRJKXipNIOfVHxh/cs/QeDiUdopZ/LT4a+BGDGw+2OpaIiIhcgutbhxMW6E3CmXQWbjtidRzJQ8VJpJxxupz8e9O/+SLlC9Ky0uhWqxsLblhAy2otrY4mIiIil8jTYWfYVfUAmLsmGsMwLE4kOVScRMqRU2mnGL1sNJ9FfQbAyFYjebvP21T1qWptMBEREblsbu9cFy8PO1sPn2bLoVNWx5FsKk4i5cSuk7u4beFtbIjdgJ+HH3f43cHYdmN1MlsREZEKploVb25qVwswtzqJe1BxEikHlh9Yzl2L7iLmTAx1qtRhXv95tPTSrnkiIiIV1T3d6gPw47ajxJ7W1OTuQMVJxI3lnJ9p/KrxpGam0iW8C58N+ozGVRtbHU1ERERKUevaQXSuH0Kmy+Dj9QesjiOoOIm4rRRnCo/9/BhvR74NwJ0t7mR2v9k6nklERKSSuKd7fQA+3XCQNGeWtWFExUnEHR1KPMSwH4ex7MAyPOwePN/teSZ2noiH3cPqaCIiIlJG+rcMo1aQDyeSM/j+D01NbjUVJxE3s+LgCob+MJRdJ3dRzacacwfM5eYmN1sdS0RERMqYh8POsK71AU1N7g5UnETcRKYrk5kbZ/LwyodJcibRrno75t8wn/Y12lsdTURERCxye+cIfDzt/HU0kd+jT1odp1JTcRJxA8dSjjFq6Sjm/jkXgGEthzH3urmE+4dbnExERESsVNXPi5uvqA3AvLX7LU5Tuak4iVjs99jfGfL9EDbFbcLf05+Z187kiSufwNPuaXU0ERERcQPDs6cmX/JnHDGnUq0NU4mpOIlYxGW4eG/be4xaOorjacdpEtyE+YPm069eP6ujiYiIiBtpHh5It0bVyHIZfLROU5NbRcVJxAIn004ybvk4Xt/8Oi7DxU2NbuKTgZ9QP6i+1dFERETEDeWcEHf+7wdJzdDU5FZQcRIpY5viNvGP7//BrzG/4u3wZnLXybzQ/QV8PXytjiYiIiJuqk+LMCJCfDmV4uTbyBir41yacjo7oIqTSBlxGS7mbJ3DyCUjiU+Jp35gfT4Z+An/aPoPbDab1fFERETEjTnsNoZnT00+r7xPTf7dOPhxIqQlWp2kWFScRMrA8dTj/POnf/LGljfIMrK4oeENLLhhAc1CmlkdTURERMqJIZ0i8PNyEBWXxLq9x62OUzL7f4HIj+G32ZCw2+o0xaLiJFLKcmbNW3tkLT4OH57v9jwvXv0ifp5+VkcTERGRciTI15O/d6gDwNy10daGKYnMdPhhgnm7071Qp6O1eYpJxUmklLgMF+9ufZdRS0dxLPUYjYIa8dmgz7i5yc3aNU9ERERKZHi3egD8tCOOQydSLE5TTGvegOO7wb8G9HnO6jTFpuIkUgoSMxJ5eMXDvLnlTVyGi781+hufDvqUxsGNrY4mIiIi5VjjGgH0aBKKYcCH5Wmr0/G98Mu/zdvXvQS+VS2NUxIqTiKXWdSJKG774TZWHV6Fl92Lqd2m8sLVL2jXPBEREbks7u3eAIAFGw+RnJ5pcZqLYBiw6DHISoeG10Lrv1udqERUnEQuo+/3fs9di+7iUNIhavnX4r8D/8stTW6xOpaIiIhUID2bVqdBqD9JaZl8vfmw1XGKtv0r2LsCHN4waCaU00MWVJxELgNnlpMX1r/AU6ufIi0rje61urPghgW0qtbK6mgiIiJSwdjtNoZ3NY91mrc2GpfLjacmTz0FS54yb/d4FKo1sjTOpVBxErlEscmx3LPkHhZELQBgdLvRzOozi6o+Va0NJiIiIhXW3zvWoYq3B3uPJbN6T4LVcQq34gU4EwfVGsPV461Oc0lUnEQuQWR8JLf9cBtbj20lwCuAWX1mMbb9WBx2h9XRREREpAIL8PFkSKfsqcnX7Lc4TSEOb4Lf3zNvD5oJHt7W5rlEKk4iJfT17q8ZsWQEx9OO0yS4CQsGLeCaOtdYHUtEREQqieFd62OzwcqoY+xPSLY6Tn5ZmfDDeMCAtkOhYU+rE10yFSeRYnK6nLz424tMXjuZTFcm/er14+PrPyYiMMLqaCIiIlKJ1A/1p1ezGoAbTk2+4V2I3Qo+QdD/X1anuSxUnESK4WTaSUYvG81nOz8DYGz7sczoOUNTjYuIiIglRnSvD8AXGw+RlOa0NkyOXUthxTTzdt+pUKW6tXkuExUnkYu06+Qubl94OxtiN+Dn4cdrvV5jdLvR2G36ZyQiIiLWuLpxKI1rVCE5I4svN1k8NblhwLpZ8NlQcKZAoz7QYbi1mS4jfeMTuQjLDyznrkV3EXMmhjpV6vDxwI/pU7eP1bFERESkkrPZbNzTrT5g7q5n2dTkmRnw/cPm1OOGC64YBrfPB3vFqRsV55OIlALDMJi7fS7jV40nNTOVq2pexfwb5tMkuInV0UREREQAuKVDbQJ8PIg+nsIvu4+VfYCUE/DRzbD5Q7DZYcCLcNOb4OFV9llKkYqTSCGcLidT101l5qaZAAxtNpR3+r5DkHeQxclEREREzvLz8uCGtrUAWL27jM/pdCwK5vSGA6vBK8DcytR1LNhsZZujDHhYHUDEHSVmJPLoqkdZf3Q9Nmw8ceUT3NniTmwV8JeAiIiIlH9XNQzhsw0H+T36ROm/mcsFKcfh0Hr4diykn4aqdeH2BRDWsvTf3yIqTiLnOJx0mHHLx7H39F58PXz5v2v+j2sjrrU6loiIiEihOtUPAWD7kUSS0zPx977Ir/mnDsK2L8GZWvDjRnZJOhMHSbHm9Zk4cGWeXaduVxj6MfiHXuKncG8qTiJ5bD22lQdXPMiJtBPU8K3BW33eokW1FlbHEhEREbmg2lV9qV3Vl5hTqUQeOkX3xkWUmBP74NeZ8Mdn+UtQcfiFQutboP8L4OFdstcoR1ScRLItiV7C06ufJj0rneYhzXmz95uE+4dbHUtERETkolxZP5iYyFQ27D9ReHFK2AO/zoCtn4ORZS6r3wNqXOAPxb4hEBAGVcLPXlepAQ7Py/8h3JiKk1R6LsPFf/74D2//8TYA19S5hn9f82+d1FZERETKlU71Q/g28kjBxznF74Rf/g1/fm3ufgfQuB/0fAIiOpdt0HJKxUkqtRRnCs+seYZlB5YBcFeLu3is02M47A6Lk4mIiIgUT+cG5nFOWw6ewpnlwtNhhywn/DTFPDEt2ed4ano99Hwcane0LGt5pOIklVZsciwPrXiIHSd24GH34LmrnuPmJjdbHUtERESkRBpXr0JVP09OpTj580gi7YNS4IsR5ux3AM1vMLcw1WxnbdBySsVJKqXI+EjGrxzP8bTjhPiE8Oq1r9IhrIPVsURERERKzG630aleMD/tiCdm04+03/UMpCSAdyAMfhta3Gh1xHJNxUkqne/2fMfUdVNxupw0DW7Km73fpFaVWlbHEhEREblkV9arSvNd/+H6yC8BA8LawK0fQrVGVkcr91ScpNJwGS5e2/wac7fPBaB3RG9e6vGSJoEQERGRiiHlBLfteYwgz1UAGFcMwzbw3+Dpa22uCkLFSSqFjKwMnlnzDD/u/xGA+9vez9j2Y7Hb7BYnExEREblEqadg91JY/jxBpw+RZnjybOYIHuj6HI1Vmi4bFSep8M5knGH8qvH8dvQ3PGwePN/9eW5spH18RUREpBw7dRCifoSdC+HAmrMnsQ1pyHOOx/jiUFWu2H+SxjUCrM1Zgag4SYWWkJrAP3/6JztP7MTXw5fXrn2NbrW7WR1LREREpPiO7zVPXBu1EGK35X+senNz8oduDxL+Sywc2sPv0Se4o0tda7JWQCpOUmFFn45m9E+jiTkTQ4hPCG/3eZtWoa2sjiUiIiJSPLHb4NeZ8Ne3Z09ea7NDxFXQfCA0G5hv8ocrG2QAFHwiXCkxFSepkLYnbGfMT2M4mX6SiIAIZvedTd1A/cVFREREypGD6+HXV8zjl3I07gutboGmA8A/tMCnXVE3GLsNDp9M5ejpVGoG6Tiny0HFSSqc1TGrmbBqAqmZqbSs1pJZfWYR6lvwLxYRERERt2IYsHe5uYXpwBpzmc1ulqWrH4Hw1kW+RBVvD1rVCmJbzGk27D/B39rXLuXQlYOKk1QoP+z7gWdXP0umkUm3Wt2Yee1M/D39rY4lIiIiUrST0fDNaDi4zrzv8IJ2t0P3h4t9HqYr64ewLeY0v0erOF0uKk5SYXz818dM/306AAMbDOSF7i/g6fC0OJWIiIjIRdj6BSycAOmJ4OkHne6FrmMhsFaJXu7K+sF8sGY/G6NPXuaglZeKk5R7hmHw5pY3mbNtDgB3tbiLx698XOdoEhEREfeXlgiLHoOtC8z7EVfBLe9CcL1LetlO9UMAiIpL4nSKkyA//TH5UumbpZRrWa4spq2flluaHrziQZ648gmVJhEREXF/h36H2Vebpclmh2snwT0LL7k0AVQP8KZhqD+GARsPaHa9y0FbnKTcysjKYOKvE1l2YBl2m51nrnqGIU2HWB1LRERE5MJcWebkD6teAiMLgurC3+dA3asu69t0qh/MvoRkNkSfoE+LsMv62pWRipOUS8nOZB5e8TC/xf6Gp92T6ddMp1+9flbHEhEREbmwuD/hhwlwaL15v80QGPQK+ARd9re6sn4In288rOOcLhMVJyl3ElITGLt8LH8d/ws/Dz/e6P0GXWp2sTqWiIiISOHSEuHn6bD+HXMrk1eAWZjaDS21t+zcwDzOaevhU6Q5s/DxdJTae1UGKk5Sruw9tZcxP43hSPIRQnxCeLvv27Sq1srqWCIiIiIFMwzY/hUseRrOxJrLWtwEA16EqhGl+tZ1Q/yoHuDNsaR0Ig+d4qqG1Ur1/So6HUEv5cb6o+sZtmgYR5KPUC+wHv+9/r8qTSIiIuK+4nfChzfCVyPN0hTSEO78CoZ+VOqlCcBms9E5e3a9jdGaIOJSaYuTlAvf7P6G59c9T6aRSYcaHXi91+tU9alqdSwRERGR853YBxvegw3/AVcmePhAj0eh20Pg6VOmUa6sH8zCbUfZoOOcLpmKk7g1l+HirS1v5U43PrDBQKZ1n4aXw8viZCIiIiJ5OFPhr//Blo8g+tezy5teD9e/DMH1LYl1ZfZxTpsPnCTLZeCw2yzJURGoOInbSs9K55nVz7A4ejEAD7R9gLHtx2Kz6R+8iIiIuIkjkWZZ2voFpJ/OXmiDRr2hy2ho2t/KdDQPDyTA24Ok9Ex2HE2kde3LP3tfZeEWxzjNmjWL+vXr4+PjQ5cuXdiwYUOh686ZM4cePXoQHBxMcHAwffv2veD6Uj6dTj/NfUvvY3H0YjxsHkzrPo1xV4xTaRIRERHrZaTApg9hdg94tyf8/p5ZmoLqwrVPwfhtMOxry0sTgMNuo0O9YADW7EmwOE35ZnlxWrBgARMmTGDy5Mls3ryZdu3aMWDAAOLj4wtcf9WqVdx+++2sXLmSdevWERERQf/+/YmJiSnj5FJaElITGLFkBFvitxDgGcDsfrMZ3Hiw1bFERESksju+15wdb2Zz+P4hiN0KDi9odQsM+xYe/gOufbJMJn4ojr4tzZPfzl0TTZozy+I05ZflxWnmzJncd999jBgxgpYtWzJ79mz8/Pz44IMPClz/k08+YcyYMbRv357mzZvz3nvv4XK5WL58eRknl9IQmxzLiMUj2H1yN6G+ofz3+v/qHE0iIiJiHZcLdi2Bj/8Bb3aAdW9B2mnzmKX+L8CjUTBkLjTqBXbLv1oXaEjHOtQM8iE2MY3PNhy0Ok65ZekxThkZGWzatIlJkyblLrPb7fTt25d169Zd1GukpKTgdDoJCQkp8PH09HTS09Nz7ycmJgLgdDpxOp2XkP7yyMngDlmsFnMmhtHLRxOTHEO4Xzize8+mbpW6+tkUQONGSkLjRkpKY0dKotyPG8OFbfuXOH79N7aT+81F2DAa9cHVaSRGoz5gyy5Kbv4ZHcA/ezbguf/tYNbKPfy9fU18vdzzZLhlPW6K8z42wzCMUsxyQUeOHKF27dqsXbuWrl275i5/4okn+Pnnn/ntt9+KfI0xY8awZMkS/vzzT3x8zp/eccqUKUydOvW85Z9++il+fn6X9gHksknISuCDMx+QaCQSYg9hRJURBNuDrY4lIiIilVBo0l+0iplP1dRoADIcfhwMuYbo6n1I9g6zNlwJZbrgX5EOTqTbuKluFn1qW1YB3EpKSgp33HEHp0+fJjAw8ILrlutZ9V5++WXmz5/PqlWrCixNAJMmTWLChAm59xMTE3OPiyrqh1MWnE4ny5Yto1+/fnh6elodxxJ7Tu3h1RWvkmgk0iCwAbN7z6a6X3WrY7k1jRspCY0bKSmNHSmJcjluju3EsXwK9r0/AWB4B+DqNh5bp1HU8/KnnsXxLlVGrRgmffMnvyb4MPXuHlTxdr8qUNbjJmdvtIth6U8rNDQUh8NBXFxcvuVxcXGEh4df8LkzZszg5Zdf5qeffqJt27aFruft7Y23t/d5yz09Pd3qH7G75Skrfx7/kweWP8Dp9NM0C27Gu/3fJcSn4N0u5XyVddzIpdG4kZLS2JGSKBfjJikWVr5oTituuMDuAZ3uxdbzSRz+objnTm3FN6RTXd79NZr9Ccl8suEw43o3sTpSocpq3BTnPSw9gs3Ly4uOHTvmm9ghZ6KHvLvunev//u//mDZtGosXL6ZTp05lEVVKQWR8JKOWjOJ0+mnahLbh/QHvqzSJiIhI2Uk8Ys6S90YH2PyhWZpa3AhjfoOB/wb/UKsTXlYeDjvj+5pl6d1f9nE61b2PzXI3lk/9MWHCBObMmcOHH37Ijh07+Oc//0lycjIjRowA4O677843ecT06dN59tln+eCDD6hfvz6xsbHExsZy5swZqz6ClMDmuM08sOwBzjjP0KFGB97t9y5B3johm4iIiJSBY7vgu7HwWltzljxnMtS5Eu5dAkM/htDGVicsNTe0rUWTGlVITMvk/V/3WR2nXLF8x8ahQ4dy7NgxnnvuOWJjY2nfvj2LFy8mLMw88O7gwYPY80zt+M4775CRkcE//vGPfK8zefJkpkyZUpbRpYR+j/2dscvHkpqZSpfwLrzR+w38PDVRh4iIiJSywxth9auwcyGQPTlCve5w9SPQuC/YbJbGKwsOu40J/Zryz08288GaaEZ0b0Cwv5fVscoFy4sTwLhx4xg3blyBj61atSrf/ejo6NIPJKXmt6O/MW75ONKy0uhasyuv934dXw9fq2OJiIhIRWUYsHeFWZiifz27vNkguHo8RHS2LJpVBrQKp2XNQP46msh/ftnHxOubWx2pXLB8Vz2pPNYeWcvY5WNJy0qje+3uvNnnTZUmERERKR0uF+z4Aeb0go9vMUuT3QPa32kew3T7p5WyNAHYs7c6AXy4NppjSelFPEPATbY4ScW3OmY1D694mAxXBtfUuYZXr30VL4c2C4uIiMhllpUJf34Nv86EYzvMZR6+0PEe6DYOgupYGs9d9GlRg3YRVfnj0Clm/7yXZ29oaXUkt6fiJKXul8O/MH7leJwuJ70ievFKz1fwdLj5tKQiIiLiftKT4OSBwh+P2QirX4OT+8373oHQ+T64akyFmyHvUtlsNh7t15S7P9jAR+sP0KdFDfy9zq8GDruNpmEBeHloRzUVJylVKw6u4NGfHyXTlUm/ev2Yfs10PO0qTSIiInKRTkbDriUQ9SNErwbXRUyh7RsCXcfAlfeBb9XSTlhu9WgSypX1g/k9+iR3zPmt0PUGta3JrDs6lGEy96TiJKVmSfQSJv4ykUwjkwH1B/BSj5dUmkREROTCXFlwaAPsWmxeju3M/7hvCBS254pPkLlLXsd7wMu/tJOWezabjck3tmLC55Ekp2cVuM6R06ks3HqU8X2SaBIWUMYJ3YuKk5SKhfsW8tTqp3AZLgY1HMQL3V/Aw67hJiIiIoUwDPjzG/hpCpzKszuezQH1ukHTAdD0+gp9jiUrtK4dxNJHehb6+AMfbWTJn3G8+8s+/j2kXRkmcz/6JiuX3Te7v2Hy2skYGAxuPJgpXafgsDusjiUiIiLu6uBvsPRpOPy7ed+nKjTpb5alxn3AN9jSeJXZ6J6NWPJnHN9GxjChf1NqBlXeGZFVnOSy+jzqc6atnwbArU1v5emrnsZu08GEIiIiUoAT++CnqfDXt+Z9T3/o/rA5+512tXMLV9QNpnODEDbsP8HcNdE8NbCF1ZEso2+0ctl8suOT3NJ0Z4s7eeaqZ1SaRERE5HwpJ2DJ0/BWZ7M02ezQ4W54aDNc+6RKk5v5Z89GAHz620FOp17E5BwVlLY4yWUxb/s8Xtn0CgAjWo3gkY6PYLPZLE4lIiIibsEw4Phe2LMMdi+F6DWQlX3S1UZ9oP80CGtlbUYp1LXNqtMsLICouCQ++e0AY66tnMeZqTjJJftg+we8uulVAO5vez/j2o9TaRIREansnCnUOP0H9iW/wN6fzGnF86rRCvo/D437WhJPLp7NZuP+axry6Bd/MHdNNPd2b4CPZ+U7fl3FSS7J51Gf55amse3HMrrdaIsTiYiIiCWyMuHIZtj3M+z/GY9DG+ialQ77sh+3e5qz4zXpB437QfVmoD+0lhs3ta/FK0ujOHI6jW+2xHB757pWRypzKk5SYov3L+aF9S8AcF+b+1SaREREKhNXFsT/Bft/hf0/m7vfZSTlPmwDUjyr4d36BhzNBkCDa8C7cp8HqDzzdNi59+oGvLBwB3N+2cetnSJw2CtX8VVxkhJZHbOaSasnYWBwa9NbefCKB62OJCIiIqXFMMxzK8VsgpjN5uXoH+BMzr+eT1Vo0AMa9MRZtzvL1u9i4MBBODwLOWGtlCu3d67Lmyv2sC8hmWV/xXJd65pWRypTKk5SbJHxkTyy8hEyXZlcX/96nurylI5pEhERqUjOxJvl6Mjms9cpx89fz6sKRHSGBj2hYU8Ibws55250OsG2u2xzS6ny9/Zg2FX1eGvlHt75eR8DWoVXqu+AKk5SLFEnohizfAxpWWl0r92df139L53cVkREpDxLPQVHtuQpSVsgMeb89eyeEN4aaneEWh2gdgcIbXq2KEmlcE/3+rz76z7+OHSK3/af4KqG1ayOVGZUnOSiHUo8xAPLHiApI4kralzBq9e+iqdDm95FRETKjSwnxP0JMRvh8CbzOmFXASvazMkbanWAWleYZSm8NXh4l3lkcS+hVbwZ0rEOn/x2kP/8vFfFSeRc8Snx3LfsPo6nHadZcDPe6vMWvh6+VscSERGRgmRmmMckHd9z9hK/E45GQmba+etXrWduQcrZklSznSZykELd16Mhn204yMqoY+yMTaR5eKDVkcqEipMUKT4lnvuW3kfMmRgiAiKY3W82gV6V4x+IiIiI20s5AYc3wqHfIHarWZJOHgAjq+D1fYLMLUi1O2Vfd4Qq1cs2s5Rr9UP9ub51TRZuO8o7q/by+m1XWB2pTKg4yQXFJscycslIDiYdJMwvjHf7vUuob6jVsURERConlwuO7zZL0qHf4NCGQna1Azz9oVqj7EtjqNbE3JoU0gjs9rLNLRXO6J6NWLjtKN9FHuHvHepwTdOKX75VnKRQh5MOM2rpKGLOxFC7Sm3e6/8edQLqWB1LRESk8shIMSdtOLj+bFFKO3X+etUaQ0SX7Akbmpn3A8J1glkpNW3qBDG8az0+XHeAJ7/ayuLx1xDkW7GPfVdxkgIdSDzAyCUjiUuJo25AXd4f8D7h/uFWxxIREam4Uk/C8X3mrnZHI82yFLsVXJn51/PwNXevi+hslqU6V4J/5TlAX9zHk9c35+ddx4g+nsLz3//FK7e2szpSqVJxkvPsPbWXUUtHkZCaQMOghrzX/z2q+1X8za8iIiKlzjAg8Yi5FenYzrNF6cTegs+TBBBQ0yxIda8yy1J4W9CstuIG/Lw8mDGkHUP+s46vNh/mutbh9GsZZnWsUqPiJPlEnYji/mX3cyLtBE2CmzCn3xyq+eqvWCIiIiWSetI8L1LMJvMcSTGb4Uxs4esH1DR3s6ve/GxRCorQLnfitjrVD+H+Hg35zy/7mPT1NjrVCybY38vqWKVCxUly/Xn8Tx5Y9gCn00/TIqQF7/Z7l6o+Va2OJSIi4h4Mwzwx7NGtELvN3I0ufgdkpheyfhYkHT1/uc0BYS0hrPXZiRtCGkFIQ/CuUrqfQaQUPNKvKSt2xrM7/gzPfredt+7oYHWkUqHiJABsid/CmJ/GcMZ5hrahbXmn3zuaclxERCo3VxYcWAu7l8LRP8yylHqi+K8TXP/stN+1O5q72nn5Xfa4Ilbx8XTwyq3tuPnttfyw9SjXtT7CDW1rWR3rslNxEtYeWcv4leNJzUylY1hHZvWZhb+nv9WxREREyl6WE/b/DH/9D3YuhJSE/I/bPczd6MLbmAUorBX4XOAPjUF1NXGDVApt61Rl7LWNeGPFHp79djtdGlSjeoC31bEuKxWnSm75weU8/vPjOF1OutfuzqvXvoqvh6/VsURERMqGy2XuTnf0D9jxP4haBGmnzz7uUxWaDYR6Xc2yVL0FePpYFlfEnY3r3YSfdsTz19FEJn29jTl3d8RWgY7PU3GqxL7f+z3PrnmWLCOLfvX6Mb3HdDw1S4+IiFQ0mRlwMhpO7IOT++HEfvP+yf1w8gBknXOMkn8NaHEDtLgJ6l+tGexELpKXh51Xbm3HTW+t5qcdcXy9OYa/d6w45wBVcaqkPo/6nBfWv4CBwd8a/Y0p3abgYddwEBGRcsrlgsTDkLAr/xTfx/fAqYNguAp/rt3DPA6pcT9oeZM59bfdUWbRRSqSFjUDGd+3Kf9eEsVz322nZa1AWtSsGMfN65tyJTR3+1xmbpoJwO3Nb2di54nYbXaLU4mIiFwElwtOHYBjUeZ5kPJeO5MLf56nP1RrCMENIKSBeR1c37wdWAcc+kokcrk8cE1Dft19jPX7TnDvvN/5dmx3wgLL/y6u+i1RiRiGwZtb3mTOtjkA3NfmPh684sEKte+piIhUIGmJEP+XOZtd3HaI+xPi/iq8INk9zSm9Q5uY19Uan53uu0qYzoUkUkY8HHb+c1cnbn5nDfuOJXPvvN/5/IGu+HuX7+pRvtPLRUtxpvDMmmdYdmAZAOM7jGdkm5EWpxIREQHSz5i72CXsOrv1KO5Pc8tSQRzeENoUqjczZ7jLuQ5poOORRNxEkJ8n8+7pzM1vr+HPI4k89NkW3r27Ew57+f0DhopTJXAo8RAPrXyIPaf24GH34NmrnuWWJrdYHUtERCqTzAzzWKPcyRn2ZxelKDh9qPDnBdSC8NbmyWJzrkMaadc6kXKgbjU/5gzvxO3vrmf5znim/fAXU25qZXWsEtNvnQpu7ZG1PP7z4yRmJBLqG8qr175K+xrtrY4lIiIVUd4JGo5lb0HKmcnu9OELT9DgX93cahTa1Lyu0dwsSX4hZZdfRC67DnWDeXVoe8Z8spl5a6OpG+LHvVc3sDpWiag4VVCGYfDhnx/y6uZXcRku2oa25dVer1LDr4bV0UREpDwzDEg5nj29d54tRwm7IGE3OFMKf66nX57JGeqbxx7l7GqngiRSYQ1sU5NJ1zfnpR93Mm3hX9QJ9qV/q3CrYxWbilMFlJqZypS1U1i0fxEAgxsP5pmrnsHbUbHO3iwiIqXAMCD1pLn73KlDcPow9pPRdN63AY85083jjjLOFP58u6c5IUNoU/NSrfHZWeyq1NAEDSKV1P3XNCT6eAqfbTjIw/MjWfDAVbStU9XqWMWi4lTBxCXH8eCKB9lxYgceNg+e6PwEtzW7TTPniYiIKSsTzsRml6JD5nFHpw/nK0rnzlrnAGrmW2KDwFrmVqPcLUfNzKIUXF8TNIjIeWw2G9P+1oqYU6n8susYIz/cyDdjulEn2M/qaBdNxakC2XliJ2OXjyU+JZ5g72BeufYVrgy/0upYIiJSmtLPQMwmOPSbeTl1gYkWnKmQGANGVtGv618dgiKgagRZAbX4MyaZlt0H4lG9sbncs/yfk0VEypaHw86sO65gyOx1nEnPJM15geMe3ZCKUwXxy+FfeOznx0jNTKVRUCPe6vMWdQLqWB1LREQuF5fL3IUuOd6cqjunKMVuv7gilJfdAwJrQ9W6EFQntyARlHOpDZ6+Z9/a6WT/okW0aNwXPLU1SURKLsDHk7kjrsTDbqd6QPk6jETFqQL4bOdnvLzhZVyGiy41uzDz2pkEegVaHUtERC6Gy2VOtpB4GBKPmJfTh+FMHJyJN4vSmWOQfKzwghQUARGdIaKLucuczVHweh7eZmEKCAd7IeuIiJSymkG+Ra/khlScyrEsVxYzNs7g4x0fA3BLk1t45qpn8LTrr4EiIpbLzDALUXK8WYCSYs+WoZzrxBhIOgpZGRf/ur7B5nFEEV3OXoJql9rHEBERk4pTOZXiTOHJX59k1aFVADzc4WFGth6pSSBEREqLMxWSEyAlAZKPZ18n5Lk+nv/x9NPFeHEbVAkzJ1wIrGXuPlclzJyFzr8GVKluXvtXBw+vUvuIIiJSOBWnciguOY6HVj7EX8f/wsvuxYs9XmRA/QFWxxIRKT8MwzzfUE7hSTmRXXiOmctyC1Ce++fMNHdRbPbs4lMjuwiF5bld42xRCqipmehERNycilM5s/XYVh5e+TAJqQmE+ITweq/XaV+jvdWxRERKn8tl7tp2fDekJRa+XlYGpJ6CtNOQlnOdfUk9ebYkZaYVP4PdE/xDwS8U/KtlXxd2PxR8qoLdXsIPLCIi7kTFqRz5fu/3TFk7hQxXBo2rNubN3m9q5jwRqThcLnP3tpQTZsE5GQ0JuyBht1mWju81txJdTg7v7KITcrbs+FcHv2rmdb77oeAdqBO4iohUUipO5UCWK4vXN7/O3D/nAtA7ojcv9ngRf09/i5OJiBQiIwVST5i7waWePLulJ+d27v0TZ69TT4JRxDk97B4Q3MAsMRRSYBye4BMEvlXNa58gc8uPT/Z9/2pmEfILBS9/FSEREbkoKk5uLikjiSd+eYLVMasBuL/t/YxtPxa7Tbt+iMhllHrKnOWtMK5Mc7e3vMXn3BKUtwhlppY8i1cV8A0xZ4qr1hhCm0BoU6jWBILr6VggERGxhIqTG4s+Hc2DKx4kOjEaH4cP07pP47oG11kdS0TKE8OAjGTz+J4zx6meuB3b5mOQeMjcFS7nknbq8r+33dPcBc43xJxC2y/E3ArkG3zOspD81x7l64SIIiJSOag4ual9p/dx16K7SMpIIswvjDd6v0HLai2tjiUiZckwIDMd0hMhPcksP7m3E8/eT0s0jw1KS8y+fzr/xZUJgCfQDWBvIe/nHVT4RAY2R/bub8EFXKqau77lFJ+cEuQdoN3gRESkwlBxclNf7vqSpIwkWlZryaw+swj1DbU6kogUxTDMY3pOHzZnfzsdA2diwZVV2BPMrUHpSWfLUHpi/nLkcl6ebHYPDJ+qnHF54V+nFfaQhuZJVHMv9czjfURERKRAKk5uam3MWgDubX2vSpNIWcjKhIwzZpHJSC7kdp7r9Dy3005D4hGzLJVkiuuL4R1obsHJufYJNG/nvfapmv923gkSPP3IzMxkxaJFDBw4ELunjhMSEREpDhUnNxSbHMve03ux2+xcVfMqq+OIuBfDMMtJRoo5AYEzzyUzFZxpBRScM/lv52zhyblknLm801z71zAnNgisbZ7c1OFV+LqeftnlJ6cU5dzOU468quhcQCIiIhZTcXJDa2LWANAmtA1B3kEWpxG5SC6XuVuZKxOynObuaa5Mc5kzLX/JyUwzi4ozDZzJebbsnLOlJz2p4C08RmG7vl0Gdg+zqHhVMXdd8/IH7yrgmX3t5X/28Zz73oEQEH62KGlyAxERkQpHxckNrTliFqfutbpbnKQQhpH9pdiZ/QU507wYLvMxwwUY+e/nrJN3/byXrHOXZeUe0G4eXG7Lf22zgc1uXshzO3eZYb533uuc7OfKe/C6zW5+cbY7zBnB7B5n79vs2Vkzsj+HMzt39s8h573yvm/ec9LY7Od/BmzZP58sswzku3aZr5uVcfY9su/bMzNoe2gv9kU/AdnPzy0qmWc/b855bnI/Y96fo/1sppyfI0ae98z5rBnm58xKh8wMs/Rkpmffz76dmZ7nPcuQwws8fMHTFzx9zK03Hj55yk1O2alibsHJWZ53lzfvPPe9/FV6REREpEAqTlY69Dv2w5tpGB+Jfe0eMDLJzExj/ZGVAHTb/zsc2nlOASD7NvkLiZH3i3PW2WU5JSfvl3LDZW4dyL1dwPLzvshnL88pDGIpB9AAIMHiIEXJKaIeOcXGN0/R8T2n5PjlLzyefueUnSrnbwmyO6z+hCIiIlJJqDhZacd3ONa+SRuAGHPRdm8vkmqFE5iVRes/vrIyXfHl2/pjy3/b7gmOnK03eW9n37c78tzP2eKT/aX43C1HRp6tR4argEsW522hOu+aPK+dh3FO+czdQpZdIB2e2fk989+2exSwRcl+9na+LXF5tkQZruxy4TCne853bTe3qOR7L/N+Fg5279tPk2YtcHh45v/Z5d3qVuBndOX5WbrIt2XQZjPfw+6R5729zr6/h7dZdjx8sm9nXxze2eucu6VOx+WIiIhIxaDiZKWwNria38iRuGPUimiA3dOHNWkHIGUPXavUx3Ht3eaXaMje4yrvl37b2bKR80U7d5eyvLdt+b+I594ubLn97Bf5vK+duyxPUchXHPSX/7LkcjqJSl1Eo6sH4tDsaCIiIiKlTsXJSu2GktXyFjYtWkRY9vTAaxfeCSnQ/Yr7oMnNVicUERERERFA+9G4kVNpp9iWsA2ArrW6WpxGRERERERyqDi5kfVH12Ng0LhqY8L9w62OIyIiIiIi2VSc3IjbT0MuIiIiIlJJqTi5CcMwWBuzFoButbtZnEZERERERPJScXITe07vIT41Hh+HDx3DOlodR0RERERE8lBxchPrjq4DoFN4J7wd3hanERERERGRvFSc3EROcdLxTSIiIiIi7kfFyQ1kGBlsjt8M6PgmERERERF3pOLkBvZn7sfpclLLvxYNAhtYHUdERERERM6h4uQG9jj3AObWJpvNZnEaERERERE5l4qTG9iduRvQ8U0iIiIiIu5KxcliR84cIcGVgMPmoEvNLlbHERERERGRAqg4WWztUfOkt21C2xDgFWBxGhERERERKYiKk8VypiHvVlOz6YmIiIiIuCsVJws5XU42xG4AoGvNrhanERERERGRwrhFcZo1axb169fHx8eHLl26sGHDhguu/8UXX9C8eXN8fHxo06YNixYtKqOkl9fWY1tJzkzGz+ZHi5AWVscREREREZFCWF6cFixYwIQJE5g8eTKbN2+mXbt2DBgwgPj4+ALXX7t2LbfffjsjR45ky5YtDB48mMGDB7N9+/YyTn7p1sSsAaCxR2PsNsv/U4iIiIiISCEs/7Y+c+ZM7rvvPkaMGEHLli2ZPXs2fn5+fPDBBwWu//rrr3Pdddfx+OOP06JFC6ZNm0aHDh146623yjj5pQv3D6d5cHOaeDaxOoqIiIiIiFyAh5VvnpGRwaZNm5g0aVLuMrvdTt++fVm3bl2Bz1m3bh0TJkzIt2zAgAF8++23Ba6fnp5Oenp67v3ExEQAnE4nTqfzEj/Bpbm54c3cEHEDS5cutTyLlC8540XjRopD40ZKSmNHSkLjRkqirMdNcd7H0uKUkJBAVlYWYWFh+ZaHhYWxc+fOAp8TGxtb4PqxsbEFrv/SSy8xderU85YvXboUPz+/Eia/vGw2G8uWLbM6hpRDGjdSEho3UlIaO1ISGjdSEmU1blJSUi56XUuLU1mYNGlSvi1UiYmJRERE0L9/fwIDAy1MZnI6nSxbtox+/frh6elpdRwpJzRupCQ0bqSkNHakJDRupCTKetzk7I12MSwtTqGhoTgcDuLi4vItj4uLIzw8vMDnhIeHF2t9b29vvL29z1vu6enpVv+I3S2PlA8aN1ISGjdSUho7UhIaN1ISZTVuivMelk4O4eXlRceOHVm+fHnuMpfLxfLly+nateDzGnXt2jXf+mBuyitsfRERERERkUtl+a56EyZMYPjw4XTq1InOnTvz2muvkZyczIgRIwC4++67qV27Ni+99BIADz/8MD179uSVV15h0KBBzJ8/n40bN/Luu+9a+TFERERERKQCs7w4DR06lGPHjvHcc88RGxtL+/btWbx4ce4EEAcPHsRuP7thrFu3bnz66ac888wzPPXUUzRp0oRvv/2W1q1bW/URRERERESkgrO8OAGMGzeOcePGFfjYqlWrzls2ZMgQhgwZUsqpRERERERETJafAFdERERERMTdqTiJiIiIiIgUQcVJRERERESkCCpOIiIiIiIiRVBxEhERERERKYKKk4iIiIiISBFUnERERERERIqg4iQiIiIiIlIEFScREREREZEiqDiJiIiIiIgUQcVJRERERESkCB5WByhrhmEAkJiYaHESk9PpJCUlhcTERDw9Pa2OI+WExo2UhMaNlJTGjpSExo2URFmPm5xOkNMRLqTSFaekpCQAIiIiLE4iIiIiIiLuICkpiaCgoAuuYzMupl5VIC6XiyNHjhAQEIDNZrM6DomJiURERHDo0CECAwOtjiPlhMaNlITGjZSUxo6UhMaNlERZjxvDMEhKSqJWrVrY7Rc+iqnSbXGy2+3UqVPH6hjnCQwM1C8VKTaNGykJjRspKY0dKQmNGymJshw3RW1pyqHJIURERERERIqg4iQiIiIiIlIEFSeLeXt7M3nyZLy9va2OIuWIxo2UhMaNlJTGjpSExo2UhDuPm0o3OYSIiIiIiEhxaYuTiIiIiIhIEVScREREREREiqDiJCIiIiIiUgQVJxERERERkSKoOJWyWbNmUb9+fXx8fOjSpQsbNmy44PpffPEFzZs3x8fHhzZt2rBo0aIySirupjhjZ86cOfTo0YPg4GCCg4Pp27dvkWNNKqbi/s7JMX/+fGw2G4MHDy7dgOKWijtuTp06xdixY6lZsybe3t40bdpU/7+qpIo7dl577TWaNWuGr68vERERPPLII6SlpZVRWnEHv/zyCzfeeCO1atXCZrPx7bffFvmcVatW0aFDB7y9vWncuDHz5s0r9ZwFUXEqRQsWLGDChAlMnjyZzZs3065dOwYMGEB8fHyB669du5bbb7+dkSNHsmXLFgYPHszgwYPZvn17GScXqxV37KxatYrbb7+dlStXsm7dOiIiIujfvz8xMTFlnFysVNxxkyM6OprHHnuMHj16lFFScSfFHTcZGRn069eP6OhovvzyS6KiopgzZw61a9cu4+RiteKOnU8//ZSJEycyefJkduzYwfvvv8+CBQt46qmnyji5WCk5OZl27doxa9asi1p///79DBo0iF69ehEZGcn48eMZNWoUS5YsKeWkBTCk1HTu3NkYO3Zs7v2srCyjVq1axksvvVTg+rfeeqsxaNCgfMu6dOliPPDAA6WaU9xPccfOuTIzM42AgADjww8/LK2I4oZKMm4yMzONbt26Ge+9954xfPhw429/+1sZJBV3Utxx88477xgNGzY0MjIyyiqiuKnijp2xY8cavXv3zrdswoQJRvfu3Us1p7gvwPjmm28uuM4TTzxhtGrVKt+yoUOHGgMGDCjFZAXTFqdSkpGRwaZNm+jbt2/uMrvdTt++fVm3bl2Bz1m3bl2+9QEGDBhQ6PpSMZVk7JwrJSUFp9NJSEhIacUUN1PScfP8889To0YNRo4cWRYxxc2UZNz873//o2vXrowdO5awsDBat27Niy++SFZWVlnFFjdQkrHTrVs3Nm3alLs73759+1i0aBEDBw4sk8xSPrnT92OPMn/HSiIhIYGsrCzCwsLyLQ8LC2Pnzp0FPic2NrbA9WNjY0stp7ifkoydcz355JPUqlXrvF80UnGVZNysXr2a999/n8jIyDJIKO6oJONm3759rFixgjvvvJNFixaxZ88exowZg9PpZPLkyWURW9xAScbOHXfcQUJCAldffTWGYZCZmcno0aO1q55cUGHfjxMTE0lNTcXX17fMsmiLk0gF8/LLLzN//ny++eYbfHx8rI4jbiopKYlhw4YxZ84cQkNDrY4j5YjL5aJGjRq8++67dOzYkaFDh/L0008ze/Zsq6OJm1u1ahUvvvgib7/9Nps3b+brr79m4cKFTJs2zepoIhdFW5xKSWhoKA6Hg7i4uHzL4+LiCA8PL/A54eHhxVpfKqaSjJ0cM2bM4OWXX+ann36ibdu2pRlT3Exxx83evXuJjo7mxhtvzF3mcrkA8PDwICoqikaNGpVuaLFcSX7f1KxZE09PTxwOR+6yFi1aEBsbS0ZGBl5eXqWaWdxDScbOs88+y7Bhwxg1ahQAbdq0ITk5mfvvv5+nn34au11/z5fzFfb9ODAwsEy3NoG2OJUaLy8vOnbsyPLly3OXuVwuli9fTteuXQt8TteuXfOtD7Bs2bJC15eKqSRjB+D//u//mDZtGosXL6ZTp05lEVXcSHHHTfPmzdm2bRuRkZG5l5tuuil31qKIiIiyjC8WKcnvm+7du7Nnz57cog2wa9cuatasqdJUiZRk7KSkpJxXjnIKuGEYpRdWyjW3+n5c5tNRVCLz5883vL29jXnz5hl//fWXcf/99xtVq1Y1YmNjDcMwjGHDhhkTJ07MXX/NmjWGh4eHMWPGDGPHjh3G5MmTDU9PT2Pbtm1WfQSxSHHHzssvv2x4eXkZX375pXH06NHcS1JSklUfQSxQ3HFzLs2qVzkVd9wcPHjQCAgIMMaNG2dERUUZP/zwg1GjRg3jhRdesOojiEWKO3YmT55sBAQEGJ999pmxb98+Y+nSpUajRo2MW2+91aqPIBZISkoytmzZYmzZssUAjJkzZxpbtmwxDhw4YBiGYUycONEYNmxY7vr79u0z/Pz8jMcff9zYsWOHMWvWLMPhcBiLFy8u8+wqTqXszTffNOrWrWt4eXkZnTt3NtavX5/7WM+ePY3hw4fnW//zzz83mjZtanh5eRmtWrUyFi5cWMaJxV0UZ+zUq1fPAM67TJ48ueyDi6WK+zsnLxWnyqu442bt2rVGly5dDG9vb6Nhw4bGv/71LyMzM7OMU4s7KM7YcTqdxpQpU4xGjRoZPj4+RkREhDFmzBjj5MmTZR9cLLNy5coCv7PkjJXhw4cbPXv2PO857du3N7y8vIyGDRsac+fOLfPchmEYNsPQtlEREREREZEL0TFOIiIiIiIiRVBxEhERERERKYKKk4iIiIiISBFUnERERERERIqg4iQiIiIiIlIEFScREREREZEiqDiJiIiIiIgUQcVJRERERESkCCpOIiLillatWoXNZuPUqVNl+r7z5s2jatWql/Qa0dHR2Gw2IiMjC13Hqs8nIiIlo+IkIiJlzmazXfAyZcoUqyOKiIjk42F1ABERqXyOHj2ae3vBggU899xzREVF5S6rUqUKGzduLPbrZmRk4OXldVkyioiI5KUtTiIiUubCw8NzL0FBQdhstnzLqlSpkrvupk2b6NSpE35+fnTr1i1fwZoyZQrt27fnvffeo0GDBvj4+ABw6tQpRo0aRfXq1QkMDKR379788ccfuc/7448/6NWrFwEBAQQGBtKxY8fzitqSJUto0aIFVapU4brrrstX9lwuF88//zx16tTB29ub9u3bs3jx4gt+5kWLFtG0aVN8fX3p1asX0dHRl/IjFBGRMqbiJCIibu3pp5/mlVdeYePGjXh4eHDvvffme3zPnj189dVXfP3117nHFA0ZMoT4+Hh+/PFHNm3aRIcOHejTpw8nTpwA4M4776ROnTr8/vvvbNq0iYkTJ+Lp6Zn7mikpKcyYMYOPPvqIX375hYMHD/LYY4/lPv7666/zyiuvMGPGDLZu3cqAAQO46aab2L17d4Gf4dChQ9xyyy3ceOONREZGMmrUKCZOnHiZf1IiIlKatKueiIi4tX/961/07NkTgIkTJzJo0CDS0tJyty5lZGTw3//+l+rVqwOwevVqNmzYQHx8PN7e3gDMmDGDb7/9li+//JL777+fgwcP8vjjj9O8eXMAmjRpku89nU4ns2fPplGjRgCMGzeO559/PvfxGTNm8OSTT3LbbbcBMH36dFauXMlrr73GrFmzzvsM77zzDo0aNeKVV14BoFmzZmzbto3p06dftp+TiIiULm1xEhERt9a2bdvc2zVr1gQgPj4+d1m9evVySxOYu+GdOXOGatWqUaVKldzL/v372bt3LwATJkxg1KhR9O3bl5dffjl3eQ4/P7/c0pTzvjnvmZiYyJEjR+jevXu+53Tv3p0dO3YU+Bl27NhBly5d8i3r2rXrRf8MRETEetriJCIibi3vLnQ2mw0wjzHK4e/vn2/9M2fOULNmTVatWnXea+VMMz5lyhTuuOMOFi5cyI8//sjkyZOZP38+N99883nvmfO+hmFcjo8jIiLllLY4iYhIhdKhQwdiY2Px8PCgcePG+S6hoaG56zVt2pRHHnmEpUuXcssttzB37tyLev3AwEBq1arFmjVr8i1fs2YNLVu2LPA5LVq0YMOGDfmWrV+/vpifTERErKTiJCIiFUrfvn3p2rUrgwcPZunSpURHR7N27VqefvppNm7cSGpqKuPGjWPVqlUcOHCANWvW8Pvvv9OiRYuLfo/HH3+c6dOns2DBAqKiopg4cSKRkZE8/PDDBa4/evRodu/ezeOPP05UVBSffvop8+bNu0yfWEREyoJ21RMRkQrFZrOxaNEinn76aUaMGMGxY8cIDw/nmmuuISwsDIfDwfHjx7n77ruJi4sjNDSUW265halTp170ezz00EOcPn2aRx99lPj4eFq2bMn//ve/8yaZyFG3bl2++uorHnnkEd588006d+7Miy++eN4MgSIi4r5shnbaFhERERERuSDtqiciIiIiIlIEFScREREREZEiqDiJiIiIiIgUQcVJRERERESkCCpOIiIiIiIiRVBxEhERERERKYKKk4iIiIiISBFUnERERERERIqg4iQiIiIiIlIEFScREREREZEiqDiJiIiIiIgU4f8BWCg0KeMZfT0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dict = {\"Threshold\":[], \n",
    "             \"Recall\":[],\n",
    "             \"Precision\":[],\n",
    "             \"F1 Weighted\":[],\n",
    "             \"Ganhos Brutos\":[],\n",
    "             \"Perdas\":[],\n",
    "             \"Ganhos Líquidos\":[]}\n",
    "\n",
    "# Calculando as métricas para cada threshold\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "    predictions = (data_metrics[\"score_fraude_modelo\"] >= threshold).astype(int)\n",
    "    recall = recall_score(y_teste, predictions)\n",
    "    precision = precision_score(y_teste, predictions)\n",
    "    f1 = f1_score(y_teste, predictions, average=\"weighted\")\n",
    "    data_dict[\"Threshold\"].append(threshold)\n",
    "    data_dict[\"Recall\"].append(recall)\n",
    "    data_dict[\"Precision\"].append(precision)\n",
    "    data_dict[\"F1 Weighted\"].append(f1)\n",
    "    \n",
    "    data_metrics[\"label_fraude_modelo\"] = predictions\n",
    "    acertos = data_metrics.query(f\"fraude == 0 and label_fraude_modelo == 0\")\n",
    "    erros = data_metrics.query(f\"fraude == 1 and label_fraude_modelo == 0\")\n",
    "    ganhos = (acertos[\"valor_compra\"] * 0.10).sum()\n",
    "    perdas = erros[\"valor_compra\"].sum()\n",
    "    diff_ganhos_perdas = ganhos - perdas\n",
    "    data_dict[\"Ganhos Brutos\"].append(ganhos)\n",
    "    data_dict[\"Perdas\"].append(perdas)\n",
    "    data_dict[\"Ganhos Líquidos\"].append(diff_ganhos_perdas)\n",
    "        \n",
    "# Plotando o gráfico    \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"Recall\"], label='Recall')\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"Precision\"], label='Precision')\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"F1 Weighted\"], label='F1 Weighted')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Recall, Precision e F1 Weighted em diferentes thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Ganhos Brutos</th>\n",
       "      <th>Perdas</th>\n",
       "      <th>Ganhos Líquidos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.140762</td>\n",
       "      <td>0.843891</td>\n",
       "      <td>65912.190</td>\n",
       "      <td>19549.98</td>\n",
       "      <td>46362.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.656889</td>\n",
       "      <td>0.138260</td>\n",
       "      <td>0.838339</td>\n",
       "      <td>64916.138</td>\n",
       "      <td>18666.09</td>\n",
       "      <td>46250.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.627556</td>\n",
       "      <td>0.144376</td>\n",
       "      <td>0.849570</td>\n",
       "      <td>66744.637</td>\n",
       "      <td>20611.54</td>\n",
       "      <td>46133.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.587556</td>\n",
       "      <td>0.155786</td>\n",
       "      <td>0.865329</td>\n",
       "      <td>70014.224</td>\n",
       "      <td>23907.04</td>\n",
       "      <td>46107.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.151379</td>\n",
       "      <td>0.860041</td>\n",
       "      <td>68921.392</td>\n",
       "      <td>22849.33</td>\n",
       "      <td>46072.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.960889</td>\n",
       "      <td>0.050904</td>\n",
       "      <td>0.107224</td>\n",
       "      <td>4596.165</td>\n",
       "      <td>2524.54</td>\n",
       "      <td>2071.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.050722</td>\n",
       "      <td>0.093628</td>\n",
       "      <td>3830.730</td>\n",
       "      <td>2447.83</td>\n",
       "      <td>1382.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.050479</td>\n",
       "      <td>0.079154</td>\n",
       "      <td>3133.909</td>\n",
       "      <td>2094.57</td>\n",
       "      <td>1039.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.050439</td>\n",
       "      <td>0.065304</td>\n",
       "      <td>2313.644</td>\n",
       "      <td>1486.31</td>\n",
       "      <td>827.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold    Recall  Precision  F1 Weighted  Ganhos Brutos    Perdas  \\\n",
       "76       0.76  0.640000   0.140762     0.843891      65912.190  19549.98   \n",
       "75       0.75  0.656889   0.138260     0.838339      64916.138  18666.09   \n",
       "77       0.77  0.627556   0.144376     0.849570      66744.637  20611.54   \n",
       "80       0.80  0.587556   0.155786     0.865329      70014.224  23907.04   \n",
       "79       0.79  0.600000   0.151379     0.860041      68921.392  22849.33   \n",
       "..        ...       ...        ...          ...            ...       ...   \n",
       "4        0.04  0.960889   0.050904     0.107224       4596.165   2524.54   \n",
       "3        0.03  0.965333   0.050722     0.093628       3830.730   2447.83   \n",
       "2        0.02  0.968889   0.050479     0.079154       3133.909   2094.57   \n",
       "1        0.01  0.976000   0.050439     0.065304       2313.644   1486.31   \n",
       "0        0.00  1.000000   0.050000     0.004762          0.000      0.00   \n",
       "\n",
       "    Ganhos Líquidos  \n",
       "76        46362.210  \n",
       "75        46250.048  \n",
       "77        46133.097  \n",
       "80        46107.184  \n",
       "79        46072.062  \n",
       "..              ...  \n",
       "4          2071.625  \n",
       "3          1382.900  \n",
       "2          1039.339  \n",
       "1           827.334  \n",
       "0             0.000  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando os dados em forma de tabela\n",
    "pd.DataFrame(data_dict).sort_values(by=\"Ganhos Líquidos\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso maior ganho está no Threshold 0.76, onde o lucro líquido foi de 46362.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando os experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os dicionarios com os modelos e etapas de pre-processamento que serã utilizadas\n",
    "\n",
    "dict_models_scale_sensitive = {\"LR\": LogisticRegression(random_state=rs,\n",
    "                                                        class_weight='balanced')}\n",
    "\n",
    "dict_models_tree_based = {\"LGBM\": LGBMClassifier(is_unbalance=True,\n",
    "                                                 objective= 'binary',\n",
    "                                                 random_state=rs),\n",
    "                          \"XGB\": XGBClassifier(random_state=rs,\n",
    "                                               objective='binary:hinge'),\n",
    "                          \"RF\": RandomForestClassifier(class_weight='balanced',\n",
    "                                                       random_state=rs)}\n",
    "\n",
    "# Criando dicionário com os encoders\n",
    "dict_encoders = {\"OHE\": OneHotEncoder(drop='first'),\n",
    "                 \"TE\": ce.TargetEncoder(),\n",
    "                 \"BE\": ce.BinaryEncoder(),\n",
    "                 \"ME\": ce.MEstimateEncoder(),\n",
    "                 \"CE\": ce.CatBoostEncoder(),\n",
    "                 \"GE\":ce.GrayEncoder(),\n",
    "                 \"CTE\":ce.CountEncoder()}\n",
    "\n",
    "dict_imputers_num = {\"SIAVG\": SimpleImputer(strategy='mean'),\n",
    "                     \"SIMEDIAN\": SimpleImputer(strategy='median')}\n",
    "\n",
    "dict_scalers = {\"SS\": StandardScaler(),\n",
    "                \"RS\": RobustScaler()}\n",
    "\n",
    "# Criando dicionário com os transformers\n",
    "dict_transformers = {\"PT\": PowerTransformer()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando/acessando o experimento\n",
    "#mlflow.set_experiment('Comparando modelos base')\n",
    "#\n",
    "## Iniciando os experimentos sem transformers\n",
    "#for tag, model in dict_models_scale_sensitive.items():\n",
    "#\n",
    "#    # Gerando a tag de identificação do modelo\n",
    "#    nome_modelo = f'{tag}'\n",
    "#\n",
    "#    with mlflow.start_run(run_name=nome_modelo):\n",
    "#\n",
    "#        # Criando os pipeline com os transformers\n",
    "#        pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                            ('encoder', OneHotEncoder(drop='first'))])\n",
    "#    \n",
    "#        # Criando os pipeline com os transformers\n",
    "#        pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                        ('encoder_hd', ce.CatBoostEncoder())])\n",
    "#    \n",
    "#        pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "#                            ('scaler', StandardScaler())])\n",
    "#    \n",
    "#        # Criando o transformador\n",
    "#        transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                        ('num', pipe_num, num_cols),\n",
    "#                                        ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "#                                        remainder=\"passthrough\")\n",
    "#    \n",
    "#        # Criando o pipeline final\n",
    "#        pipe = Pipeline([('transformer', transformer),\n",
    "#                        ('model', model)])\n",
    "#    \n",
    "#        # Executando o cross validation\n",
    "#        cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='recall')\n",
    "#    \n",
    "#        # Calculando a média das métricas\n",
    "#        mean_score = cross_val_scores.mean()           \n",
    "#    \n",
    "#        # Salvando a métrica da folder 1\n",
    "#        mlflow.log_metric('recall_fold_1', cross_val_scores[0])\n",
    "#    \n",
    "#        # Salvando a métrica da folder 2\n",
    "#        mlflow.log_metric('recall_fold_2', cross_val_scores[1])\n",
    "#    \n",
    "#        # Salvando a métrica da folder 3\n",
    "#        mlflow.log_metric('recall_fold_3', cross_val_scores[2])\n",
    "#    \n",
    "#        # Salvando a métrica da folder 4\n",
    "#        mlflow.log_metric('recall_fold_4', cross_val_scores[3])\n",
    "#    \n",
    "#        # Salvando a métrica da folder 5\n",
    "#        mlflow.log_metric('recall_fold_5', cross_val_scores[4])\n",
    "#    \n",
    "#        # Salvando as métricas\n",
    "#        mlflow.log_metric('recall_mean', mean_score)\n",
    "#        \n",
    "#        # Salvando o f1 weighted\n",
    "#        mean_f1 = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='f1_weighted').mean()\n",
    "#        \n",
    "#        # Salvando a métrica do f1\n",
    "#        mlflow.log_metric('f1_weighted_mean', mean_f1)\n",
    "#    \n",
    "#        # Treinando o algoritmo\n",
    "#        pipe.fit(x_treino, y_treino)\n",
    "#    \n",
    "#        # Calculando a latência média\n",
    "#        latency_list = []\n",
    "#    \n",
    "#        for _, row in x_treino[:1000].iterrows():\n",
    "#        \n",
    "#            # Início da contagem de tempo\n",
    "#            start_time = time.time()\n",
    "#    \n",
    "#            # Extrair os recursos da linha\n",
    "#            features = row.values.reshape(1, -1)\n",
    "#    \n",
    "#            # Fazer a previsão para a linha individual\n",
    "#            prediction = pipe.predict(pd.DataFrame(features, columns = x_treino.columns.to_list()))\n",
    "#    \n",
    "#            # Encerra a contagem\n",
    "#            end_time = time.time()\n",
    "#            atomic_time = end_time - start_time\n",
    "#    \n",
    "#            # Transforma segundo em milissegundo\n",
    "#            atomic_milissec = atomic_time * 1000\n",
    "#    \n",
    "#            # Adiciona o tempo em uma lista\n",
    "#            latency_list.append(atomic_milissec)\n",
    "#    \n",
    "#        # calcula a média \n",
    "#        mlflow.log_metric(\"Latência média\", np.mean(latency_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos sem transformers\n",
    "#for tag, model in dict_models_tree_based.items():\n",
    "#\n",
    "#    # Gerando a tag de identificação do modelo\n",
    "#    nome_modelo = f'{tag}'\n",
    "#\n",
    "#    with mlflow.start_run(run_name=nome_modelo):\n",
    "#\n",
    "#        # Criando os pipeline com os transformers\n",
    "#        pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                            ('encoder', OneHotEncoder(drop='first'))])\n",
    "#    \n",
    "#        # Criando os pipeline com os transformers\n",
    "#        pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                        ('encoder_hd', ce.CatBoostEncoder())])\n",
    "#    \n",
    "#        pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\"))])\n",
    "#    \n",
    "#        # Criando o transformador\n",
    "#        transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                        ('num', pipe_num, num_cols),\n",
    "#                                        ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "#                                        remainder=\"passthrough\")\n",
    "#    \n",
    "#        # Criando o pipeline final\n",
    "#        pipe = Pipeline([('transformer', transformer),\n",
    "#                        ('model', model)])\n",
    "#    \n",
    "#        # Executando o cross validation\n",
    "#        cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='recall')\n",
    "#    \n",
    "#        # Calculando a média das métricas\n",
    "#        mean_score = cross_val_scores.mean()           \n",
    "#    \n",
    "#        # Salvando a métrica da folder 1\n",
    "#        mlflow.log_metric('recall_fold_1', cross_val_scores[0])\n",
    "#    \n",
    "#        # Salvando a métrica da folder 2\n",
    "#        mlflow.log_metric('recall_fold_2', cross_val_scores[1])\n",
    "#    \n",
    "#        # Salvando a métrica da folder 3\n",
    "#        mlflow.log_metric('recall_fold_3', cross_val_scores[2])\n",
    "#    \n",
    "#        # Salvando a métrica da folder 4\n",
    "#        mlflow.log_metric('recall_fold_4', cross_val_scores[3])\n",
    "#    \n",
    "#        # Salvando a métrica da folder 5\n",
    "#        mlflow.log_metric('recall_fold_5', cross_val_scores[4])\n",
    "#    \n",
    "#        # Salvando as métricas\n",
    "#        mlflow.log_metric('recall_mean', mean_score)\n",
    "#        \n",
    "#        # Salvando o f1 weighted\n",
    "#        mean_f1 = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='f1_weighted').mean()\n",
    "#        \n",
    "#        # Salvando a métrica do f1\n",
    "#        mlflow.log_metric('f1_weighted_mean', mean_f1)\n",
    "#    \n",
    "#        # Treinando o algoritmo\n",
    "#        pipe.fit(x_treino, y_treino)\n",
    "#    \n",
    "#        # Calculando a latência média\n",
    "#        latency_list = []\n",
    "#    \n",
    "#        for _, row in x_treino[:1000].iterrows():\n",
    "#        \n",
    "#            # Início da contagem de tempo\n",
    "#            start_time = time.time()\n",
    "#    \n",
    "#            # Extrair os recursos da linha\n",
    "#            features = row.values.reshape(1, -1)\n",
    "#    \n",
    "#            # Fazer a previsão para a linha individual\n",
    "#            prediction = pipe.predict(pd.DataFrame(features, columns = x_treino.columns.to_list()))\n",
    "#    \n",
    "#            # Encerra a contagem\n",
    "#            end_time = time.time()\n",
    "#            atomic_time = end_time - start_time\n",
    "#    \n",
    "#            # Transforma segundo em milissegundo\n",
    "#            atomic_milissec = atomic_time * 1000\n",
    "#    \n",
    "#            # Adiciona o tempo em uma lista\n",
    "#            latency_list.append(atomic_milissec)\n",
    "#    \n",
    "#        # calcula a média \n",
    "#        mlflow.log_metric(\"Latência média\", np.mean(latency_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['tags.mlflow.runName', 'metrics.f1_weighted_mean',\\n       'metrics.recall_mean', 'metrics.Latência média',\\n       'metrics.recall_fold_1', 'metrics.recall_fold_2',\\n       'metrics.recall_fold_3', 'metrics.recall_fold_4',\\n       'metrics.recall_fold_5'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m colunas_para_buscar \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags.mlflow.runName\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.f1_weighted_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.recall_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.Latência média\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.recall_fold_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.recall_fold_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.recall_fold_3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.recall_fold_4\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.recall_fold_5\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Buscando os melhores modelos\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m runs \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_runs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolunas_para_buscar\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Ordenando por recall médio\u001b[39;00m\n\u001b[1;32m     12\u001b[0m runs\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics.recall_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['tags.mlflow.runName', 'metrics.f1_weighted_mean',\\n       'metrics.recall_mean', 'metrics.Latência média',\\n       'metrics.recall_fold_1', 'metrics.recall_fold_2',\\n       'metrics.recall_fold_3', 'metrics.recall_fold_4',\\n       'metrics.recall_fold_5'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Definindo as colunas de interesse\n",
    "colunas_para_buscar = [\"tags.mlflow.runName\", 'metrics.f1_weighted_mean', \n",
    "                       'metrics.recall_mean', 'metrics.Latência média', \n",
    "                       'metrics.recall_fold_1', 'metrics.recall_fold_2', \n",
    "                       'metrics.recall_fold_3', 'metrics.recall_fold_4', \n",
    "                       'metrics.recall_fold_5']\n",
    "\n",
    "# Buscando os melhores modelos\n",
    "runs = mlflow.search_runs()[colunas_para_buscar]\n",
    "\n",
    "# Ordenando por recall médio\n",
    "runs.sort_values(by=\"metrics.recall_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos modelos testados, apenas o **LightGBM** e a **Regressão Logística** tiveram\n",
    "um bom resultado. \n",
    "\n",
    "- O **Recall** do **LightGBM** é cerca de **0.5% superior** ao da **Regressão**.\n",
    "- A **latência** do **LightGBM** é cerca de **76% maior** do que a da **Regressão**.\n",
    "\n",
    "Vamos tunar e avaliar ambos os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/12 09:31:13 INFO mlflow.tracking.fluent: Experiment with name 'Comparando regressões' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## Criando/acessando o experimento\n",
    "#mlflow.set_experiment('Comparando regressões')\n",
    "#\n",
    "## Iniciando os experimentos com regressões\n",
    "#for tag_encoder, encoder in dict_encoders.items():\n",
    "#    for tag_scaler, scaler in dict_scalers.items():\n",
    "#        for tag_imputer, imputer in dict_imputers_num.items():\n",
    "#        \n",
    "#            # Gerando a tag de identificação do modelo\n",
    "#            nome_modelo = f'LR_{tag_encoder}_{tag_scaler}_{tag_imputer}'\n",
    "#\n",
    "#            with mlflow.start_run(run_name=nome_modelo):\n",
    "#            \n",
    "#                # Criando os pipeline com os transformers\n",
    "#                pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                    ('encoder', encoder)])\n",
    "#\n",
    "#                # Criando os pipeline com os transformers\n",
    "#                pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "#\n",
    "#                pipe_num = Pipeline([('imputer_num', imputer),\n",
    "#                                     ('scaler', scaler)])\n",
    "#\n",
    "#                # Criando o transformador\n",
    "#                transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                ('num', pipe_num, num_cols),\n",
    "#                                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "#                                                remainder=\"passthrough\")\n",
    "#\n",
    "#                # Criando o pipeline final\n",
    "#                pipe = Pipeline([('transformer', transformer),\n",
    "#                                ('model', LogisticRegression(class_weight='balanced',\n",
    "#                                                             random_state=rs))])\n",
    "#\n",
    "#                # Executando o cross validation\n",
    "#                cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='recall')\n",
    "#\n",
    "#                # Calculando a média das métricas\n",
    "#                mean_score = cross_val_scores.mean()           \n",
    "#\n",
    "#                # Salvando a métrica da folder 1\n",
    "#                mlflow.log_metric('recall_fold_1', cross_val_scores[0])\n",
    "#\n",
    "#                # Salvando a métrica da folder 2\n",
    "#                mlflow.log_metric('recall_fold_2', cross_val_scores[1])\n",
    "#\n",
    "#                # Salvando a métrica da folder 3\n",
    "#                mlflow.log_metric('recall_fold_3', cross_val_scores[2])\n",
    "#\n",
    "#                # Salvando a métrica da folder 4\n",
    "#                mlflow.log_metric('recall_fold_4', cross_val_scores[3])\n",
    "#\n",
    "#                # Salvando a métrica da folder 5\n",
    "#                mlflow.log_metric('recall_fold_5', cross_val_scores[4])\n",
    "#\n",
    "#                # Salvando as métricas\n",
    "#                mlflow.log_metric('recall_mean', mean_score)\n",
    "#                \n",
    "#                # Salvando o f1 weighted\n",
    "#                mean_f1 = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='f1_weighted').mean()\n",
    "#                \n",
    "#                # Salvando a métrica do f1\n",
    "#                mlflow.log_metric('f1_weighted_mean', mean_f1)\n",
    "#\n",
    "#                # Treinando o algoritmo\n",
    "#                pipe.fit(x_treino, y_treino)\n",
    "#\n",
    "#                # Calculando a latência média\n",
    "#                latency_list = []\n",
    "#\n",
    "#                for _, row in x_treino[:1000].iterrows():\n",
    "#                \n",
    "#                    # Início da contagem de tempo\n",
    "#                    start_time = time.time()\n",
    "#\n",
    "#                    # Extrair os recursos da linha\n",
    "#                    features = row.values.reshape(1, -1)\n",
    "#\n",
    "#                    # Fazer a previsão para a linha individual\n",
    "#                    prediction = pipe.predict(pd.DataFrame(features, columns = x_treino.columns.to_list()))\n",
    "#\n",
    "#                    # Encerra a contagem\n",
    "#                    end_time = time.time()\n",
    "#                    atomic_time = end_time - start_time\n",
    "#\n",
    "#                    # Transforma segundo em milissegundo\n",
    "#                    atomic_milissec = atomic_time * 1000\n",
    "#\n",
    "#                    # Adiciona o tempo em uma lista\n",
    "#                    latency_list.append(atomic_milissec)\n",
    "#\n",
    "#                # calcula a média \n",
    "#                mlflow.log_metric(\"Latência média\", np.mean(latency_list))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>metrics.f1_weighted_mean</th>\n",
       "      <th>metrics.recall_mean</th>\n",
       "      <th>metrics.Latência média</th>\n",
       "      <th>metrics.recall_fold_1</th>\n",
       "      <th>metrics.recall_fold_2</th>\n",
       "      <th>metrics.recall_fold_3</th>\n",
       "      <th>metrics.recall_fold_4</th>\n",
       "      <th>metrics.recall_fold_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_CTE_RS_SIMEDIAN</td>\n",
       "      <td>0.690758</td>\n",
       "      <td>0.700571</td>\n",
       "      <td>39.934036</td>\n",
       "      <td>0.721905</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.682857</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.703810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_CTE_RS_SIAVG</td>\n",
       "      <td>0.717180</td>\n",
       "      <td>0.699048</td>\n",
       "      <td>45.698645</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.707619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR_GE_SS_SIAVG</td>\n",
       "      <td>0.807978</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>51.978545</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.677143</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.665714</td>\n",
       "      <td>0.688571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR_BE_RS_SIAVG</td>\n",
       "      <td>0.808237</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>56.522726</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.678095</td>\n",
       "      <td>0.665714</td>\n",
       "      <td>0.670476</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LR_BE_SS_SIMEDIAN</td>\n",
       "      <td>0.808429</td>\n",
       "      <td>0.672762</td>\n",
       "      <td>56.829186</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.678095</td>\n",
       "      <td>0.663810</td>\n",
       "      <td>0.688571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LR_OHE_RS_SIMEDIAN</td>\n",
       "      <td>0.806843</td>\n",
       "      <td>0.672762</td>\n",
       "      <td>30.154952</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.674286</td>\n",
       "      <td>0.674286</td>\n",
       "      <td>0.664762</td>\n",
       "      <td>0.687619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR_GE_SS_SIMEDIAN</td>\n",
       "      <td>0.808443</td>\n",
       "      <td>0.672381</td>\n",
       "      <td>60.197710</td>\n",
       "      <td>0.660952</td>\n",
       "      <td>0.677143</td>\n",
       "      <td>0.669524</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.692381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR_GE_RS_SIMEDIAN</td>\n",
       "      <td>0.807141</td>\n",
       "      <td>0.672381</td>\n",
       "      <td>63.011021</td>\n",
       "      <td>0.658095</td>\n",
       "      <td>0.677143</td>\n",
       "      <td>0.669524</td>\n",
       "      <td>0.665714</td>\n",
       "      <td>0.691429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LR_OHE_RS_SIAVG</td>\n",
       "      <td>0.806142</td>\n",
       "      <td>0.672190</td>\n",
       "      <td>20.303402</td>\n",
       "      <td>0.656190</td>\n",
       "      <td>0.674286</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.665714</td>\n",
       "      <td>0.691429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LR_OHE_SS_SIMEDIAN</td>\n",
       "      <td>0.808796</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>25.794318</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.687619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LR_OHE_SS_SIAVG</td>\n",
       "      <td>0.808684</td>\n",
       "      <td>0.671810</td>\n",
       "      <td>24.292106</td>\n",
       "      <td>0.660952</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.670476</td>\n",
       "      <td>0.664762</td>\n",
       "      <td>0.686667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LR_BE_SS_SIAVG</td>\n",
       "      <td>0.808623</td>\n",
       "      <td>0.671238</td>\n",
       "      <td>58.590704</td>\n",
       "      <td>0.658095</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.688571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR_GE_RS_SIAVG</td>\n",
       "      <td>0.807479</td>\n",
       "      <td>0.670857</td>\n",
       "      <td>61.363517</td>\n",
       "      <td>0.655238</td>\n",
       "      <td>0.677143</td>\n",
       "      <td>0.665714</td>\n",
       "      <td>0.664762</td>\n",
       "      <td>0.691429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR_BE_RS_SIMEDIAN</td>\n",
       "      <td>0.807414</td>\n",
       "      <td>0.670667</td>\n",
       "      <td>58.327520</td>\n",
       "      <td>0.659048</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.668571</td>\n",
       "      <td>0.660952</td>\n",
       "      <td>0.688571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LR_TE_SS_SIAVG</td>\n",
       "      <td>0.814076</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>47.668181</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.658095</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.649524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR_ME_SS_SIAVG</td>\n",
       "      <td>0.814127</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>45.508358</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.658095</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.643810</td>\n",
       "      <td>0.649524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LR_TE_SS_SIMEDIAN</td>\n",
       "      <td>0.814107</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>43.880348</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.656190</td>\n",
       "      <td>0.643810</td>\n",
       "      <td>0.650476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LR_ME_SS_SIMEDIAN</td>\n",
       "      <td>0.814060</td>\n",
       "      <td>0.651619</td>\n",
       "      <td>46.144974</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.656190</td>\n",
       "      <td>0.656190</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.650476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LR_ME_RS_SIMEDIAN</td>\n",
       "      <td>0.807481</td>\n",
       "      <td>0.650857</td>\n",
       "      <td>49.230142</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.639048</td>\n",
       "      <td>0.671429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LR_CE_SS_SIMEDIAN</td>\n",
       "      <td>0.814214</td>\n",
       "      <td>0.648952</td>\n",
       "      <td>54.637035</td>\n",
       "      <td>0.649524</td>\n",
       "      <td>0.654286</td>\n",
       "      <td>0.660952</td>\n",
       "      <td>0.641905</td>\n",
       "      <td>0.638095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LR_CE_SS_SIAVG</td>\n",
       "      <td>0.814186</td>\n",
       "      <td>0.648381</td>\n",
       "      <td>69.957388</td>\n",
       "      <td>0.644762</td>\n",
       "      <td>0.654286</td>\n",
       "      <td>0.660952</td>\n",
       "      <td>0.643810</td>\n",
       "      <td>0.638095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR_CE_RS_SIMEDIAN</td>\n",
       "      <td>0.813405</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>49.562705</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.641905</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LR_TE_RS_SIAVG</td>\n",
       "      <td>0.813473</td>\n",
       "      <td>0.645524</td>\n",
       "      <td>39.170982</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.643810</td>\n",
       "      <td>0.648571</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.643810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LR_ME_RS_SIAVG</td>\n",
       "      <td>0.812950</td>\n",
       "      <td>0.644952</td>\n",
       "      <td>45.659231</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.640952</td>\n",
       "      <td>0.644762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR_CE_RS_SIAVG</td>\n",
       "      <td>0.814163</td>\n",
       "      <td>0.644762</td>\n",
       "      <td>48.665474</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.656190</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.634286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LR_TE_RS_SIMEDIAN</td>\n",
       "      <td>0.813803</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>48.941018</td>\n",
       "      <td>0.643810</td>\n",
       "      <td>0.644762</td>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.647619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR_CTE_SS_SIMEDIAN</td>\n",
       "      <td>0.818412</td>\n",
       "      <td>0.617905</td>\n",
       "      <td>46.426286</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.607619</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.610476</td>\n",
       "      <td>0.644762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR_CTE_SS_SIAVG</td>\n",
       "      <td>0.819263</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>47.812604</td>\n",
       "      <td>0.611429</td>\n",
       "      <td>0.603810</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.608571</td>\n",
       "      <td>0.629524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tags.mlflow.runName  metrics.f1_weighted_mean  metrics.recall_mean  \\\n",
       "0   LR_CTE_RS_SIMEDIAN                  0.690758             0.700571   \n",
       "1      LR_CTE_RS_SIAVG                  0.717180             0.699048   \n",
       "7       LR_GE_SS_SIAVG                  0.807978             0.673333   \n",
       "17      LR_BE_RS_SIAVG                  0.808237             0.673333   \n",
       "18   LR_BE_SS_SIMEDIAN                  0.808429             0.672762   \n",
       "24  LR_OHE_RS_SIMEDIAN                  0.806843             0.672762   \n",
       "6    LR_GE_SS_SIMEDIAN                  0.808443             0.672381   \n",
       "4    LR_GE_RS_SIMEDIAN                  0.807141             0.672381   \n",
       "25     LR_OHE_RS_SIAVG                  0.806142             0.672190   \n",
       "26  LR_OHE_SS_SIMEDIAN                  0.808796             0.672000   \n",
       "27     LR_OHE_SS_SIAVG                  0.808684             0.671810   \n",
       "19      LR_BE_SS_SIAVG                  0.808623             0.671238   \n",
       "5       LR_GE_RS_SIAVG                  0.807479             0.670857   \n",
       "16   LR_BE_RS_SIMEDIAN                  0.807414             0.670667   \n",
       "23      LR_TE_SS_SIAVG                  0.814076             0.652381   \n",
       "15      LR_ME_SS_SIAVG                  0.814127             0.652000   \n",
       "22   LR_TE_SS_SIMEDIAN                  0.814107             0.652000   \n",
       "14   LR_ME_SS_SIMEDIAN                  0.814060             0.651619   \n",
       "12   LR_ME_RS_SIMEDIAN                  0.807481             0.650857   \n",
       "10   LR_CE_SS_SIMEDIAN                  0.814214             0.648952   \n",
       "11      LR_CE_SS_SIAVG                  0.814186             0.648381   \n",
       "8    LR_CE_RS_SIMEDIAN                  0.813405             0.645714   \n",
       "21      LR_TE_RS_SIAVG                  0.813473             0.645524   \n",
       "13      LR_ME_RS_SIAVG                  0.812950             0.644952   \n",
       "9       LR_CE_RS_SIAVG                  0.814163             0.644762   \n",
       "20   LR_TE_RS_SIMEDIAN                  0.813803             0.644000   \n",
       "2   LR_CTE_SS_SIMEDIAN                  0.818412             0.617905   \n",
       "3      LR_CTE_SS_SIAVG                  0.819263             0.613333   \n",
       "\n",
       "    metrics.Latência média  metrics.recall_fold_1  metrics.recall_fold_2  \\\n",
       "0                39.934036               0.721905               0.708571   \n",
       "1                45.698645               0.714286               0.706667   \n",
       "7                51.978545               0.661905               0.677143   \n",
       "17               56.522726               0.661905               0.678095   \n",
       "18               56.829186               0.660000               0.673333   \n",
       "24               30.154952               0.662857               0.674286   \n",
       "6                60.197710               0.660952               0.677143   \n",
       "4                63.011021               0.658095               0.677143   \n",
       "25               20.303402               0.656190               0.674286   \n",
       "26               25.794318               0.661905               0.676190   \n",
       "27               24.292106               0.660952               0.676190   \n",
       "19               58.590704               0.658095               0.673333   \n",
       "5                61.363517               0.655238               0.677143   \n",
       "16               58.327520               0.659048               0.676190   \n",
       "23               47.668181               0.651429               0.657143   \n",
       "15               45.508358               0.651429               0.658095   \n",
       "22               43.880348               0.652381               0.657143   \n",
       "14               46.144974               0.652381               0.656190   \n",
       "12               49.230142               0.645714               0.645714   \n",
       "10               54.637035               0.649524               0.654286   \n",
       "11               69.957388               0.644762               0.654286   \n",
       "8                49.562705               0.647619               0.645714   \n",
       "21               39.170982               0.645714               0.643810   \n",
       "13               45.659231               0.646667               0.646667   \n",
       "9                48.665474               0.645714               0.647619   \n",
       "20               48.941018               0.643810               0.644762   \n",
       "2                46.426286               0.613333               0.607619   \n",
       "3                47.812604               0.611429               0.603810   \n",
       "\n",
       "    metrics.recall_fold_3  metrics.recall_fold_4  metrics.recall_fold_5  \n",
       "0                0.682857               0.685714               0.703810  \n",
       "1                0.680952               0.685714               0.707619  \n",
       "7                0.673333               0.665714               0.688571  \n",
       "17               0.665714               0.670476               0.690476  \n",
       "18               0.678095               0.663810               0.688571  \n",
       "24               0.674286               0.664762               0.687619  \n",
       "6                0.669524               0.661905               0.692381  \n",
       "4                0.669524               0.665714               0.691429  \n",
       "25               0.673333               0.665714               0.691429  \n",
       "26               0.671429               0.662857               0.687619  \n",
       "27               0.670476               0.664762               0.686667  \n",
       "19               0.673333               0.662857               0.688571  \n",
       "5                0.665714               0.664762               0.691429  \n",
       "16               0.668571               0.660952               0.688571  \n",
       "23               0.658095               0.645714               0.649524  \n",
       "15               0.657143               0.643810               0.649524  \n",
       "22               0.656190               0.643810               0.650476  \n",
       "14               0.656190               0.642857               0.650476  \n",
       "12               0.652381               0.639048               0.671429  \n",
       "10               0.660952               0.641905               0.638095  \n",
       "11               0.660952               0.643810               0.638095  \n",
       "8                0.653333               0.641905               0.640000  \n",
       "21               0.648571               0.645714               0.643810  \n",
       "13               0.645714               0.640952               0.644762  \n",
       "9                0.656190               0.640000               0.634286  \n",
       "20               0.645714               0.638095               0.647619  \n",
       "2                0.613333               0.610476               0.644762  \n",
       "3                0.613333               0.608571               0.629524  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo as colunas de interesse\n",
    "colunas_para_buscar = [\"tags.mlflow.runName\", 'metrics.f1_weighted_mean', \n",
    "                       'metrics.recall_mean', 'metrics.Latência média', \n",
    "                       'metrics.recall_fold_1', 'metrics.recall_fold_2', \n",
    "                       'metrics.recall_fold_3', 'metrics.recall_fold_4', \n",
    "                       'metrics.recall_fold_5']\n",
    "\n",
    "# Buscando os melhores modelos\n",
    "runs = mlflow.search_runs()[colunas_para_buscar]\n",
    "\n",
    "# Ordenando por recall médio\n",
    "runs.sort_values(by=\"metrics.recall_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/12 10:14:07 INFO mlflow.tracking.fluent: Experiment with name 'Comparando lgbms' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2755\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4509\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4508\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2748\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2747\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2754\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 4200, number of negative: 79800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 84000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n",
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2753\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n"
     ]
    }
   ],
   "source": [
    "## Criando/acessando o experimento\n",
    "#mlflow.set_experiment('Comparando lgbms')\n",
    "#\n",
    "## Iniciando os experimentos com o lightgbm\n",
    "#for tag_encoder, encoder in dict_encoders.items():\n",
    "#        for tag_imputer, imputer in dict_imputers_num.items():\n",
    "#    \n",
    "#            # Gerando a tag de identificação do modelo\n",
    "#            nome_modelo = f'LGBM_{tag_encoder}_{tag_imputer}'\n",
    "#    \n",
    "#            with mlflow.start_run(run_name=nome_modelo):\n",
    "#            \n",
    "#                # Criando os pipeline com os transformers\n",
    "#                pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                    ('encoder', encoder)])\n",
    "#    \n",
    "#                # Criando os pipeline com os transformers\n",
    "#                pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "#    \n",
    "#                pipe_num = Pipeline([('imputer_num', imputer)])\n",
    "#    \n",
    "#                # Criando o transformador\n",
    "#                transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                ('num', pipe_num, num_cols),\n",
    "#                                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "#                                                remainder=\"passthrough\")\n",
    "#    \n",
    "#                # Criando o pipeline final\n",
    "#                pipe = Pipeline([('transformer', transformer),\n",
    "#                                ('model', LGBMClassifier(is_unbalance=True,\n",
    "#                                                 objective= 'binary',\n",
    "#                                                 random_state=rs))])\n",
    "#    \n",
    "#                # Executando o cross validation\n",
    "#                cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='recall')\n",
    "#    \n",
    "#                # Calculando a média das métricas\n",
    "#                mean_score = cross_val_scores.mean()           \n",
    "#    \n",
    "#                # Salvando a métrica da folder 1\n",
    "#                mlflow.log_metric('recall_fold_1', cross_val_scores[0])\n",
    "#    \n",
    "#                # Salvando a métrica da folder 2\n",
    "#                mlflow.log_metric('recall_fold_2', cross_val_scores[1])\n",
    "#    \n",
    "#                # Salvando a métrica da folder 3\n",
    "#                mlflow.log_metric('recall_fold_3', cross_val_scores[2])\n",
    "#    \n",
    "#                # Salvando a métrica da folder 4\n",
    "#                mlflow.log_metric('recall_fold_4', cross_val_scores[3])\n",
    "#    \n",
    "#                # Salvando a métrica da folder 5\n",
    "#                mlflow.log_metric('recall_fold_5', cross_val_scores[4])\n",
    "#    \n",
    "#                # Salvando as métricas\n",
    "#                mlflow.log_metric('recall_mean', mean_score)\n",
    "#                \n",
    "#                # Salvando o f1 weighted\n",
    "#                mean_f1 = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='f1_weighted').mean()\n",
    "#                \n",
    "#                # Salvando a métrica do f1\n",
    "#                mlflow.log_metric('f1_weighted_mean', mean_f1)\n",
    "#    \n",
    "#                # Treinando o algoritmo\n",
    "#                pipe.fit(x_treino, y_treino)\n",
    "#    \n",
    "#                # Calculando a latência média\n",
    "#                latency_list = []\n",
    "#    \n",
    "#                for _, row in x_treino[:1000].iterrows():\n",
    "#                \n",
    "#                    # Início da contagem de tempo\n",
    "#                    start_time = time.time()\n",
    "#    \n",
    "#                    # Extrair os recursos da linha\n",
    "#                    features = row.values.reshape(1, -1)\n",
    "#    \n",
    "#                    # Fazer a previsão para a linha individual\n",
    "#                    prediction = pipe.predict(pd.DataFrame(features, columns = x_treino.columns.to_list()))\n",
    "#    \n",
    "#                    # Encerra a contagem\n",
    "#                    end_time = time.time()\n",
    "#                    atomic_time = end_time - start_time\n",
    "#    \n",
    "#                    # Transforma segundo em milissegundo\n",
    "#                    atomic_milissec = atomic_time * 1000\n",
    "#    \n",
    "#                    # Adiciona o tempo em uma lista\n",
    "#                    latency_list.append(atomic_milissec)\n",
    "#    \n",
    "#                # calcula a média \n",
    "#                mlflow.log_metric(\"Latência média\", np.mean(latency_list))\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>metrics.f1_weighted_mean</th>\n",
       "      <th>metrics.recall_mean</th>\n",
       "      <th>metrics.Latência média</th>\n",
       "      <th>metrics.recall_fold_1</th>\n",
       "      <th>metrics.recall_fold_2</th>\n",
       "      <th>metrics.recall_fold_3</th>\n",
       "      <th>metrics.recall_fold_4</th>\n",
       "      <th>metrics.recall_fold_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LGBM_TE_SIAVG</td>\n",
       "      <td>0.838867</td>\n",
       "      <td>0.643619</td>\n",
       "      <td>62.969607</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.636190</td>\n",
       "      <td>0.647619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBM_ME_SIAVG</td>\n",
       "      <td>0.838867</td>\n",
       "      <td>0.643619</td>\n",
       "      <td>56.503378</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.636190</td>\n",
       "      <td>0.647619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LGBM_OHE_SIAVG</td>\n",
       "      <td>0.837828</td>\n",
       "      <td>0.639619</td>\n",
       "      <td>39.661925</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.656190</td>\n",
       "      <td>0.639048</td>\n",
       "      <td>0.641905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM_CE_SIMEDIAN</td>\n",
       "      <td>0.839450</td>\n",
       "      <td>0.639429</td>\n",
       "      <td>68.224117</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.610476</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.644762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM_GE_SIAVG</td>\n",
       "      <td>0.837333</td>\n",
       "      <td>0.639429</td>\n",
       "      <td>64.073688</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.629524</td>\n",
       "      <td>0.650476</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBM_GE_SIMEDIAN</td>\n",
       "      <td>0.839062</td>\n",
       "      <td>0.638667</td>\n",
       "      <td>64.845442</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.649524</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.650476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGBM_BE_SIAVG</td>\n",
       "      <td>0.838539</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>66.973334</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.627619</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.641905</td>\n",
       "      <td>0.640952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LGBM_TE_SIMEDIAN</td>\n",
       "      <td>0.838495</td>\n",
       "      <td>0.636952</td>\n",
       "      <td>61.431783</td>\n",
       "      <td>0.640952</td>\n",
       "      <td>0.623810</td>\n",
       "      <td>0.649524</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.638095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBM_ME_SIMEDIAN</td>\n",
       "      <td>0.838495</td>\n",
       "      <td>0.636952</td>\n",
       "      <td>58.542917</td>\n",
       "      <td>0.640952</td>\n",
       "      <td>0.623810</td>\n",
       "      <td>0.649524</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.638095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LGBM_BE_SIMEDIAN</td>\n",
       "      <td>0.838933</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>65.299150</td>\n",
       "      <td>0.636190</td>\n",
       "      <td>0.629524</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.647619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LGBM_OHE_SIMEDIAN</td>\n",
       "      <td>0.839467</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>39.251838</td>\n",
       "      <td>0.631429</td>\n",
       "      <td>0.629524</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.629524</td>\n",
       "      <td>0.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBM_CE_SIAVG</td>\n",
       "      <td>0.841665</td>\n",
       "      <td>0.634476</td>\n",
       "      <td>67.996633</td>\n",
       "      <td>0.648571</td>\n",
       "      <td>0.603810</td>\n",
       "      <td>0.643810</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.636190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM_CTE_SIMEDIAN</td>\n",
       "      <td>0.839328</td>\n",
       "      <td>0.632952</td>\n",
       "      <td>57.475409</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.629524</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.629524</td>\n",
       "      <td>0.624762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM_CTE_SIAVG</td>\n",
       "      <td>0.839782</td>\n",
       "      <td>0.631619</td>\n",
       "      <td>57.958078</td>\n",
       "      <td>0.620952</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.631429</td>\n",
       "      <td>0.640952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tags.mlflow.runName  metrics.f1_weighted_mean  metrics.recall_mean  \\\n",
       "11       LGBM_TE_SIAVG                  0.838867             0.643619   \n",
       "7        LGBM_ME_SIAVG                  0.838867             0.643619   \n",
       "13      LGBM_OHE_SIAVG                  0.837828             0.639619   \n",
       "4     LGBM_CE_SIMEDIAN                  0.839450             0.639429   \n",
       "3        LGBM_GE_SIAVG                  0.837333             0.639429   \n",
       "2     LGBM_GE_SIMEDIAN                  0.839062             0.638667   \n",
       "9        LGBM_BE_SIAVG                  0.838539             0.638095   \n",
       "10    LGBM_TE_SIMEDIAN                  0.838495             0.636952   \n",
       "6     LGBM_ME_SIMEDIAN                  0.838495             0.636952   \n",
       "8     LGBM_BE_SIMEDIAN                  0.838933             0.636000   \n",
       "12   LGBM_OHE_SIMEDIAN                  0.839467             0.636000   \n",
       "5        LGBM_CE_SIAVG                  0.841665             0.634476   \n",
       "0    LGBM_CTE_SIMEDIAN                  0.839328             0.632952   \n",
       "1       LGBM_CTE_SIAVG                  0.839782             0.631619   \n",
       "\n",
       "    metrics.Latência média  metrics.recall_fold_1  metrics.recall_fold_2  \\\n",
       "11               62.969607               0.640000               0.642857   \n",
       "7                56.503378               0.640000               0.642857   \n",
       "13               39.661925               0.632381               0.628571   \n",
       "4                68.224117               0.647619               0.610476   \n",
       "3                64.073688               0.638095               0.629524   \n",
       "2                64.845442               0.632381               0.628571   \n",
       "9                66.973334               0.637143               0.627619   \n",
       "10               61.431783               0.640952               0.623810   \n",
       "6                58.542917               0.640952               0.623810   \n",
       "8                65.299150               0.636190               0.629524   \n",
       "12               39.251838               0.631429               0.629524   \n",
       "5                67.996633               0.648571               0.603810   \n",
       "0                57.475409               0.628571               0.629524   \n",
       "1                57.958078               0.620952               0.626667   \n",
       "\n",
       "    metrics.recall_fold_3  metrics.recall_fold_4  metrics.recall_fold_5  \n",
       "11               0.651429               0.636190               0.647619  \n",
       "7                0.651429               0.636190               0.647619  \n",
       "13               0.656190               0.639048               0.641905  \n",
       "4                0.660000               0.634286               0.644762  \n",
       "3                0.650476               0.632381               0.646667  \n",
       "2                0.649524               0.632381               0.650476  \n",
       "9                0.642857               0.641905               0.640952  \n",
       "10               0.649524               0.632381               0.638095  \n",
       "6                0.649524               0.632381               0.638095  \n",
       "8                0.632381               0.634286               0.647619  \n",
       "12               0.642857               0.629524               0.646667  \n",
       "5                0.643810               0.640000               0.636190  \n",
       "0                0.652381               0.629524               0.624762  \n",
       "1                0.638095               0.631429               0.640952  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo as colunas de interesse\n",
    "colunas_para_buscar = [\"tags.mlflow.runName\", 'metrics.f1_weighted_mean', \n",
    "                       'metrics.recall_mean', 'metrics.Latência média', \n",
    "                       'metrics.recall_fold_1', 'metrics.recall_fold_2', \n",
    "                       'metrics.recall_fold_3', 'metrics.recall_fold_4', \n",
    "                       'metrics.recall_fold_5']\n",
    "\n",
    "# Buscando os melhores modelos\n",
    "runs = mlflow.search_runs()[colunas_para_buscar]\n",
    "\n",
    "# Ordenando por recall médio\n",
    "runs.sort_values(by=\"metrics.recall_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística \n",
    "A combinação **Logistic Regression** + **CountEncoder** + **RobustSaler** + \n",
    "**SimpleImputer(Mediana)** obteve o primeiro lugar com as seguintes estatísticas:\n",
    "- Recall médio de 0.70\n",
    "- F1 weighted médio de 0.69 \n",
    "- Latência média de 39 milissegundos\n",
    "\n",
    "No geral, são boas métricas, e ele será o modelo escolhido. Entretanto, também\n",
    "houveram outras combinações que se saíram bem. A combinação \n",
    "**Logistic Regression** + **OneHotEncoder** + **RobustSaler** + \n",
    "**SimpleImputer(Media)** demonstrou ser promissora:\n",
    "- Recall médio de 0.67 (0.03 a menos que o primeiro colocado)\n",
    "- F1 weighted médio de 0.80 (0.10 a mais que o primeiro colocado)\n",
    "- Latência média de 20 milissegundos (19 milissegundos a menos que o primeiro colocado)\n",
    "\n",
    "Selecionaremos esses dois modelos para tunar os parâmetros.\n",
    "\n",
    "#### LightGBM\n",
    "\n",
    "Para os modelos com base no LightGBM, temos métricas bem semelhantes entre as \n",
    "combinações, por isso, selecionaremos aquele com a menor latência dentre os \n",
    "5 primeiros:\n",
    "**LightGBM** + **OneHotEncoder** + **SimpleImputer(Média)**\n",
    "\n",
    "## Tunando o modelo candidato\n",
    "\n",
    "Agora que já temos a melhor combinação de preprocessors, vamos buscar a melhor\n",
    "opção de hiperparâmetros.\n",
    "\n",
    "Para tal, usaremos o **Optuna**.\n",
    "\n",
    "Vamos iniciar com a primeira regressão: **Logistic Regression** + **CountEncoder** + **RobustSaler** + \n",
    "**SimpleImputer(Mediana)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-12 15:59:48,722] A new study created in memory with name: no-name-372bc1b2-d0ae-440c-9a60-b263a86e3316\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-12 16:00:04,612] Trial 0 finished with value: 0.005333333333333333 and parameters: {'C': 1993.2154892627345, 'penalty': None, 'solver': 'lbfgs', 'max_iter': 709, 'fit_intercept': True, 'class_weight': None}. Best is trial 0 with value: 0.005333333333333333.\n",
      "[I 2024-04-12 16:00:07,617] Trial 1 finished with value: 0.6657777777777778 and parameters: {'C': 7.489568008473854, 'penalty': 'l2', 'solver': 'newton-cholesky', 'max_iter': 511, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.6657777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-12 16:00:22,791] Trial 2 finished with value: 0.005333333333333333 and parameters: {'C': 285.20051792784255, 'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 604, 'fit_intercept': False, 'class_weight': None}. Best is trial 1 with value: 0.6657777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-12 16:00:43,859] Trial 3 finished with value: 0.736 and parameters: {'C': 8.828759543707518, 'penalty': None, 'solver': 'lbfgs', 'max_iter': 748, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 3 with value: 0.736.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:02:07,802] Trial 4 finished with value: 0.8853333333333333 and parameters: {'C': 1789.4428651327607, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 694, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.8853333333333333.\n",
      "[I 2024-04-12 16:02:11,138] Trial 5 finished with value: 0.6666666666666666 and parameters: {'C': 0.35414075332240885, 'penalty': 'l2', 'solver': 'newton-cholesky', 'max_iter': 528, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.8853333333333333.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-12 16:02:25,399] Trial 6 finished with value: 0.7431111111111111 and parameters: {'C': 0.0762468856835023, 'penalty': None, 'solver': 'lbfgs', 'max_iter': 479, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.8853333333333333.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:03:07,499] Trial 7 finished with value: 0.6577777777777778 and parameters: {'C': 0.2458606965099764, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 320, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.8853333333333333.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-12 16:03:19,804] Trial 8 finished with value: 0.7457777777777778 and parameters: {'C': 0.00015663074854998192, 'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 405, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.8853333333333333.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:03:53,388] Trial 9 finished with value: 0.9635555555555556 and parameters: {'C': 0.002498024022101175, 'penalty': None, 'solver': 'saga', 'max_iter': 250, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:04:08,977] Trial 10 finished with value: 0.0 and parameters: {'C': 0.000961305422885798, 'penalty': None, 'solver': 'saga', 'max_iter': 104, 'fit_intercept': False, 'class_weight': None}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:06:17,397] Trial 11 finished with value: 0.8213333333333334 and parameters: {'C': 0.008380193616118798, 'penalty': None, 'solver': 'saga', 'max_iter': 991, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:06:45,618] Trial 12 finished with value: 0.6817777777777778 and parameters: {'C': 5077.986128830362, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 203, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:08:17,733] Trial 13 finished with value: 0.536 and parameters: {'C': 95.60490136353339, 'penalty': None, 'solver': 'saga', 'max_iter': 880, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:08:49,102] Trial 14 finished with value: 0.7191111111111111 and parameters: {'C': 0.009706313915879278, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 302, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:09:54,717] Trial 15 finished with value: 0.0 and parameters: {'C': 9.417036104926076, 'penalty': None, 'solver': 'saga', 'max_iter': 663, 'fit_intercept': True, 'class_weight': None}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:09:57,330] Trial 16 finished with value: 0.6693333333333333 and parameters: {'C': 0.020032245932087925, 'penalty': None, 'solver': 'newton-cholesky', 'max_iter': 54, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:11:16,791] Trial 17 finished with value: 0.5937777777777777 and parameters: {'C': 0.00010325587934813729, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 804, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:11:37,753] Trial 18 finished with value: 0.0 and parameters: {'C': 261.6917656696862, 'penalty': None, 'solver': 'saga', 'max_iter': 197, 'fit_intercept': False, 'class_weight': None}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:12:12,959] Trial 19 finished with value: 0.44 and parameters: {'C': 1.9240204062484882, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 341, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "[I 2024-04-12 16:12:15,642] Trial 20 finished with value: 0.6773333333333333 and parameters: {'C': 0.0014745489909638962, 'penalty': 'l2', 'solver': 'newton-cholesky', 'max_iter': 878, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:13:51,575] Trial 21 finished with value: 0.8213333333333334 and parameters: {'C': 0.003851073088312536, 'penalty': None, 'solver': 'saga', 'max_iter': 991, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:15:28,321] Trial 22 finished with value: 0.5555555555555556 and parameters: {'C': 0.06648894741572006, 'penalty': None, 'solver': 'saga', 'max_iter': 999, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:16:26,515] Trial 23 finished with value: 0.6604444444444444 and parameters: {'C': 0.0007453483516003042, 'penalty': None, 'solver': 'saga', 'max_iter': 583, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:18:06,948] Trial 24 finished with value: 0.24622222222222223 and parameters: {'C': 0.015606159640863213, 'penalty': None, 'solver': 'saga', 'max_iter': 872, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9635555555555556.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:18:59,259] Trial 25 finished with value: 0.9751111111111112 and parameters: {'C': 0.004044313551618763, 'penalty': None, 'solver': 'saga', 'max_iter': 417, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 25 with value: 0.9751111111111112.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:19:54,807] Trial 26 finished with value: 0.0 and parameters: {'C': 1.0455445652633168, 'penalty': None, 'solver': 'saga', 'max_iter': 391, 'fit_intercept': True, 'class_weight': None}. Best is trial 25 with value: 0.9751111111111112.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:20:24,865] Trial 27 finished with value: 0.9937777777777778 and parameters: {'C': 0.0003497693165590731, 'penalty': None, 'solver': 'saga', 'max_iter': 224, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:20:27,772] Trial 28 finished with value: 0.6666666666666666 and parameters: {'C': 0.000311963918845018, 'penalty': None, 'solver': 'newton-cholesky', 'max_iter': 233, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:20:47,500] Trial 29 finished with value: 0.0 and parameters: {'C': 0.00237143279547758, 'penalty': None, 'solver': 'saga', 'max_iter': 158, 'fit_intercept': False, 'class_weight': None}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-12 16:20:57,042] Trial 30 finished with value: 0.7262222222222222 and parameters: {'C': 0.0004675795235146905, 'penalty': None, 'solver': 'lbfgs', 'max_iter': 285, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:21:47,110] Trial 31 finished with value: 0.9937777777777778 and parameters: {'C': 0.05334507824326141, 'penalty': None, 'solver': 'saga', 'max_iter': 431, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:22:47,942] Trial 32 finished with value: 0.928 and parameters: {'C': 0.05948878203013159, 'penalty': None, 'solver': 'saga', 'max_iter': 451, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:23:38,550] Trial 33 finished with value: 0.33066666666666666 and parameters: {'C': 0.002830152288125064, 'penalty': None, 'solver': 'saga', 'max_iter': 389, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:24:10,768] Trial 34 finished with value: 0.9813333333333333 and parameters: {'C': 0.03777314333430858, 'penalty': None, 'solver': 'saga', 'max_iter': 272, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:25:15,801] Trial 35 finished with value: 0.7875555555555556 and parameters: {'C': 0.1712891679263953, 'penalty': None, 'solver': 'saga', 'max_iter': 566, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-12 16:25:26,010] Trial 36 finished with value: 0.7333333333333333 and parameters: {'C': 0.02884984443800152, 'penalty': None, 'solver': 'lbfgs', 'max_iter': 353, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:25:28,879] Trial 37 finished with value: 0.018666666666666668 and parameters: {'C': 0.006137780170579053, 'penalty': None, 'solver': 'newton-cholesky', 'max_iter': 509, 'fit_intercept': False, 'class_weight': None}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:26:24,530] Trial 38 finished with value: 0.2311111111111111 and parameters: {'C': 2.846374867130478, 'penalty': None, 'solver': 'saga', 'max_iter': 448, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-12 16:26:30,365] Trial 39 finished with value: 0.7253333333333334 and parameters: {'C': 0.03120143211618977, 'penalty': None, 'solver': 'lbfgs', 'max_iter': 143, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:27:04,483] Trial 40 finished with value: 0.9937777777777778 and parameters: {'C': 0.5412349992679119, 'penalty': None, 'solver': 'saga', 'max_iter': 278, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:27:37,540] Trial 41 finished with value: 0.13244444444444445 and parameters: {'C': 0.22104735207861645, 'penalty': None, 'solver': 'saga', 'max_iter': 254, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:28:29,461] Trial 42 finished with value: 0.49422222222222223 and parameters: {'C': 0.8090114254895263, 'penalty': None, 'solver': 'saga', 'max_iter': 427, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:29:14,351] Trial 43 finished with value: 0.9937777777777778 and parameters: {'C': 0.4860613802443932, 'penalty': None, 'solver': 'saga', 'max_iter': 362, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:30:01,730] Trial 44 finished with value: 0.6933333333333334 and parameters: {'C': 31.171904656490224, 'penalty': None, 'solver': 'saga', 'max_iter': 356, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:30:40,098] Trial 45 finished with value: 0.8986666666666666 and parameters: {'C': 0.49151803754297885, 'penalty': None, 'solver': 'saga', 'max_iter': 298, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:31:04,240] Trial 46 finished with value: 0.9937777777777778 and parameters: {'C': 5.055192123347818, 'penalty': None, 'solver': 'saga', 'max_iter': 190, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-12 16:31:10,782] Trial 47 finished with value: 0.7262222222222222 and parameters: {'C': 3.8112454162179095, 'penalty': None, 'solver': 'lbfgs', 'max_iter': 193, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:31:24,517] Trial 48 finished with value: 0.0 and parameters: {'C': 14.429775968779882, 'penalty': None, 'solver': 'saga', 'max_iter': 101, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.9937777777777778.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:32:25,360] Trial 49 finished with value: 0.0 and parameters: {'C': 20.458135272774697, 'penalty': None, 'solver': 'saga', 'max_iter': 493, 'fit_intercept': False, 'class_weight': None}. Best is trial 27 with value: 0.9937777777777778.\n"
     ]
    }
   ],
   "source": [
    "## Criando função para tunar o modelo\n",
    "#def objective(trial):\n",
    "#\n",
    "#    params = {\n",
    "#        'C': trial.suggest_float('C', 1e-4, 1e+4, log=True),\n",
    "#        'penalty': trial.suggest_categorical('penalty', [None, 'l2']),\n",
    "#        'solver': trial.suggest_categorical('solver', ['lbfgs', 'saga', 'newton-cholesky']),\n",
    "#        'max_iter': trial.suggest_int('max_iter', 50, 1000),\n",
    "#        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "#        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "#        'random_state': rs\n",
    "#    }\n",
    "#    \n",
    "#    # Criando os pipeline com os transformers\n",
    "#    pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                        ('encoder', ce.CountEncoder())])\n",
    "#\n",
    "#    # Criando os pipeline com os transformers\n",
    "#    pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                    ('encoder_hd', ce.CatBoostEncoder())])\n",
    "#\n",
    "#    pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "#                          (\"scaler\", RobustScaler())])\n",
    "#\n",
    "#    # Criando o transformador\n",
    "#    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                    ('num', pipe_num, num_cols),\n",
    "#                                    ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "#                                    remainder=\"passthrough\")\n",
    "#    \n",
    "#    # Criando o pipeline final\n",
    "#    pipe = Pipeline([('transformer', transformer),\n",
    "#                    ('model', LogisticRegression(**params))])\n",
    "#\n",
    "#    # Treinando o modelo com os dados de treino\n",
    "#    pipe.fit(x_treino, y_treino)\n",
    "#   \n",
    "#    recall = recall_score(y_dev, pipe.predict(x_dev))\n",
    "#    \n",
    "#    return recall\n",
    "#\n",
    "## Criando o estudo de otimização\n",
    "#study = optuna.create_study(direction = 'maximize')\n",
    "#study.optimize(objective, n_trials = 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos parâmetros que quase zeram a taxa de falsos negativos. Averiguaremos \n",
    "melhor durante o teste final, mas me reservarei a selecionar outro conjunto de \n",
    "parâmetros que identifiquei no log dos experimentos, pois diferentemente dos\n",
    "melhores parâmetros encontrados, estes usam regularização, que ajuda a prevenir o \n",
    "overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando os melhores parâmetros\n",
    "best_params_l1_v1 = {'C': 0.0003497693165590731,\n",
    "                    'penalty': None,\n",
    "                    'solver': 'saga',\n",
    "                    'max_iter': 224,\n",
    "                    'fit_intercept': False,\n",
    "                    'class_weight': 'balanced',\n",
    "                    'random_state': rs}\n",
    "\n",
    "best_params_l1_v2 = {'C': 1789.4428651327607, \n",
    "                      'penalty': 'l2', \n",
    "                      'solver': 'saga', \n",
    "                      'max_iter': 694, \n",
    "                      'fit_intercept': True, \n",
    "                      'class_weight': 'balanced',\n",
    "                      'random_state':rs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  [&#x27;entrega_doc_2&#x27;,\n",
       "                                                   &#x27;entrega_doc_3&#x27;,\n",
       "                                                   &#x27;continente&#x27;,\n",
       "                                                   &#x27;nome_dia_compra&#x27;,\n",
       "                                                   &#x27;dia_compra_classe&#x27;,\n",
       "                                                   &#x27;turno_compra&#x27;,\n",
       "                                                   &#x27;horario_comercial_compra&#x27;]),...\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat_hd&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder_hd&#x27;,\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  [&#x27;pais&#x27;,\n",
       "                                                   &#x27;categoria_produto&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=0.0003497693165590731,\n",
       "                                    class_weight=&#x27;balanced&#x27;,\n",
       "                                    fit_intercept=False, max_iter=224,\n",
       "                                    penalty=None, random_state=840,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  [&#x27;entrega_doc_2&#x27;,\n",
       "                                                   &#x27;entrega_doc_3&#x27;,\n",
       "                                                   &#x27;continente&#x27;,\n",
       "                                                   &#x27;nome_dia_compra&#x27;,\n",
       "                                                   &#x27;dia_compra_classe&#x27;,\n",
       "                                                   &#x27;turno_compra&#x27;,\n",
       "                                                   &#x27;horario_comercial_compra&#x27;]),...\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat_hd&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder_hd&#x27;,\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  [&#x27;pais&#x27;,\n",
       "                                                   &#x27;categoria_produto&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=0.0003497693165590731,\n",
       "                                    class_weight=&#x27;balanced&#x27;,\n",
       "                                    fit_intercept=False, max_iter=224,\n",
       "                                    penalty=None, random_state=840,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;transformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for transformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                 [&#x27;entrega_doc_2&#x27;, &#x27;entrega_doc_3&#x27;,\n",
       "                                  &#x27;continente&#x27;, &#x27;nome_dia_compra&#x27;,\n",
       "                                  &#x27;dia_compra_classe&#x27;, &#x27;turno_compra&#x27;,\n",
       "                                  &#x27;horario_comercial_compra&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute...\n",
       "                                                 (&#x27;scaler&#x27;, RobustScaler())]),\n",
       "                                 Index([&#x27;score_1&#x27;, &#x27;score_2&#x27;, &#x27;score_3&#x27;, &#x27;score_4&#x27;, &#x27;score_5&#x27;, &#x27;score_6&#x27;,\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat_hd&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder_hd&#x27;,\n",
       "                                                  CatBoostEncoder())]),\n",
       "                                 [&#x27;pais&#x27;, &#x27;categoria_produto&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;entrega_doc_2&#x27;, &#x27;entrega_doc_3&#x27;, &#x27;continente&#x27;, &#x27;nome_dia_compra&#x27;, &#x27;dia_compra_classe&#x27;, &#x27;turno_compra&#x27;, &#x27;horario_comercial_compra&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CountEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>CountEncoder(combine_min_nan_groups=True)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>Index([&#x27;score_1&#x27;, &#x27;score_2&#x27;, &#x27;score_3&#x27;, &#x27;score_4&#x27;, &#x27;score_5&#x27;, &#x27;score_6&#x27;,\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RobustScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.RobustScaler.html\">?<span>Documentation for RobustScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RobustScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat_hd</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;pais&#x27;, &#x27;categoria_produto&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CatBoostEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>CatBoostEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.0003497693165590731, class_weight=&#x27;balanced&#x27;,\n",
       "                   fit_intercept=False, max_iter=224, penalty=None,\n",
       "                   random_state=840, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  ['entrega_doc_2',\n",
       "                                                   'entrega_doc_3',\n",
       "                                                   'continente',\n",
       "                                                   'nome_dia_compra',\n",
       "                                                   'dia_compra_classe',\n",
       "                                                   'turno_compra',\n",
       "                                                   'horario_comercial_compra']),...\n",
       "       'valor_compra', 'dia_compra', 'hora_compra'],\n",
       "      dtype='object')),\n",
       "                                                 ('cat_hd',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder_hd',\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  ['pais',\n",
       "                                                   'categoria_produto'])])),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=0.0003497693165590731,\n",
       "                                    class_weight='balanced',\n",
       "                                    fit_intercept=False, max_iter=224,\n",
       "                                    penalty=None, random_state=840,\n",
       "                                    solver='saga'))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando os pipeline com os transformers\n",
    "pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', ce.CountEncoder())])\n",
    "\n",
    "# Criando os pipeline com os transformers\n",
    "pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "                        (\"scaler\", RobustScaler())])\n",
    "\n",
    "# Criando o transformador\n",
    "transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                ('num', pipe_num, num_cols),\n",
    "                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                remainder=\"passthrough\")\n",
    "\n",
    "# Criando o pipeline final\n",
    "pipe_logistica_1_v1 = Pipeline([('transformer', transformer),\n",
    "                ('model', LogisticRegression(**best_params_l1_v1))])\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "pipe_logistica_1_v1.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  [&#x27;entrega_doc_2&#x27;,\n",
       "                                                   &#x27;entrega_doc_3&#x27;,\n",
       "                                                   &#x27;continente&#x27;,\n",
       "                                                   &#x27;nome_dia_compra&#x27;,\n",
       "                                                   &#x27;dia_compra_classe&#x27;,\n",
       "                                                   &#x27;turno_compra&#x27;,\n",
       "                                                   &#x27;horario_comercial_compra&#x27;]),...\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat_hd&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder_hd&#x27;,\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  [&#x27;pais&#x27;,\n",
       "                                                   &#x27;categoria_produto&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=1789.4428651327607,\n",
       "                                    class_weight=&#x27;balanced&#x27;, max_iter=694,\n",
       "                                    random_state=840, solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  [&#x27;entrega_doc_2&#x27;,\n",
       "                                                   &#x27;entrega_doc_3&#x27;,\n",
       "                                                   &#x27;continente&#x27;,\n",
       "                                                   &#x27;nome_dia_compra&#x27;,\n",
       "                                                   &#x27;dia_compra_classe&#x27;,\n",
       "                                                   &#x27;turno_compra&#x27;,\n",
       "                                                   &#x27;horario_comercial_compra&#x27;]),...\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat_hd&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder_hd&#x27;,\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  [&#x27;pais&#x27;,\n",
       "                                                   &#x27;categoria_produto&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=1789.4428651327607,\n",
       "                                    class_weight=&#x27;balanced&#x27;, max_iter=694,\n",
       "                                    random_state=840, solver=&#x27;saga&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;transformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for transformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                 [&#x27;entrega_doc_2&#x27;, &#x27;entrega_doc_3&#x27;,\n",
       "                                  &#x27;continente&#x27;, &#x27;nome_dia_compra&#x27;,\n",
       "                                  &#x27;dia_compra_classe&#x27;, &#x27;turno_compra&#x27;,\n",
       "                                  &#x27;horario_comercial_compra&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute...\n",
       "                                                 (&#x27;scaler&#x27;, RobustScaler())]),\n",
       "                                 Index([&#x27;score_1&#x27;, &#x27;score_2&#x27;, &#x27;score_3&#x27;, &#x27;score_4&#x27;, &#x27;score_5&#x27;, &#x27;score_6&#x27;,\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat_hd&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder_hd&#x27;,\n",
       "                                                  CatBoostEncoder())]),\n",
       "                                 [&#x27;pais&#x27;, &#x27;categoria_produto&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;entrega_doc_2&#x27;, &#x27;entrega_doc_3&#x27;, &#x27;continente&#x27;, &#x27;nome_dia_compra&#x27;, &#x27;dia_compra_classe&#x27;, &#x27;turno_compra&#x27;, &#x27;horario_comercial_compra&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CountEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>CountEncoder(combine_min_nan_groups=True)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>Index([&#x27;score_1&#x27;, &#x27;score_2&#x27;, &#x27;score_3&#x27;, &#x27;score_4&#x27;, &#x27;score_5&#x27;, &#x27;score_6&#x27;,\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RobustScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.RobustScaler.html\">?<span>Documentation for RobustScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RobustScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat_hd</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;pais&#x27;, &#x27;categoria_produto&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CatBoostEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>CatBoostEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=1789.4428651327607, class_weight=&#x27;balanced&#x27;, max_iter=694,\n",
       "                   random_state=840, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   CountEncoder(combine_min_nan_groups=True))]),\n",
       "                                                  ['entrega_doc_2',\n",
       "                                                   'entrega_doc_3',\n",
       "                                                   'continente',\n",
       "                                                   'nome_dia_compra',\n",
       "                                                   'dia_compra_classe',\n",
       "                                                   'turno_compra',\n",
       "                                                   'horario_comercial_compra']),...\n",
       "       'score_7', 'score_8', 'score_9', 'score_10', 'entrega_doc_1',\n",
       "       'valor_compra', 'dia_compra', 'hora_compra'],\n",
       "      dtype='object')),\n",
       "                                                 ('cat_hd',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder_hd',\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  ['pais',\n",
       "                                                   'categoria_produto'])])),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1789.4428651327607,\n",
       "                                    class_weight='balanced', max_iter=694,\n",
       "                                    random_state=840, solver='saga'))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando os pipeline com os transformers\n",
    "pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', ce.CountEncoder())])\n",
    "\n",
    "# Criando os pipeline com os transformers\n",
    "pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "                        (\"scaler\", RobustScaler())])\n",
    "\n",
    "# Criando o transformador\n",
    "transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                ('num', pipe_num, num_cols),\n",
    "                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                remainder=\"passthrough\")\n",
    "\n",
    "# Criando o pipeline final\n",
    "pipe_logistica_1_v2 = Pipeline([('transformer', transformer),\n",
    "                ('model', LogisticRegression(**best_params_l1_v2))])\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "pipe_logistica_1_v2.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos testar a segunda: **Logistic Regression** + **OneHotEncoder** + **RobustSaler** + \n",
    "**SimpleImputer(Media)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-12 16:51:30,165] A new study created in memory with name: no-name-1c824317-15b5-4c22-be94-40fab415489d\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:52:22,398] Trial 0 finished with value: 0.0 and parameters: {'C': 21.713037031707483, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 349, 'fit_intercept': False, 'class_weight': None}. Best is trial 0 with value: 0.0.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=7.45724e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:52:27,452] Trial 1 finished with value: 0.016 and parameters: {'C': 0.00017662101025737182, 'penalty': None, 'solver': 'newton-cholesky', 'max_iter': 968, 'fit_intercept': True, 'class_weight': None}. Best is trial 1 with value: 0.016.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=7.45724e-18): result may not be accurate.\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:52:32,501] Trial 2 finished with value: 0.016 and parameters: {'C': 1725.9200400428695, 'penalty': None, 'solver': 'newton-cholesky', 'max_iter': 285, 'fit_intercept': True, 'class_weight': None}. Best is trial 1 with value: 0.016.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:52:36,921] Trial 3 finished with value: 0.016 and parameters: {'C': 0.32066844780991377, 'penalty': None, 'solver': 'lbfgs', 'max_iter': 846, 'fit_intercept': False, 'class_weight': None}. Best is trial 1 with value: 0.016.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:52:44,157] Trial 4 finished with value: 0.6702222222222223 and parameters: {'C': 0.08097097577299654, 'penalty': None, 'solver': 'lbfgs', 'max_iter': 547, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.6702222222222223.\n",
      "[I 2024-04-12 16:52:50,828] Trial 5 finished with value: 0.6711111111111111 and parameters: {'C': 683.5340573258113, 'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 274, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.6711111111111111.\n",
      "[I 2024-04-12 16:52:52,995] Trial 6 finished with value: 0.016 and parameters: {'C': 0.4789075639714033, 'penalty': 'l2', 'solver': 'newton-cholesky', 'max_iter': 306, 'fit_intercept': False, 'class_weight': None}. Best is trial 5 with value: 0.6711111111111111.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:54:06,240] Trial 7 finished with value: 0.7093333333333334 and parameters: {'C': 0.008154731923032201, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 495, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 7 with value: 0.7093333333333334.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:56:29,714] Trial 8 finished with value: 0.7093333333333334 and parameters: {'C': 1687.523110186112, 'penalty': None, 'solver': 'saga', 'max_iter': 994, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 7 with value: 0.7093333333333334.\n",
      "[I 2024-04-12 16:56:31,855] Trial 9 finished with value: 0.005333333333333333 and parameters: {'C': 0.0004219666833741841, 'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 714, 'fit_intercept': True, 'class_weight': None}. Best is trial 7 with value: 0.7093333333333334.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:56:40,692] Trial 10 finished with value: 0.696 and parameters: {'C': 0.006235084930029958, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 51, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 7 with value: 0.7093333333333334.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:58:07,924] Trial 11 finished with value: 0.7066666666666667 and parameters: {'C': 36.02601571635819, 'penalty': None, 'solver': 'saga', 'max_iter': 597, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 7 with value: 0.7093333333333334.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 16:59:52,137] Trial 12 finished with value: 0.7066666666666667 and parameters: {'C': 0.017204202482803813, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 718, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 7 with value: 0.7093333333333334.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:02:15,033] Trial 13 finished with value: 0.7102222222222222 and parameters: {'C': 3.9049332827863656, 'penalty': None, 'solver': 'saga', 'max_iter': 983, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:03:21,645] Trial 14 finished with value: 0.7102222222222222 and parameters: {'C': 9.08882961078663, 'penalty': None, 'solver': 'saga', 'max_iter': 447, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:04:26,790] Trial 15 finished with value: 0.7102222222222222 and parameters: {'C': 10.398512134626426, 'penalty': None, 'solver': 'saga', 'max_iter': 441, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:04:42,340] Trial 16 finished with value: 0.6924444444444444 and parameters: {'C': 6.41127402653964, 'penalty': None, 'solver': 'saga', 'max_iter': 98, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:06:21,429] Trial 17 finished with value: 0.7084444444444444 and parameters: {'C': 152.74950475004258, 'penalty': None, 'solver': 'saga', 'max_iter': 677, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:08:21,049] Trial 18 finished with value: 0.7102222222222222 and parameters: {'C': 1.99359668411708, 'penalty': None, 'solver': 'saga', 'max_iter': 824, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22406e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:08:28,517] Trial 19 finished with value: 0.6702222222222223 and parameters: {'C': 133.09780425217278, 'penalty': None, 'solver': 'newton-cholesky', 'max_iter': 440, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:08:51,322] Trial 20 finished with value: 0.6942222222222222 and parameters: {'C': 2.1753955631276884, 'penalty': None, 'solver': 'saga', 'max_iter': 148, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:09:57,847] Trial 21 finished with value: 0.7102222222222222 and parameters: {'C': 11.329348092611983, 'penalty': None, 'solver': 'saga', 'max_iter': 449, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:10:57,196] Trial 22 finished with value: 0.7084444444444444 and parameters: {'C': 8522.107060001204, 'penalty': None, 'solver': 'saga', 'max_iter': 405, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:12:26,667] Trial 23 finished with value: 0.7066666666666667 and parameters: {'C': 84.80699587953825, 'penalty': None, 'solver': 'saga', 'max_iter': 596, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:13:02,301] Trial 24 finished with value: 0.7013333333333334 and parameters: {'C': 0.13756930799706127, 'penalty': None, 'solver': 'saga', 'max_iter': 239, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:13:53,783] Trial 25 finished with value: 0.7084444444444444 and parameters: {'C': 8.090910020212537, 'penalty': None, 'solver': 'saga', 'max_iter': 368, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:15:04,085] Trial 26 finished with value: 0.7057777777777777 and parameters: {'C': 1.473233802947596, 'penalty': None, 'solver': 'saga', 'max_iter': 512, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:16:58,547] Trial 27 finished with value: 0.7102222222222222 and parameters: {'C': 5.174078104703016, 'penalty': None, 'solver': 'saga', 'max_iter': 814, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:498: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.22406e-17): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "[I 2024-04-12 17:17:06,092] Trial 28 finished with value: 0.6684444444444444 and parameters: {'C': 387.7583037302257, 'penalty': None, 'solver': 'newton-cholesky', 'max_iter': 198, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:17:10,793] Trial 29 finished with value: 0.016 and parameters: {'C': 0.061064607959288246, 'penalty': None, 'solver': 'lbfgs', 'max_iter': 362, 'fit_intercept': False, 'class_weight': None}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:18:49,710] Trial 30 finished with value: 0.7075555555555556 and parameters: {'C': 36.986491506000824, 'penalty': None, 'solver': 'saga', 'max_iter': 637, 'fit_intercept': True, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:21:13,593] Trial 31 finished with value: 0.7102222222222222 and parameters: {'C': 2.3090348472033595, 'penalty': None, 'solver': 'saga', 'max_iter': 942, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-04-12 17:23:21,383] Trial 32 finished with value: 0.7102222222222222 and parameters: {'C': 0.7135311801383506, 'penalty': None, 'solver': 'saga', 'max_iter': 895, 'fit_intercept': False, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.7102222222222222.\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Criando função para tunar o modelo\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 1e-4, 1e+4, log=True),\n",
    "        'penalty': trial.suggest_categorical('penalty', [None, 'l2']),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'saga', 'newton-cholesky']),\n",
    "        'max_iter': trial.suggest_int('max_iter', 50, 1000),\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "        'random_state': rs\n",
    "    }\n",
    "    \n",
    "    # Criando os pipeline com os transformers\n",
    "    pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                        ('encoder', OneHotEncoder(drop='first'))])\n",
    "\n",
    "    # Criando os pipeline com os transformers\n",
    "    pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "    pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"mean\")),\n",
    "                        ('scaler', RobustScaler())])\n",
    "\n",
    "    # Criando o transformador\n",
    "    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                    ('num', pipe_num, num_cols),\n",
    "                                    ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                    remainder=\"passthrough\")\n",
    "    \n",
    "    # Criando o pipeline final\n",
    "    pipe = Pipeline([('transformer', transformer),\n",
    "                    ('model', LogisticRegression(**params))])\n",
    "\n",
    "    # Treinando o modelo com os dados de treino\n",
    "    pipe.fit(x_treino, y_treino)\n",
    "   \n",
    "    recall = recall_score(y_dev, pipe.predict(x_dev))\n",
    "    \n",
    "    return recall\n",
    "\n",
    "# Criando o estudo de otimização\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_l2 = {'C': 0.00010412571220790058, \n",
    "                'penalty': 'l2', \n",
    "                'solver': 'saga', \n",
    "                'max_iter': 668, \n",
    "                'fit_intercept': False, \n",
    "                'class_weight': 'balanced',\n",
    "                'random_state':rs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;entrega_doc_2&#x27;,\n",
       "                                                   &#x27;entrega_doc_3&#x27;,\n",
       "                                                   &#x27;continente&#x27;,\n",
       "                                                   &#x27;nome_dia_compra&#x27;,\n",
       "                                                   &#x27;dia_compra_classe&#x27;,\n",
       "                                                   &#x27;turno_compra&#x27;,\n",
       "                                                   &#x27;horario_comercial_...\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat_hd&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder_hd&#x27;,\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  [&#x27;pais&#x27;,\n",
       "                                                   &#x27;categoria_produto&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=0.00010412571220790058,\n",
       "                                    class_weight=&#x27;balanced&#x27;,\n",
       "                                    fit_intercept=False, max_iter=668,\n",
       "                                    random_state=840, solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;entrega_doc_2&#x27;,\n",
       "                                                   &#x27;entrega_doc_3&#x27;,\n",
       "                                                   &#x27;continente&#x27;,\n",
       "                                                   &#x27;nome_dia_compra&#x27;,\n",
       "                                                   &#x27;dia_compra_classe&#x27;,\n",
       "                                                   &#x27;turno_compra&#x27;,\n",
       "                                                   &#x27;horario_comercial_...\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat_hd&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder_hd&#x27;,\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  [&#x27;pais&#x27;,\n",
       "                                                   &#x27;categoria_produto&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=0.00010412571220790058,\n",
       "                                    class_weight=&#x27;balanced&#x27;,\n",
       "                                    fit_intercept=False, max_iter=668,\n",
       "                                    random_state=840, solver=&#x27;saga&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;transformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for transformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;entrega_doc_2&#x27;, &#x27;entrega_doc_3&#x27;,\n",
       "                                  &#x27;continente&#x27;, &#x27;nome_dia_compra&#x27;,\n",
       "                                  &#x27;dia_compra_classe&#x27;, &#x27;turno_compra&#x27;,\n",
       "                                  &#x27;horario_comercial_compra&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps...\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 Index([&#x27;score_1&#x27;, &#x27;score_2&#x27;, &#x27;score_3&#x27;, &#x27;score_4&#x27;, &#x27;score_5&#x27;, &#x27;score_6&#x27;,\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat_hd&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder_hd&#x27;,\n",
       "                                                  CatBoostEncoder())]),\n",
       "                                 [&#x27;pais&#x27;, &#x27;categoria_produto&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;entrega_doc_2&#x27;, &#x27;entrega_doc_3&#x27;, &#x27;continente&#x27;, &#x27;nome_dia_compra&#x27;, &#x27;dia_compra_classe&#x27;, &#x27;turno_compra&#x27;, &#x27;horario_comercial_compra&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>Index([&#x27;score_1&#x27;, &#x27;score_2&#x27;, &#x27;score_3&#x27;, &#x27;score_4&#x27;, &#x27;score_5&#x27;, &#x27;score_6&#x27;,\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat_hd</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;pais&#x27;, &#x27;categoria_produto&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CatBoostEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>CatBoostEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.00010412571220790058, class_weight=&#x27;balanced&#x27;,\n",
       "                   fit_intercept=False, max_iter=668, random_state=840,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 handle_unknown='ignore'))]),\n",
       "                                                  ['entrega_doc_2',\n",
       "                                                   'entrega_doc_3',\n",
       "                                                   'continente',\n",
       "                                                   'nome_dia_compra',\n",
       "                                                   'dia_compra_classe',\n",
       "                                                   'turno_compra',\n",
       "                                                   'horario_comercial_...\n",
       "       'valor_compra', 'dia_compra', 'hora_compra'],\n",
       "      dtype='object')),\n",
       "                                                 ('cat_hd',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder_hd',\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  ['pais',\n",
       "                                                   'categoria_produto'])])),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=0.00010412571220790058,\n",
       "                                    class_weight='balanced',\n",
       "                                    fit_intercept=False, max_iter=668,\n",
       "                                    random_state=840, solver='saga'))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando os pipeline com os transformers\n",
    "pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))])\n",
    "\n",
    "# Criando os pipeline com os transformers\n",
    "pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "                    ('scaler', StandardScaler())])\n",
    "\n",
    "# Criando o transformador\n",
    "transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                ('num', pipe_num, num_cols),\n",
    "                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                remainder=\"passthrough\")\n",
    "\n",
    "# Criando o pipeline final\n",
    "pipe_logistica_2 = Pipeline([('transformer', transformer),\n",
    "                ('model', LogisticRegression(**best_params_l2))])\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "pipe_logistica_2.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E finalmente, vamos à ultima combinação: **LightGBM** + **OneHotEncoder** + **SimpleImputer(Média)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsxgb = {'n_estimators': 226,\n",
    " 'learning_rate': 0.24648438544316717,\n",
    " 'max_depth': 7,\n",
    " 'subsample': 0.6835401307831506,\n",
    " 'colsample_bytree': 0.8125214901314792,\n",
    " 'reg_alpha': 9.520719398813776,\n",
    " 'reg_lambda': 4.946735056145298,\n",
    "'random_state':rs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5250, number of negative: 99750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2757\n",
      "[LightGBM] [Info] Number of data points in the train set: 105000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050000 -> initscore=-2.944439\n",
      "[LightGBM] [Info] Start training from score -2.944439\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;entrega_doc_2&#x27;,\n",
       "                                                   &#x27;entrega_doc_3&#x27;,\n",
       "                                                   &#x27;continente&#x27;,\n",
       "                                                   &#x27;nome_dia_compra&#x27;,\n",
       "                                                   &#x27;dia_compra_classe&#x27;,\n",
       "                                                   &#x27;turno_compra&#x27;,\n",
       "                                                   &#x27;horario_comercial_...\n",
       "                                                  Index([&#x27;score_1&#x27;, &#x27;score_2&#x27;, &#x27;score_3&#x27;, &#x27;score_4&#x27;, &#x27;score_5&#x27;, &#x27;score_6&#x27;,\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat_hd&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder_hd&#x27;,\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  [&#x27;pais&#x27;,\n",
       "                                                   &#x27;categoria_produto&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(is_unbalance=True, objective=&#x27;binary&#x27;,\n",
       "                                random_state=840))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;entrega_doc_2&#x27;,\n",
       "                                                   &#x27;entrega_doc_3&#x27;,\n",
       "                                                   &#x27;continente&#x27;,\n",
       "                                                   &#x27;nome_dia_compra&#x27;,\n",
       "                                                   &#x27;dia_compra_classe&#x27;,\n",
       "                                                   &#x27;turno_compra&#x27;,\n",
       "                                                   &#x27;horario_comercial_...\n",
       "                                                  Index([&#x27;score_1&#x27;, &#x27;score_2&#x27;, &#x27;score_3&#x27;, &#x27;score_4&#x27;, &#x27;score_5&#x27;, &#x27;score_6&#x27;,\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat_hd&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder_hd&#x27;,\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  [&#x27;pais&#x27;,\n",
       "                                                   &#x27;categoria_produto&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(is_unbalance=True, objective=&#x27;binary&#x27;,\n",
       "                                random_state=840))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;transformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for transformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;entrega_doc_2&#x27;, &#x27;entrega_doc_3&#x27;,\n",
       "                                  &#x27;continente&#x27;, &#x27;nome_dia_compra&#x27;,\n",
       "                                  &#x27;dia_compra_classe&#x27;, &#x27;turno_compra&#x27;,\n",
       "                                  &#x27;horario_comercial_compra&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps...\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 Index([&#x27;score_1&#x27;, &#x27;score_2&#x27;, &#x27;score_3&#x27;, &#x27;score_4&#x27;, &#x27;score_5&#x27;, &#x27;score_6&#x27;,\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat_hd&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer_cat&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder_hd&#x27;,\n",
       "                                                  CatBoostEncoder())]),\n",
       "                                 [&#x27;pais&#x27;, &#x27;categoria_produto&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;entrega_doc_2&#x27;, &#x27;entrega_doc_3&#x27;, &#x27;continente&#x27;, &#x27;nome_dia_compra&#x27;, &#x27;dia_compra_classe&#x27;, &#x27;turno_compra&#x27;, &#x27;horario_comercial_compra&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>Index([&#x27;score_1&#x27;, &#x27;score_2&#x27;, &#x27;score_3&#x27;, &#x27;score_4&#x27;, &#x27;score_5&#x27;, &#x27;score_6&#x27;,\n",
       "       &#x27;score_7&#x27;, &#x27;score_8&#x27;, &#x27;score_9&#x27;, &#x27;score_10&#x27;, &#x27;entrega_doc_1&#x27;,\n",
       "       &#x27;valor_compra&#x27;, &#x27;dia_compra&#x27;, &#x27;hora_compra&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">cat_hd</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;pais&#x27;, &#x27;categoria_produto&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CatBoostEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>CatBoostEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">remainder</label><div class=\"sk-toggleable__content fitted\"><pre>[]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(is_unbalance=True, objective=&#x27;binary&#x27;, random_state=840)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 handle_unknown='ignore'))]),\n",
       "                                                  ['entrega_doc_2',\n",
       "                                                   'entrega_doc_3',\n",
       "                                                   'continente',\n",
       "                                                   'nome_dia_compra',\n",
       "                                                   'dia_compra_classe',\n",
       "                                                   'turno_compra',\n",
       "                                                   'horario_comercial_...\n",
       "                                                  Index(['score_1', 'score_2', 'score_3', 'score_4', 'score_5', 'score_6',\n",
       "       'score_7', 'score_8', 'score_9', 'score_10', 'entrega_doc_1',\n",
       "       'valor_compra', 'dia_compra', 'hora_compra'],\n",
       "      dtype='object')),\n",
       "                                                 ('cat_hd',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder_hd',\n",
       "                                                                   CatBoostEncoder())]),\n",
       "                                                  ['pais',\n",
       "                                                   'categoria_produto'])])),\n",
       "                ('model',\n",
       "                 LGBMClassifier(is_unbalance=True, objective='binary',\n",
       "                                random_state=840))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando os pipeline com os transformers\n",
    "pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))])\n",
    "\n",
    "# Criando os pipeline com os transformers\n",
    "pipe_cat_high_dim = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "                                ('encoder_hd', ce.CatBoostEncoder())])\n",
    "\n",
    "pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy=\"median\")),\n",
    "                    ('scaler', StandardScaler())])\n",
    "\n",
    "# Criando o transformador\n",
    "transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                ('num', pipe_num, num_cols),\n",
    "                                ('cat_hd', pipe_cat_high_dim, cat_cols_high_dim)],\n",
    "                                remainder=\"passthrough\")\n",
    "\n",
    "# Criando o pipeline final\n",
    "pipexgb = Pipeline([('transformer', transformer),\n",
    "                ('model', LGBMClassifier(is_unbalance=True,\n",
    "                                                 objective= 'binary',\n",
    "                                                 random_state=rs))])\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "pipexgb.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664\n",
      "0.8368105205162732\n"
     ]
    }
   ],
   "source": [
    "# Calculando o recall\n",
    "print(recall_score(y_teste, pipexgb.predict(x_teste)))\n",
    "print(f1_score(y_teste, pipexgb.predict(x_teste), average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6471111111111111\n",
      "0.8006417475071521\n"
     ]
    }
   ],
   "source": [
    "# Calculando o recall\n",
    "print(recall_score(y_teste, pipe.predict(x_teste)))\n",
    "print(f1_score(y_teste, pipe.predict(x_teste), average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprando modelos\n",
    "\n",
    "Podemos ver que o modelo atual possui um desempenho melhor em evitar falsos \n",
    "positivos.\n",
    "\n",
    "Vamos adicionar métricas financeiras para melhorar a análise. Vamos relembrar:\n",
    "- A cada aprovação correta, recebemos 10% do valor.\n",
    "- A cada fraude aprovada, perdemos 100% do valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metrics[\"label_fraude_novo_modelo\"] = pipexgb.predict(x_teste)\n",
    "data_metrics[\"score_fraude_novo_modelo\"] = pipexgb.predict_proba(x_teste)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com o threshold base (50%), o recall é de:  0.664\n",
      "Com o threshold base (50%), o f1-score weighted é de:  0.8368105205162732\n",
      "Com o threshold base (50%), as perdas são de:  15101.95\n",
      "Com o threshold base (50%), os ganhos bruto são de:  59328.899000000005\n",
      "Com o threshold base (50%), os ganhos líquidos são de:  44226.94900000001\n"
     ]
    }
   ],
   "source": [
    "# Calculando as métricas\n",
    "recall = recall_score(data_metrics[\"fraude\"], data_metrics[\"label_fraude_novo_modelo\"])\n",
    "f1_weighted = f1_score(data_metrics[\"fraude\"], data_metrics[\"label_fraude_novo_modelo\"], average=\"weighted\")\n",
    "perdas = data_metrics.query(\"fraude == 1 and label_fraude_novo_modelo == 0\")[\"valor_compra\"].sum()\n",
    "ganhos_brutos = (data_metrics.query(\"fraude == 0 and label_fraude_novo_modelo == 0\")[\"valor_compra\"] * 0.10).sum()\n",
    "ganhos_liquidos = ganhos_brutos - perdas\n",
    "\n",
    "print(\"Com o threshold base (50%), o recall é de: \", recall)\n",
    "print(\"Com o threshold base (50%), o f1-score weighted é de: \", f1_weighted)\n",
    "print(\"Com o threshold base (50%), as perdas são de: \", perdas)\n",
    "print(\"Com o threshold base (50%), os ganhos bruto são de: \", ganhos_brutos)\n",
    "print(\"Com o threshold base (50%), os ganhos líquidos são de: \", ganhos_liquidos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ganhos Líquidos = 46362.210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dict = {\"Threshold\":[], \n",
    "             \"Recall\":[],\n",
    "             \"Precision\":[],\n",
    "             \"F1 Weighted\":[],\n",
    "             \"Ganhos Brutos\":[],\n",
    "             \"Perdas\":[],\n",
    "             \"Ganhos Líquidos\":[]}\n",
    "\n",
    "# Calculando as métricas para cada threshold\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "    predictions = (data_metrics[\"score_fraude_novo_modelo\"] >= threshold).astype(int)\n",
    "    recall = recall_score(y_teste, predictions)\n",
    "    precision = precision_score(y_teste, predictions)\n",
    "    f1 = f1_score(y_teste, predictions, average=\"weighted\")\n",
    "    data_dict[\"Threshold\"].append(threshold)\n",
    "    data_dict[\"Recall\"].append(recall)\n",
    "    data_dict[\"Precision\"].append(precision)\n",
    "    data_dict[\"F1 Weighted\"].append(f1)\n",
    "    \n",
    "    data_metrics[\"label_fraude_novo_modelo\"] = predictions\n",
    "    acertos = data_metrics.query(f\"fraude == 0 and label_fraude_novo_modelo == 0\")\n",
    "    erros = data_metrics.query(f\"fraude == 1 and label_fraude_novo_modelo == 0\")\n",
    "    ganhos = (acertos[\"valor_compra\"] * 0.10).sum()\n",
    "    perdas = erros[\"valor_compra\"].sum()\n",
    "    diff_ganhos_perdas = ganhos - perdas\n",
    "    data_dict[\"Ganhos Brutos\"].append(ganhos)\n",
    "    data_dict[\"Perdas\"].append(perdas)\n",
    "    data_dict[\"Ganhos Líquidos\"].append(diff_ganhos_perdas)\n",
    "        \n",
    "# Plotando o gráfico    \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"Recall\"], label='Recall')\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"Precision\"], label='Precision')\n",
    "sns.lineplot(x=data_dict[\"Threshold\"], y=data_dict[\"F1 Weighted\"], label='F1 Weighted')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Recall, Precision e F1 Weighted em diferentes thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Ganhos Brutos</th>\n",
       "      <th>Perdas</th>\n",
       "      <th>Ganhos Líquidos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.237756</td>\n",
       "      <td>0.914819</td>\n",
       "      <td>75491.945</td>\n",
       "      <td>25932.14</td>\n",
       "      <td>49559.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.218862</td>\n",
       "      <td>0.906826</td>\n",
       "      <td>73321.485</td>\n",
       "      <td>23838.09</td>\n",
       "      <td>49483.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.458667</td>\n",
       "      <td>0.230976</td>\n",
       "      <td>0.912273</td>\n",
       "      <td>74648.887</td>\n",
       "      <td>25195.20</td>\n",
       "      <td>49453.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.224335</td>\n",
       "      <td>0.909590</td>\n",
       "      <td>73874.218</td>\n",
       "      <td>24503.60</td>\n",
       "      <td>49370.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.497778</td>\n",
       "      <td>0.209111</td>\n",
       "      <td>0.902855</td>\n",
       "      <td>72443.900</td>\n",
       "      <td>23230.17</td>\n",
       "      <td>49213.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.051079</td>\n",
       "      <td>0.050909</td>\n",
       "      <td>1265.073</td>\n",
       "      <td>38.95</td>\n",
       "      <td>1226.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.050481</td>\n",
       "      <td>0.028589</td>\n",
       "      <td>596.902</td>\n",
       "      <td>38.95</td>\n",
       "      <td>557.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>0.050179</td>\n",
       "      <td>0.013537</td>\n",
       "      <td>250.757</td>\n",
       "      <td>6.20</td>\n",
       "      <td>244.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>30.749</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold    Recall  Precision  F1 Weighted  Ganhos Brutos    Perdas  \\\n",
       "68       0.68  0.444444   0.237756     0.914819      75491.945  25932.14   \n",
       "65       0.65  0.488889   0.218862     0.906826      73321.485  23838.09   \n",
       "67       0.67  0.458667   0.230976     0.912273      74648.887  25195.20   \n",
       "66       0.66  0.472000   0.224335     0.909590      73874.218  24503.60   \n",
       "64       0.64  0.497778   0.209111     0.902855      72443.900  23230.17   \n",
       "..        ...       ...        ...          ...            ...       ...   \n",
       "4        0.04  0.997333   0.051079     0.050909       1265.073     38.95   \n",
       "3        0.03  0.997333   0.050481     0.028589        596.902     38.95   \n",
       "2        0.02  0.999111   0.050179     0.013537        250.757      6.20   \n",
       "1        0.01  1.000000   0.050033     0.006097         30.749      0.00   \n",
       "0        0.00  1.000000   0.050000     0.004762          0.000      0.00   \n",
       "\n",
       "    Ganhos Líquidos  \n",
       "68        49559.805  \n",
       "65        49483.395  \n",
       "67        49453.687  \n",
       "66        49370.618  \n",
       "64        49213.730  \n",
       "..              ...  \n",
       "4          1226.123  \n",
       "3           557.952  \n",
       "2           244.557  \n",
       "1            30.749  \n",
       "0             0.000  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando os dados em forma de tabela\n",
    "pd.DataFrame(data_dict).sort_values(by=\"Ganhos Líquidos\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos fazer o mesmo com as predições do modelo atual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9617/2854574763.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  conjunto_teste[f\"predict_threshold_{str(threshold).replace('.', '_')}\"] = predictions\n",
      "/tmp/ipykernel_9617/2854574763.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  conjunto_teste[f\"predict_threshold_{str(threshold).replace('.', '_')}\"] = predictions\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/tmp/ipykernel_9617/2854574763.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  conjunto_teste[f\"predict_threshold_{str(threshold).replace('.', '_')}\"] = predictions\n",
      "/home/daniel/Documents/preditor_fraude/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/tmp/ipykernel_9617/2854574763.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  conjunto_teste[f\"predict_threshold_{str(threshold).replace('.', '_')}\"] = predictions\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definindo listas vazias\n",
    "thresholds = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "earnings = []\n",
    "loses = []\n",
    "diff_earnings_loses = []\n",
    "\n",
    "# Calculando as métricas para cada threshold\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "    predictions = (pipe.predict_proba(x_teste)[:, 1] >= threshold).astype(int)\n",
    "    recall = recall_score(y_teste, predictions)\n",
    "    precision = precision_score(y_teste, predictions)\n",
    "    recall_list.append(recall)\n",
    "    precision_list.append(precision)\n",
    "    thresholds.append(threshold)\n",
    "    \n",
    "    conjunto_teste[f\"predict_threshold_{str(threshold).replace('.', '_')}\"] = predictions\n",
    "    acertos = conjunto_teste.query(f\"fraude == 0 and predict_threshold_{str(threshold).replace('.', '_')} == 0\")\n",
    "    erros = conjunto_teste.query(f\"fraude == 1 and predict_threshold_{str(threshold).replace('.', '_')} == 0\")\n",
    "    ganhos = (acertos[\"valor_compra\"] * 0.10).sum()\n",
    "    perdas = erros[\"valor_compra\"].sum()\n",
    "    diff_ganhos_perdas = ganhos - perdas\n",
    "    earnings.append(ganhos)\n",
    "    loses.append(perdas)\n",
    "    diff_earnings_loses.append(diff_ganhos_perdas)\n",
    "    \n",
    "# Plotando o gráfico    \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=thresholds, y=recall_list, label='Recall')\n",
    "sns.lineplot(x=thresholds, y=precision_list, label='Precision')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Recall e Precision em diferentes thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dataframe com os dados\n",
    "data_metrics = pd.DataFrame({'Thresholds': thresholds, \n",
    "                             \"Recall\":recall_list, \n",
    "                             \"Precision\":precision_list,\n",
    "                             \"Ganho_Bruto\":earnings,\n",
    "                             \"Perdas_Com_Fraudes\":loses,\n",
    "                             \"Ganho_Líquido\":diff_earnings_loses})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thresholds</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Ganho_Bruto</th>\n",
       "      <th>Perdas_Com_Fraudes</th>\n",
       "      <th>Ganho_Líquido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.389333</td>\n",
       "      <td>0.182652</td>\n",
       "      <td>68438.636</td>\n",
       "      <td>28984.77</td>\n",
       "      <td>39453.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.358222</td>\n",
       "      <td>0.190905</td>\n",
       "      <td>69812.134</td>\n",
       "      <td>30540.60</td>\n",
       "      <td>39271.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.518222</td>\n",
       "      <td>0.137792</td>\n",
       "      <td>59685.895</td>\n",
       "      <td>21415.16</td>\n",
       "      <td>38270.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.490667</td>\n",
       "      <td>0.145723</td>\n",
       "      <td>61813.399</td>\n",
       "      <td>23544.99</td>\n",
       "      <td>38268.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.410667</td>\n",
       "      <td>0.171492</td>\n",
       "      <td>66761.063</td>\n",
       "      <td>28499.29</td>\n",
       "      <td>38261.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>3.308</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>3.308</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Thresholds    Recall  Precision  Ganho_Bruto  Perdas_Com_Fraudes  \\\n",
       "62        0.62  0.389333   0.182652    68438.636            28984.77   \n",
       "63        0.63  0.358222   0.190905    69812.134            30540.60   \n",
       "57        0.57  0.518222   0.137792    59685.895            21415.16   \n",
       "58        0.58  0.490667   0.145723    61813.399            23544.99   \n",
       "61        0.61  0.410667   0.171492    66761.063            28499.29   \n",
       "..         ...       ...        ...          ...                 ...   \n",
       "3         0.03  1.000000   0.050002        3.308                0.00   \n",
       "4         0.04  1.000000   0.050002        3.308                0.00   \n",
       "1         0.01  1.000000   0.050000        0.000                0.00   \n",
       "2         0.02  1.000000   0.050000        0.000                0.00   \n",
       "0         0.00  1.000000   0.050000        0.000                0.00   \n",
       "\n",
       "    Ganho_Líquido  \n",
       "62      39453.866  \n",
       "63      39271.534  \n",
       "57      38270.735  \n",
       "58      38268.409  \n",
       "61      38261.773  \n",
       "..            ...  \n",
       "3           3.308  \n",
       "4           3.308  \n",
       "1           0.000  \n",
       "2           0.000  \n",
       "0           0.000  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenando pelo modelo que mais trouxe ganhos totais\n",
    "data_metrics.sort_values(\"Ganho_Líquido\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo com o threshold de 0.62 foi o que mais trouxe ganho dado apenas o conjunto\n",
    "de validação.\n",
    "\n",
    "Agora que já temos o melhor modelo, e sabemos qual o threshold que vai trazer o \n",
    "maior retorno, vamos criar uma API que poderia ser acoplada ao um sistema de\n",
    "transações. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/logistica.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe, \"../models/logistica.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
